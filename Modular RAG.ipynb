{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß© Modular RAG Implementation\n",
    "\n",
    "## Complete Modular Architecture for AI Systems\n",
    "\n",
    "This notebook demonstrates a **Modular RAG system** with:\n",
    "- üîç Intelligent Query Processing\n",
    "- üîé Multi-Strategy Retrieval \n",
    "- ü§ñ Adaptive Generation\n",
    "- üíæ Memory Management\n",
    "- üö¶ Smart Routing\n",
    "\n",
    "### Key Benefits of Modular Architecture\n",
    "- **Flexibility**: Easy to swap and customize components\n",
    "- **Scalability**: Add new modules without changing core system\n",
    "- **Maintainability**: Independent testing and updates\n",
    "- **Extensibility**: Domain-specific specializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: google-generativeai in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: rank-bm25 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: scikit-learn in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dotenv in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: scipy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: tqdm in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: google-api-core in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: pydantic in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: protobuf in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-python-client in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.173.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.11.0->sentence-transformers) (58.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers faiss-cpu google-generativeai rank-bm25 transformers scikit-learn numpy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import google.generativeai as genai\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Core Data Structures\n",
    "\n",
    "Define the foundational structures for our modular system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Data structures defined!\n"
     ]
    }
   ],
   "source": [
    "# Enums for system configuration\n",
    "class QueryType(Enum):\n",
    "    FACTUAL = \"factual\"\n",
    "    COMPARATIVE = \"comparative\"\n",
    "    PROCEDURAL = \"procedural\"\n",
    "    ANALYTICAL = \"analytical\"\n",
    "    CONVERSATIONAL = \"conversational\"\n",
    "\n",
    "class Domain(Enum):\n",
    "    TECHNOLOGY = \"technology\"\n",
    "    SCIENCE = \"science\"\n",
    "    BUSINESS = \"business\"\n",
    "    HEALTHCARE = \"healthcare\"\n",
    "    GENERAL = \"general\"\n",
    "\n",
    "class RetrievalStrategy(Enum):\n",
    "    SEMANTIC = \"semantic\"\n",
    "    KEYWORD = \"keyword\"\n",
    "    HYBRID = \"hybrid\"\n",
    "\n",
    "# Core data structures\n",
    "@dataclass\n",
    "class Document:\n",
    "    id: str\n",
    "    title: str\n",
    "    content: str\n",
    "    domain: Domain\n",
    "    keywords: List[str] = field(default_factory=list)\n",
    "    embedding: Optional[np.ndarray] = None\n",
    "\n",
    "@dataclass\n",
    "class Query:\n",
    "    id: str\n",
    "    text: str\n",
    "    query_type: QueryType\n",
    "    domain: Domain\n",
    "    user_id: Optional[str] = None\n",
    "    session_id: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class RetrievalResult:\n",
    "    document: Document\n",
    "    score: float\n",
    "    rank: int\n",
    "    strategy_used: RetrievalStrategy\n",
    "\n",
    "@dataclass\n",
    "class ModularResponse:\n",
    "    query: Query\n",
    "    retrieved_documents: List[RetrievalResult]\n",
    "    generated_answer: str\n",
    "    confidence_score: float\n",
    "    processing_pipeline: List[str]\n",
    "    processing_time: float\n",
    "\n",
    "print(\"üèóÔ∏è Data structures defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Multi-Domain Knowledge Base\n",
    "\n",
    "Create knowledge base covering multiple domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Knowledge base created with 5 documents\n",
      "üåç Domains: {'healthcare', 'science', 'business', 'technology'}\n"
     ]
    }
   ],
   "source": [
    "# Multi-domain knowledge base\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"id\": \"tech_001\",\n",
    "        \"title\": \"Cloud Computing Fundamentals\",\n",
    "        \"domain\": \"technology\",\n",
    "        \"content\": \"Cloud computing delivers computing services including servers, storage, databases, networking, software, analytics, and intelligence over the internet. Main service models include Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Major providers include AWS, Microsoft Azure, and Google Cloud Platform. Benefits include cost reduction, scalability, reliability, and global reach.\",\n",
    "        \"keywords\": [\"cloud\", \"computing\", \"AWS\", \"Azure\", \"IaaS\", \"PaaS\", \"SaaS\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"tech_002\",\n",
    "        \"title\": \"Artificial Intelligence and Machine Learning\",\n",
    "        \"domain\": \"technology\",\n",
    "        \"content\": \"Artificial Intelligence simulates human intelligence in machines programmed to think and learn. Machine Learning is a subset of AI that enables systems to learn from experience without explicit programming. Deep Learning uses neural networks with multiple layers. Key applications include computer vision, natural language processing, recommendation systems, and autonomous vehicles.\",\n",
    "        \"keywords\": [\"AI\", \"machine learning\", \"deep learning\", \"neural networks\", \"computer vision\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"sci_001\",\n",
    "        \"title\": \"Quantum Computing Principles\",\n",
    "        \"domain\": \"science\",\n",
    "        \"content\": \"Quantum computing leverages quantum mechanical phenomena like superposition and entanglement to process information differently than classical computers. Quantum bits (qubits) can exist in multiple states simultaneously. Key principles include superposition, entanglement, and quantum interference. Applications include cryptography, optimization, drug discovery, and financial modeling.\",\n",
    "        \"keywords\": [\"quantum\", \"qubits\", \"superposition\", \"entanglement\", \"cryptography\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"health_001\",\n",
    "        \"title\": \"Telemedicine and Digital Health\",\n",
    "        \"domain\": \"healthcare\",\n",
    "        \"content\": \"Telemedicine uses telecommunications technology to provide clinical health care at a distance. Key modalities include video consultations, remote patient monitoring, mobile health applications, and digital therapeutics. Benefits include improved access to care, reduced costs, convenience, and ability to serve remote populations. COVID-19 accelerated telemedicine adoption significantly.\",\n",
    "        \"keywords\": [\"telemedicine\", \"digital health\", \"remote monitoring\", \"mobile health\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"bus_001\",\n",
    "        \"title\": \"Digital Transformation Strategies\",\n",
    "        \"domain\": \"business\",\n",
    "        \"content\": \"Digital transformation integrates digital technology into all business areas, fundamentally changing operations and value delivery. Key components include process automation, data analytics, customer experience enhancement, and business model innovation. Success factors include leadership commitment, cultural change management, employee training, and customer-centric focus.\",\n",
    "        \"keywords\": [\"digital transformation\", \"automation\", \"analytics\", \"customer experience\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìö Knowledge base created with {len(knowledge_base)} documents\")\n",
    "print(f\"üåç Domains: {set(doc['domain'] for doc in knowledge_base)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Module Base Classes\n",
    "\n",
    "Define abstract base classes for modular architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Base module class defined!\n"
     ]
    }
   ],
   "source": [
    "# Base module class\n",
    "class BaseModule(ABC):\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.call_count = 0\n",
    "        self.created_at = datetime.now()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process(self, input_data: Any) -> Any:\n",
    "        pass\n",
    "    \n",
    "    def update_stats(self):\n",
    "        self.call_count += 1\n",
    "    \n",
    "    def get_info(self):\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'calls': self.call_count,\n",
    "            'created': self.created_at\n",
    "        }\n",
    "\n",
    "print(\"üß© Base module class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Query Processing Module\n",
    "\n",
    "Intelligent query understanding and classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test query processed:\n",
      "   Text: What is cloud computing?\n",
      "   Type: factual\n",
      "   Domain: technology\n",
      "‚úÖ Query Module ready!\n"
     ]
    }
   ],
   "source": [
    "class QueryModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"QueryModule\")\n",
    "        \n",
    "        # Query type patterns\n",
    "        self.type_patterns = {\n",
    "            QueryType.FACTUAL: [r\"what is\", r\"define\", r\"explain\"],\n",
    "            QueryType.COMPARATIVE: [r\"compare\", r\"difference\", r\"versus\", r\"vs\"],\n",
    "            QueryType.PROCEDURAL: [r\"how to\", r\"steps\", r\"process\"],\n",
    "            QueryType.ANALYTICAL: [r\"analyze\", r\"why\", r\"impact\"],\n",
    "            QueryType.CONVERSATIONAL: [r\"hello\", r\"hi\", r\"thanks\"]\n",
    "        }\n",
    "        \n",
    "        # Domain keywords\n",
    "        self.domain_keywords = {\n",
    "            Domain.TECHNOLOGY: [\"AI\", \"cloud\", \"software\", \"computing\", \"algorithm\"],\n",
    "            Domain.SCIENCE: [\"quantum\", \"research\", \"experiment\", \"theory\"],\n",
    "            Domain.HEALTHCARE: [\"medicine\", \"health\", \"patient\", \"treatment\"],\n",
    "            Domain.BUSINESS: [\"business\", \"strategy\", \"management\", \"revenue\"]\n",
    "        }\n",
    "    \n",
    "    def process(self, query_text: str) -> Query:\n",
    "        self.update_stats()\n",
    "        \n",
    "        query_id = str(uuid.uuid4())[:8]\n",
    "        query_type = self._detect_type(query_text)\n",
    "        domain = self._detect_domain(query_text)\n",
    "        \n",
    "        return Query(\n",
    "            id=query_id,\n",
    "            text=query_text,\n",
    "            query_type=query_type,\n",
    "            domain=domain\n",
    "        )\n",
    "    \n",
    "    def _detect_type(self, text: str) -> QueryType:\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for query_type, patterns in self.type_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    return query_type\n",
    "        \n",
    "        return QueryType.FACTUAL\n",
    "    \n",
    "    def _detect_domain(self, text: str) -> Domain:\n",
    "        text_lower = text.lower()\n",
    "        domain_scores = {}\n",
    "        \n",
    "        for domain, keywords in self.domain_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword.lower() in text_lower)\n",
    "            domain_scores[domain] = score\n",
    "        \n",
    "        if max(domain_scores.values()) > 0:\n",
    "            return max(domain_scores, key=domain_scores.get)\n",
    "        return Domain.GENERAL\n",
    "\n",
    "# Test query module\n",
    "query_module = QueryModule()\n",
    "test_query = query_module.process(\"What is cloud computing?\")\n",
    "print(f\"üîç Test query processed:\")\n",
    "print(f\"   Text: {test_query.text}\")\n",
    "print(f\"   Type: {test_query.query_type.value}\")\n",
    "print(f\"   Domain: {test_query.domain.value}\")\n",
    "print(\"‚úÖ Query Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Multi-Strategy Retrieval Module\n",
    "\n",
    "Flexible retrieval with multiple strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Retrieval module initialized\n",
      "üìö Indexing 5 documents...\n",
      "‚úÖ Documents indexed successfully!\n",
      "‚úÖ Retrieval Module ready!\n"
     ]
    }
   ],
   "source": [
    "class RetrievalModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"RetrievalModule\")\n",
    "        \n",
    "        # Initialize components\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.documents = []\n",
    "        self.semantic_index = None\n",
    "        self.bm25_index = None\n",
    "        \n",
    "        print(\"üîé Retrieval module initialized\")\n",
    "    \n",
    "    def index_documents(self, documents: List[Dict]):\n",
    "        print(f\"üìö Indexing {len(documents)} documents...\")\n",
    "        \n",
    "        # Convert to Document objects\n",
    "        self.documents = [\n",
    "            Document(\n",
    "                id=doc['id'],\n",
    "                title=doc['title'],\n",
    "                content=doc['content'],\n",
    "                domain=Domain(doc['domain']),\n",
    "                keywords=doc.get('keywords', [])\n",
    "            )\n",
    "            for doc in documents\n",
    "        ]\n",
    "        \n",
    "        # Build semantic index\n",
    "        self._build_semantic_index()\n",
    "        \n",
    "        # Build keyword index\n",
    "        self._build_keyword_index()\n",
    "        \n",
    "        print(\"‚úÖ Documents indexed successfully!\")\n",
    "    \n",
    "    def _build_semantic_index(self):\n",
    "        doc_texts = [f\"{doc.title} {doc.content}\" for doc in self.documents]\n",
    "        embeddings = self.embedding_model.encode(doc_texts)\n",
    "        \n",
    "        # Store embeddings\n",
    "        for doc, embedding in zip(self.documents, embeddings):\n",
    "            doc.embedding = embedding\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.semantic_index = faiss.IndexFlatIP(dimension)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.semantic_index.add(embeddings.astype('float32'))\n",
    "    \n",
    "    def _build_keyword_index(self):\n",
    "        doc_texts = [f\"{doc.title} {doc.content}\" for doc in self.documents]\n",
    "        tokenized_docs = [text.lower().split() for text in doc_texts]\n",
    "        self.bm25_index = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    def process(self, query: Query, strategy: RetrievalStrategy = RetrievalStrategy.HYBRID, top_k: int = 5) -> List[RetrievalResult]:\n",
    "        self.update_stats()\n",
    "        \n",
    "        if strategy == RetrievalStrategy.SEMANTIC:\n",
    "            return self._semantic_search(query, top_k)\n",
    "        elif strategy == RetrievalStrategy.KEYWORD:\n",
    "            return self._keyword_search(query, top_k)\n",
    "        else:  # HYBRID\n",
    "            return self._hybrid_search(query, top_k)\n",
    "    \n",
    "    def _semantic_search(self, query: Query, top_k: int) -> List[RetrievalResult]:\n",
    "        query_embedding = self.embedding_model.encode([query.text])\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        scores, indices = self.semantic_index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            results.append(RetrievalResult(\n",
    "                document=self.documents[idx],\n",
    "                score=float(score),\n",
    "                rank=i + 1,\n",
    "                strategy_used=RetrievalStrategy.SEMANTIC\n",
    "            ))\n",
    "        return results\n",
    "    \n",
    "    def _keyword_search(self, query: Query, top_k: int) -> List[RetrievalResult]:\n",
    "        query_tokens = query.text.lower().split()\n",
    "        scores = self.bm25_index.get_scores(query_tokens)\n",
    "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append(RetrievalResult(\n",
    "                document=self.documents[idx],\n",
    "                score=float(scores[idx]),\n",
    "                rank=i + 1,\n",
    "                strategy_used=RetrievalStrategy.KEYWORD\n",
    "            ))\n",
    "        return results\n",
    "    \n",
    "    def _hybrid_search(self, query: Query, top_k: int) -> List[RetrievalResult]:\n",
    "        # Get results from both strategies\n",
    "        semantic_results = self._semantic_search(query, top_k * 2)\n",
    "        keyword_results = self._keyword_search(query, top_k * 2)\n",
    "        \n",
    "        # Normalize scores\n",
    "        self._normalize_scores(semantic_results)\n",
    "        self._normalize_scores(keyword_results)\n",
    "        \n",
    "        # Combine with weights\n",
    "        combined_scores = {}\n",
    "        semantic_weight = 0.7\n",
    "        keyword_weight = 0.3\n",
    "        \n",
    "        for result in semantic_results:\n",
    "            doc_id = result.document.id\n",
    "            combined_scores[doc_id] = {\n",
    "                'document': result.document,\n",
    "                'semantic_score': result.score,\n",
    "                'keyword_score': 0.0\n",
    "            }\n",
    "        \n",
    "        for result in keyword_results:\n",
    "            doc_id = result.document.id\n",
    "            if doc_id in combined_scores:\n",
    "                combined_scores[doc_id]['keyword_score'] = result.score\n",
    "            else:\n",
    "                combined_scores[doc_id] = {\n",
    "                    'document': result.document,\n",
    "                    'semantic_score': 0.0,\n",
    "                    'keyword_score': result.score\n",
    "                }\n",
    "        \n",
    "        # Calculate final scores\n",
    "        final_results = []\n",
    "        for doc_id, scores in combined_scores.items():\n",
    "            final_score = (semantic_weight * scores['semantic_score'] + \n",
    "                          keyword_weight * scores['keyword_score'])\n",
    "            \n",
    "            final_results.append(RetrievalResult(\n",
    "                document=scores['document'],\n",
    "                score=final_score,\n",
    "                rank=0,\n",
    "                strategy_used=RetrievalStrategy.HYBRID\n",
    "            ))\n",
    "        \n",
    "        # Sort and assign ranks\n",
    "        final_results.sort(key=lambda x: x.score, reverse=True)\n",
    "        for i, result in enumerate(final_results[:top_k]):\n",
    "            result.rank = i + 1\n",
    "        \n",
    "        return final_results[:top_k]\n",
    "    \n",
    "    def _normalize_scores(self, results: List[RetrievalResult]):\n",
    "        if not results:\n",
    "            return\n",
    "        \n",
    "        scores = [result.score for result in results]\n",
    "        min_score, max_score = min(scores), max(scores)\n",
    "        \n",
    "        if max_score > min_score:\n",
    "            for result in results:\n",
    "                result.score = (result.score - min_score) / (max_score - min_score)\n",
    "\n",
    "# Initialize retrieval module\n",
    "retrieval_module = RetrievalModule()\n",
    "retrieval_module.index_documents(knowledge_base)\n",
    "\n",
    "print(\"‚úÖ Retrieval Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Adaptive Generation Module\n",
    "\n",
    "Context-aware answer generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Gemini API configured\n",
      "‚úÖ Generation Module ready!\n"
     ]
    }
   ],
   "source": [
    "class GenerationModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"GenerationModule\")\n",
    "        \n",
    "        # Try to initialize Gemini\n",
    "        api_key = os.getenv('GEMINI_API_KEY')\n",
    "        if api_key:\n",
    "            try:\n",
    "                genai.configure(api_key=api_key)\n",
    "                self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "                self.has_llm = True\n",
    "                print(\"ü§ñ Gemini API configured\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Gemini error: {e}\")\n",
    "                self.has_llm = False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No Gemini API key. Using template generation.\")\n",
    "            self.has_llm = False\n",
    "    \n",
    "    def process(self, query: Query, retrieved_docs: List[RetrievalResult]) -> Tuple[str, float]:\n",
    "        self.update_stats()\n",
    "        \n",
    "        if self.has_llm:\n",
    "            return self._generate_with_llm(query, retrieved_docs)\n",
    "        else:\n",
    "            return self._generate_with_template(query, retrieved_docs)\n",
    "    \n",
    "    def _generate_with_llm(self, query: Query, retrieved_docs: List[RetrievalResult]) -> Tuple[str, float]:\n",
    "        # Prepare context\n",
    "        context_parts = []\n",
    "        for result in retrieved_docs:\n",
    "            doc = result.document\n",
    "            context_parts.append(f\"Title: {doc.title}\\nContent: {doc.content}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Create prompt based on query type\n",
    "        if query.query_type == QueryType.COMPARATIVE:\n",
    "            instruction = \"Compare and contrast the concepts mentioned in the context.\"\n",
    "        elif query.query_type == QueryType.PROCEDURAL:\n",
    "            instruction = \"Provide step-by-step guidance based on the context.\"\n",
    "        elif query.query_type == QueryType.ANALYTICAL:\n",
    "            instruction = \"Provide a detailed analysis based on the context.\"\n",
    "        else:\n",
    "            instruction = \"Provide a clear, informative answer based on the context.\"\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert assistant specializing in {query.domain.value}. \n",
    "Use the provided context to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query.text}\n",
    "Query Type: {query.query_type.value}\n",
    "\n",
    "{instruction}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text, 0.9\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\", 0.0\n",
    "    \n",
    "    def _generate_with_template(self, query: Query, retrieved_docs: List[RetrievalResult]) -> Tuple[str, float]:\n",
    "        if not retrieved_docs:\n",
    "            return \"I couldn't find relevant information to answer your question.\", 0.1\n",
    "        \n",
    "        # Create template-based response\n",
    "        if query.query_type == QueryType.COMPARATIVE:\n",
    "            answer = f\"Comparing the concepts related to '{query.text}':\\n\\n\"\n",
    "            for i, result in enumerate(retrieved_docs[:2], 1):\n",
    "                doc = result.document\n",
    "                answer += f\"{i}. **{doc.title}**: {doc.content[:200]}...\\n\\n\"\n",
    "        else:\n",
    "            top_doc = retrieved_docs[0].document\n",
    "            answer = f\"Based on the available information about {query.domain.value}, \"\n",
    "            answer += f\"here's what I found about '{query.text}':\\n\\n\"\n",
    "            answer += f\"**{top_doc.title}**: {top_doc.content}\"\n",
    "            \n",
    "            if len(retrieved_docs) > 1:\n",
    "                answer += f\"\\n\\nAdditional relevant information from {len(retrieved_docs)-1} other sources is also available.\"\n",
    "        \n",
    "        confidence = min(0.8, len(retrieved_docs) / 3.0)\n",
    "        return answer, confidence\n",
    "\n",
    "# Initialize generation module\n",
    "generation_module = GenerationModule()\n",
    "print(\"‚úÖ Generation Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Memory Module\n",
    "\n",
    "Session and user context management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory Module ready!\n"
     ]
    }
   ],
   "source": [
    "class MemoryModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"MemoryModule\")\n",
    "        self.user_sessions = {}\n",
    "        self.query_history = []\n",
    "        self.max_history = 100\n",
    "    \n",
    "    def process(self, query: Query, response: ModularResponse):\n",
    "        self.update_stats()\n",
    "        \n",
    "        # Store interaction\n",
    "        interaction = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'query': query.text,\n",
    "            'query_type': query.query_type.value,\n",
    "            'domain': query.domain.value,\n",
    "            'confidence': response.confidence_score,\n",
    "            'processing_time': response.processing_time\n",
    "        }\n",
    "        \n",
    "        self.query_history.append(interaction)\n",
    "        \n",
    "        # Limit history size\n",
    "        if len(self.query_history) > self.max_history:\n",
    "            self.query_history = self.query_history[-self.max_history:]\n",
    "        \n",
    "        # Update user session if available\n",
    "        if query.user_id:\n",
    "            if query.user_id not in self.user_sessions:\n",
    "                self.user_sessions[query.user_id] = {\n",
    "                    'queries': [],\n",
    "                    'preferred_domains': {},\n",
    "                    'last_active': datetime.now()\n",
    "                }\n",
    "            \n",
    "            session = self.user_sessions[query.user_id]\n",
    "            session['queries'].append(interaction)\n",
    "            session['last_active'] = datetime.now()\n",
    "            \n",
    "            # Update domain preferences\n",
    "            domain = query.domain.value\n",
    "            if domain not in session['preferred_domains']:\n",
    "                session['preferred_domains'][domain] = 0\n",
    "            session['preferred_domains'][domain] += 1\n",
    "    \n",
    "    def get_user_context(self, user_id: str) -> Dict:\n",
    "        if user_id in self.user_sessions:\n",
    "            return self.user_sessions[user_id]\n",
    "        return {}\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        return {\n",
    "            'total_interactions': len(self.query_history),\n",
    "            'active_users': len(self.user_sessions),\n",
    "            'avg_confidence': np.mean([h['confidence'] for h in self.query_history]) if self.query_history else 0\n",
    "        }\n",
    "\n",
    "# Initialize memory module\n",
    "memory_module = MemoryModule()\n",
    "print(\"‚úÖ Memory Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö¶ Router Module\n",
    "\n",
    "Intelligent routing and pipeline orchestration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Router Module ready!\n"
     ]
    }
   ],
   "source": [
    "class RouterModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"RouterModule\")\n",
    "        \n",
    "        # Routing strategies based on query complexity\n",
    "        self.routing_strategies = {\n",
    "            'simple': {\n",
    "                'retrieval_strategy': RetrievalStrategy.SEMANTIC,\n",
    "                'max_docs': 3,\n",
    "                'pipeline': ['query', 'retrieval', 'generation']\n",
    "            },\n",
    "            'medium': {\n",
    "                'retrieval_strategy': RetrievalStrategy.HYBRID,\n",
    "                'max_docs': 5,\n",
    "                'pipeline': ['query', 'retrieval', 'generation', 'memory']\n",
    "            },\n",
    "            'complex': {\n",
    "                'retrieval_strategy': RetrievalStrategy.HYBRID,\n",
    "                'max_docs': 7,\n",
    "                'pipeline': ['query', 'retrieval', 'generation', 'memory']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def process(self, query: Query) -> Dict:\n",
    "        self.update_stats()\n",
    "        \n",
    "        # Determine complexity\n",
    "        complexity = self._assess_complexity(query)\n",
    "        \n",
    "        # Get routing strategy\n",
    "        strategy = self.routing_strategies[complexity]\n",
    "        \n",
    "        return {\n",
    "            'complexity': complexity,\n",
    "            'retrieval_strategy': strategy['retrieval_strategy'],\n",
    "            'max_docs': strategy['max_docs'],\n",
    "            'pipeline': strategy['pipeline'],\n",
    "            'estimated_time': self._estimate_time(complexity)\n",
    "        }\n",
    "    \n",
    "    def _assess_complexity(self, query: Query) -> str:\n",
    "        complexity_score = 0\n",
    "        \n",
    "        # Length-based complexity\n",
    "        word_count = len(query.text.split())\n",
    "        if word_count > 15:\n",
    "            complexity_score += 2\n",
    "        elif word_count > 8:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Query type complexity\n",
    "        if query.query_type in [QueryType.ANALYTICAL, QueryType.COMPARATIVE]:\n",
    "            complexity_score += 2\n",
    "        elif query.query_type == QueryType.PROCEDURAL:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Domain complexity\n",
    "        if query.domain in [Domain.SCIENCE, Domain.HEALTHCARE]:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Classify\n",
    "        if complexity_score <= 1:\n",
    "            return 'simple'\n",
    "        elif complexity_score <= 3:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'complex'\n",
    "    \n",
    "    def _estimate_time(self, complexity: str) -> float:\n",
    "        time_estimates = {\n",
    "            'simple': 1.0,\n",
    "            'medium': 2.5,\n",
    "            'complex': 4.0\n",
    "        }\n",
    "        return time_estimates.get(complexity, 2.0)\n",
    "\n",
    "# Initialize router module\n",
    "router_module = RouterModule()\n",
    "print(\"‚úÖ Router Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Complete Modular RAG System\n",
    "\n",
    "Integrate all modules into the complete system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Initializing Modular RAG System...\n",
      "‚úÖ Modular RAG System initialized!\n",
      "üîß Active modules: ['query', 'retrieval', 'generation', 'memory', 'router']\n",
      "\n",
      "üöÄ Complete Modular RAG System ready!\n"
     ]
    }
   ],
   "source": [
    "class ModularRAGSystem:\n",
    "    def __init__(self):\n",
    "        print(\"üß© Initializing Modular RAG System...\")\n",
    "        \n",
    "        # Initialize all modules\n",
    "        self.modules = {\n",
    "            'query': query_module,\n",
    "            'retrieval': retrieval_module,\n",
    "            'generation': generation_module,\n",
    "            'memory': memory_module,\n",
    "            'router': router_module\n",
    "        }\n",
    "        \n",
    "        # System metrics\n",
    "        self.total_queries = 0\n",
    "        self.successful_queries = 0\n",
    "        self.avg_processing_time = 0.0\n",
    "        \n",
    "        print(\"‚úÖ Modular RAG System initialized!\")\n",
    "        print(f\"üîß Active modules: {list(self.modules.keys())}\")\n",
    "    \n",
    "    def process_query(self, query_text: str, user_id: str = None) -> ModularResponse:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\nüîç Processing: '{query_text}'\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Step 1: Query processing\n",
    "            print(\"üìù Step 1: Query processing...\")\n",
    "            query = self.modules['query'].process(query_text)\n",
    "            query.user_id = user_id\n",
    "            \n",
    "            print(f\"   Type: {query.query_type.value}, Domain: {query.domain.value}\")\n",
    "            \n",
    "            # Step 2: Routing\n",
    "            print(\"üö¶ Step 2: Intelligent routing...\")\n",
    "            routing_plan = self.modules['router'].process(query)\n",
    "            \n",
    "            print(f\"   Complexity: {routing_plan['complexity']}\")\n",
    "            print(f\"   Strategy: {routing_plan['retrieval_strategy'].value}\")\n",
    "            print(f\"   Est. time: {routing_plan['estimated_time']:.1f}s\")\n",
    "            \n",
    "            # Step 3: Retrieval\n",
    "            print(\"üîç Step 3: Document retrieval...\")\n",
    "            retrieved_docs = self.modules['retrieval'].process(\n",
    "                query, \n",
    "                routing_plan['retrieval_strategy'], \n",
    "                routing_plan['max_docs']\n",
    "            )\n",
    "            \n",
    "            print(f\"   Retrieved {len(retrieved_docs)} documents\")\n",
    "            for i, doc in enumerate(retrieved_docs[:3], 1):\n",
    "                print(f\"   {i}. {doc.document.title} (Score: {doc.score:.3f})\")\n",
    "            \n",
    "            # Step 4: Generation\n",
    "            print(\"ü§ñ Step 4: Answer generation...\")\n",
    "            generated_answer, confidence = self.modules['generation'].process(query, retrieved_docs)\n",
    "            \n",
    "            print(f\"   Generated answer (Confidence: {confidence:.2f})\")\n",
    "            \n",
    "            # Create response\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            response = ModularResponse(\n",
    "                query=query,\n",
    "                retrieved_documents=retrieved_docs,\n",
    "                generated_answer=generated_answer,\n",
    "                confidence_score=confidence,\n",
    "                processing_pipeline=routing_plan['pipeline'],\n",
    "                processing_time=processing_time\n",
    "            )\n",
    "            \n",
    "            # Step 5: Memory update\n",
    "            print(\"üíæ Step 5: Memory update...\")\n",
    "            self.modules['memory'].process(query, response)\n",
    "            \n",
    "            # Update system metrics\n",
    "            self._update_metrics(response)\n",
    "            \n",
    "            print(f\"\\n‚úÖ Query processed in {processing_time:.2f}s\")\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            # Return error response\n",
    "            error_query = Query(\"error\", query_text, QueryType.FACTUAL, Domain.GENERAL, user_id)\n",
    "            return ModularResponse(\n",
    "                query=error_query,\n",
    "                retrieved_documents=[],\n",
    "                generated_answer=f\"Sorry, I encountered an error: {str(e)}\",\n",
    "                confidence_score=0.0,\n",
    "                processing_pipeline=['error'],\n",
    "                processing_time=time.time() - start_time\n",
    "            )\n",
    "    \n",
    "    def _update_metrics(self, response: ModularResponse):\n",
    "        self.total_queries += 1\n",
    "        if response.confidence_score > 0.5:\n",
    "            self.successful_queries += 1\n",
    "        \n",
    "        # Update running average\n",
    "        self.avg_processing_time = ((self.avg_processing_time * (self.total_queries - 1)) + \n",
    "                                   response.processing_time) / self.total_queries\n",
    "    \n",
    "    def get_system_status(self) -> Dict:\n",
    "        module_stats = {name: module.get_info() for name, module in self.modules.items()}\n",
    "        \n",
    "        return {\n",
    "            'total_queries': self.total_queries,\n",
    "            'successful_queries': self.successful_queries,\n",
    "            'success_rate': (self.successful_queries / max(self.total_queries, 1)) * 100,\n",
    "            'avg_processing_time': self.avg_processing_time,\n",
    "            'module_stats': module_stats,\n",
    "            'memory_stats': self.modules['memory'].get_statistics()\n",
    "        }\n",
    "\n",
    "# Initialize complete system\n",
    "modular_rag = ModularRAGSystem()\n",
    "print(\"\\nüöÄ Complete Modular RAG System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Comprehensive Testing\n",
    "\n",
    "Test the system with different query types and complexities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™ MODULAR RAG TEST SUITE üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™\n",
      "\n",
      "============================================================\n",
      "üî¨ TEST CASE 1: Simple Factual Query\n",
      "‚ùì Query: 'What is cloud computing?'\n",
      "============================================================\n",
      "\n",
      "üîç Processing: 'What is cloud computing?'\n",
      "==================================================\n",
      "üìù Step 1: Query processing...\n",
      "   Type: factual, Domain: technology\n",
      "üö¶ Step 2: Intelligent routing...\n",
      "   Complexity: simple\n",
      "   Strategy: semantic\n",
      "   Est. time: 1.0s\n",
      "üîç Step 3: Document retrieval...\n",
      "   Retrieved 3 documents\n",
      "   1. Cloud Computing Fundamentals (Score: 0.754)\n",
      "   2. Artificial Intelligence and Machine Learning (Score: 0.325)\n",
      "   3. Quantum Computing Principles (Score: 0.277)\n",
      "ü§ñ Step 4: Answer generation...\n",
      "   Generated answer (Confidence: 0.90)\n",
      "üíæ Step 5: Memory update...\n",
      "\n",
      "‚úÖ Query processed in 2.56s\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Cloud computing delivers computing services‚Äîincluding servers, storage, databases, networking, software, analytics, and intelligence‚Äîover the internet.  The main service models are Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS).  Major providers are AWS, Microsoft Azure, and Google Cloud Platform.  Benefits include reduced costs, scalability, reliability, and global reach.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Processing Time: 2.56s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Pipeline: query ‚Üí retrieval ‚Üí generation\n",
      "   ‚Ä¢ Documents Used: 3\n",
      "\n",
      "üìö **TOP SOURCES:**\n",
      "   1. üìÑ Cloud Computing Fundamentals (Score: 0.754, Domain: technology)\n",
      "   2. üìÑ Artificial Intelligence and Machine Learning (Score: 0.325, Domain: technology)\n",
      "   3. üìÑ Quantum Computing Principles (Score: 0.277, Domain: science)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 1 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ TEST CASE 2: Comparative Query\n",
      "‚ùì Query: 'Compare artificial intelligence and machine learning'\n",
      "============================================================\n",
      "\n",
      "üîç Processing: 'Compare artificial intelligence and machine learning'\n",
      "==================================================\n",
      "üìù Step 1: Query processing...\n",
      "   Type: comparative, Domain: general\n",
      "üö¶ Step 2: Intelligent routing...\n",
      "   Complexity: medium\n",
      "   Strategy: hybrid\n",
      "   Est. time: 2.5s\n",
      "üîç Step 3: Document retrieval...\n",
      "   Retrieved 5 documents\n",
      "   1. Artificial Intelligence and Machine Learning (Score: 1.000)\n",
      "   2. Cloud Computing Fundamentals (Score: 0.719)\n",
      "   3. Quantum Computing Principles (Score: 0.700)\n",
      "ü§ñ Step 4: Answer generation...\n",
      "   Generated answer (Confidence: 0.90)\n",
      "üíæ Step 5: Memory update...\n",
      "\n",
      "‚úÖ Query processed in 1.47s\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Artificial Intelligence (AI) is the broad concept of machines mimicking human intelligence, encompassing programming machines to think and learn.  Machine Learning (ML) is a *subset* of AI.  The key difference is that AI aims to create systems that exhibit intelligent behavior, while ML focuses specifically on enabling systems to learn from data without explicit programming.  AI can involve rule-based systems or other approaches not based on learning from data, while ML fundamentally relies on algorithms that learn patterns from data to improve performance on a specific task.  Deep learning is a specialized type of ML using complex neural networks.  Both AI and ML are used in applications like computer vision, natural language processing, and recommendation systems.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Processing Time: 1.47s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Pipeline: query ‚Üí retrieval ‚Üí generation ‚Üí memory\n",
      "   ‚Ä¢ Documents Used: 5\n",
      "\n",
      "üìö **TOP SOURCES:**\n",
      "   1. üìÑ Artificial Intelligence and Machine Learning (Score: 1.000, Domain: technology)\n",
      "   2. üìÑ Cloud Computing Fundamentals (Score: 0.719, Domain: technology)\n",
      "   3. üìÑ Quantum Computing Principles (Score: 0.700, Domain: science)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 2 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ TEST CASE 3: Complex Analytical Query\n",
      "‚ùì Query: 'Analyze the impact of quantum computing on digital transformation strategies in healthcare'\n",
      "============================================================\n",
      "\n",
      "üîç Processing: 'Analyze the impact of quantum computing on digital transformation strategies in healthcare'\n",
      "==================================================\n",
      "üìù Step 1: Query processing...\n",
      "   Type: analytical, Domain: technology\n",
      "üö¶ Step 2: Intelligent routing...\n",
      "   Complexity: medium\n",
      "   Strategy: hybrid\n",
      "   Est. time: 2.5s\n",
      "üîç Step 3: Document retrieval...\n",
      "   Retrieved 5 documents\n",
      "   1. Quantum Computing Principles (Score: 0.961)\n",
      "   2. Cloud Computing Fundamentals (Score: 0.813)\n",
      "   3. Artificial Intelligence and Machine Learning (Score: 0.794)\n",
      "ü§ñ Step 4: Answer generation...\n",
      "   Generated answer (Confidence: 0.90)\n",
      "üíæ Step 5: Memory update...\n",
      "\n",
      "‚úÖ Query processed in 4.04s\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Based on the provided context, the impact of quantum computing on digital transformation strategies in healthcare, specifically within the realm of telemedicine and digital health, is largely speculative but holds significant potential.  The context doesn't directly link quantum computing to digital transformation in healthcare, but we can infer potential impacts by combining information from the \"Quantum Computing Principles\" and \"Telemedicine and Digital Health\" sections.\n",
      "\n",
      "**Potential Impacts:**\n",
      "\n",
      "* **Drug Discovery and Development:** Quantum computing's ability to simulate molecular interactions could revolutionize drug discovery for various diseases. This directly impacts digital health by accelerating the development of new digital therapeutics and personalized medicine approaches. Faster drug discovery translates to quicker integration of new treatments into telemedicine platforms and mobile health applications.\n",
      "\n",
      "* **Data Analytics and Precision Medicine:** Telemedicine generates vast amounts of patient data. Quantum computing's superior processing power could enable more sophisticated analysis of this data, leading to improved diagnostic accuracy, personalized treatment plans, and proactive interventions. This enhances the effectiveness of remote patient monitoring and predictive analytics within digital health initiatives.\n",
      "\n",
      "* **Enhanced Security and Privacy:**  Quantum computing poses a threat to current encryption methods, but it also offers the potential for more secure quantum-resistant cryptography. This is crucial for protecting sensitive patient data exchanged during telemedicine consultations and stored within digital health platforms.  Improved security is essential for successful digital transformation in a privacy-conscious healthcare environment.\n",
      "\n",
      "* **Optimization of Healthcare Systems:** Quantum computing's optimization capabilities could improve resource allocation in healthcare, leading to more efficient scheduling of telemedicine appointments, optimized deployment of healthcare professionals, and better management of remote patient monitoring systems. This contributes to cost reduction and improved access to care, core tenets of successful digital transformation.\n",
      "\n",
      "\n",
      "**Limitations and Challenges:**\n",
      "\n",
      "The context lacks specifics on the current state of quantum computing technology.  The realization of these potential impacts depends on overcoming significant technological hurdles:\n",
      "\n",
      "* **Quantum Computer Availability and Scalability:** Currently, practical, large-scale quantum computers are not readily available.  Their development and widespread accessibility are crucial before widespread impact can be seen.\n",
      "* **Algorithm Development:**  Developing quantum algorithms specifically tailored for healthcare applications requires significant research and development.\n",
      "* **Integration with Existing Systems:** Integrating quantum computing capabilities into existing telemedicine and digital health infrastructure presents a significant technological challenge.\n",
      "\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "While the direct impact of quantum computing on current digital transformation strategies in healthcare is limited by the technology's nascent stage, its long-term potential is considerable.  Quantum computing's ability to accelerate drug discovery, enhance data analytics, improve security, and optimize resource allocation positions it as a transformative technology for the future of digital health. However, realizing this potential necessitates continued research, development, and overcoming significant technological challenges.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Processing Time: 4.04s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Pipeline: query ‚Üí retrieval ‚Üí generation ‚Üí memory\n",
      "   ‚Ä¢ Documents Used: 5\n",
      "\n",
      "üìö **TOP SOURCES:**\n",
      "   1. üìÑ Quantum Computing Principles (Score: 0.961, Domain: science)\n",
      "   2. üìÑ Cloud Computing Fundamentals (Score: 0.813, Domain: technology)\n",
      "   3. üìÑ Artificial Intelligence and Machine Learning (Score: 0.794, Domain: technology)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 3 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ TEST CASE 4: Procedural Query\n",
      "‚ùì Query: 'How to implement telemedicine in healthcare systems?'\n",
      "============================================================\n",
      "\n",
      "üîç Processing: 'How to implement telemedicine in healthcare systems?'\n",
      "==================================================\n",
      "üìù Step 1: Query processing...\n",
      "   Type: procedural, Domain: healthcare\n",
      "üö¶ Step 2: Intelligent routing...\n",
      "   Complexity: medium\n",
      "   Strategy: hybrid\n",
      "   Est. time: 2.5s\n",
      "üîç Step 3: Document retrieval...\n",
      "   Retrieved 5 documents\n",
      "   1. Telemedicine and Digital Health (Score: 1.000)\n",
      "   2. Artificial Intelligence and Machine Learning (Score: 0.789)\n",
      "   3. Quantum Computing Principles (Score: 0.781)\n",
      "ü§ñ Step 4: Answer generation...\n",
      "   Generated answer (Confidence: 0.90)\n",
      "üíæ Step 5: Memory update...\n",
      "\n",
      "‚úÖ Query processed in 4.99s\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Implementing telemedicine in a healthcare system requires a phased approach and careful planning.  The provided text focuses on *what* telemedicine is, not the specifics of *how* to implement it, so this answer will provide a generalized, expert-informed approach.  A true implementation plan would require much more detailed information specific to the healthcare system's needs and resources.\n",
      "\n",
      "\n",
      "**Phase 1: Assessment and Planning**\n",
      "\n",
      "1. **Needs Assessment:** Identify specific needs and goals. Which patient populations would benefit most? What types of services are best suited for telemedicine (e.g., follow-up appointments, chronic disease management, mental health consultations)?  Analyze existing infrastructure and identify gaps.\n",
      "\n",
      "2. **Technology Selection:** Choose appropriate technology based on needs and budget. This includes hardware (computers, cameras, internet connectivity for both providers and patients), software (video conferencing platforms, electronic health record (EHR) integration, remote patient monitoring devices), and cybersecurity measures. Consider HIPAA compliance and data privacy from the outset.\n",
      "\n",
      "3. **Workflow Design:**  Map out the entire patient journey using telemedicine, from scheduling to follow-up. Define roles and responsibilities for staff involved in telemedicine delivery.  Ensure seamless integration with existing workflows and EHR systems.\n",
      "\n",
      "4. **Policy and Procedure Development:** Create clear policies and procedures covering telehealth services, including patient consent, data security, billing and reimbursement, and provider credentialing for telehealth.  Consider liability and malpractice implications.\n",
      "\n",
      "5. **Staff Training:**  Train healthcare professionals and staff on the chosen technology, workflows, and new policies and procedures. This is crucial for successful implementation.  Training should include technical skills as well as clinical best practices for virtual care.\n",
      "\n",
      "\n",
      "**Phase 2: Implementation and Rollout**\n",
      "\n",
      "6. **Pilot Program:** Begin with a pilot program to test the chosen technology and workflows on a small scale. This allows for identification and correction of any issues before a full-scale rollout.  Gather feedback from both providers and patients.\n",
      "\n",
      "7. **System Integration:** Integrate the telemedicine platform with existing EHR systems to ensure seamless data flow and avoid data duplication or inconsistencies.\n",
      "\n",
      "8. **Marketing and Outreach:**  Educate patients about the availability and benefits of telemedicine services.  Provide clear instructions on how to access and use the technology.\n",
      "\n",
      "9. **Monitoring and Evaluation:** Continuously monitor the effectiveness of the telemedicine program by tracking key performance indicators (KPIs) such as patient satisfaction, cost savings, and clinical outcomes.  Regularly evaluate and adjust the program based on the data collected.\n",
      "\n",
      "\n",
      "**Phase 3: Optimization and Expansion**\n",
      "\n",
      "10. **Continuous Improvement:**  Use data from monitoring and evaluation to continuously improve the telemedicine program.  Address any challenges or issues that arise.\n",
      "\n",
      "11. **Expansion of Services:**  Gradually expand the range of services offered through telemedicine, based on success and patient demand. Consider incorporating remote patient monitoring and other digital health tools.\n",
      "\n",
      "12. **Integration of AI/ML:** Explore the potential of integrating AI and ML technologies to improve the efficiency and effectiveness of telemedicine. This might include using AI for automated appointment scheduling, patient triage, or clinical decision support.\n",
      "\n",
      "\n",
      "This process is iterative. Regular review and adaptation are essential for successful, long-term implementation of telemedicine in a healthcare system. Consulting with telemedicine experts and vendors is highly recommended throughout the process.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Processing Time: 4.99s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Pipeline: query ‚Üí retrieval ‚Üí generation ‚Üí memory\n",
      "   ‚Ä¢ Documents Used: 5\n",
      "\n",
      "üìö **TOP SOURCES:**\n",
      "   1. üìÑ Telemedicine and Digital Health (Score: 1.000, Domain: healthcare)\n",
      "   2. üìÑ Artificial Intelligence and Machine Learning (Score: 0.789, Domain: technology)\n",
      "   3. üìÑ Quantum Computing Principles (Score: 0.781, Domain: science)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 4 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üìä MODULAR RAG TEST REPORT\n",
      "============================================================\n",
      "\n",
      "üéØ **OVERALL PERFORMANCE:**\n",
      "   ‚Ä¢ Tests Passed: 4/4 (100.0%)\n",
      "   ‚Ä¢ Total Time: 13.06s\n",
      "   ‚Ä¢ Avg Time per Query: 3.26s\n",
      "\n",
      "üìà **QUALITY METRICS:**\n",
      "   ‚Ä¢ Average Confidence: 0.900\n",
      "   ‚Ä¢ Average Processing Time: 3.264s\n",
      "\n",
      "üèÜ **SYSTEM STATUS:**\n",
      "   ‚Ä¢ Total System Queries: 4\n",
      "   ‚Ä¢ System Success Rate: 100.0%\n",
      "   ‚Ä¢ Active Users: 4\n",
      "\n",
      "üß© **MODULAR CAPABILITIES DEMONSTRATED:**\n",
      "   ‚úÖ Intelligent query understanding and classification\n",
      "   ‚úÖ Adaptive routing based on query complexity\n",
      "   ‚úÖ Multi-strategy retrieval (semantic, keyword, hybrid)\n",
      "   ‚úÖ Context-aware answer generation\n",
      "   ‚úÖ User session and memory management\n",
      "   ‚úÖ Comprehensive performance monitoring\n",
      "   ‚úÖ Modular architecture with independent components\n"
     ]
    }
   ],
   "source": [
    "def run_test_suite():\n",
    "    print(\"\\n\" + \"üß™\" * 20 + \" MODULAR RAG TEST SUITE \" + \"üß™\" * 20)\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Simple Factual Query\",\n",
    "            \"query\": \"What is cloud computing?\",\n",
    "            \"expected_complexity\": \"simple\",\n",
    "            \"user_id\": \"test_user_1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Comparative Query\",\n",
    "            \"query\": \"Compare artificial intelligence and machine learning\",\n",
    "            \"expected_complexity\": \"medium\",\n",
    "            \"user_id\": \"test_user_2\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Complex Analytical Query\",\n",
    "            \"query\": \"Analyze the impact of quantum computing on digital transformation strategies in healthcare\",\n",
    "            \"expected_complexity\": \"complex\",\n",
    "            \"user_id\": \"test_user_3\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Procedural Query\",\n",
    "            \"query\": \"How to implement telemedicine in healthcare systems?\",\n",
    "            \"expected_complexity\": \"medium\",\n",
    "            \"user_id\": \"test_user_4\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"üî¨ TEST CASE {i}: {test_case['name']}\")\n",
    "        print(f\"‚ùì Query: '{test_case['query']}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            response = modular_rag.process_query(\n",
    "                test_case['query'], \n",
    "                test_case['user_id']\n",
    "            )\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\nüéØ **FINAL ANSWER:**\")\n",
    "            print(f\"   {response.generated_answer}\")\n",
    "            \n",
    "            print(f\"\\nüìä **METRICS:**\")\n",
    "            print(f\"   ‚Ä¢ Processing Time: {response.processing_time:.2f}s\")\n",
    "            print(f\"   ‚Ä¢ Confidence Score: {response.confidence_score:.2f}\")\n",
    "            print(f\"   ‚Ä¢ Pipeline: {' ‚Üí '.join(response.processing_pipeline)}\")\n",
    "            print(f\"   ‚Ä¢ Documents Used: {len(response.retrieved_documents)}\")\n",
    "            \n",
    "            print(f\"\\nüìö **TOP SOURCES:**\")\n",
    "            for j, result in enumerate(response.retrieved_documents[:3], 1):\n",
    "                doc = result.document\n",
    "                print(f\"   {j}. üìÑ {doc.title} (Score: {result.score:.3f}, Domain: {doc.domain.value})\")\n",
    "            \n",
    "            results.append({\n",
    "                'test_case': test_case['name'],\n",
    "                'success': True,\n",
    "                'processing_time': response.processing_time,\n",
    "                'confidence': response.confidence_score\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: {str(e)}\")\n",
    "            results.append({\n",
    "                'test_case': test_case['name'],\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "        \n",
    "        print(f\"\\n{'üî∏' * 30} END TEST CASE {i} {'üî∏' * 30}\")\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Generate test report\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä MODULAR RAG TEST REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    successful_tests = [r for r in results if r['success']]\n",
    "    \n",
    "    print(f\"\\nüéØ **OVERALL PERFORMANCE:**\")\n",
    "    print(f\"   ‚Ä¢ Tests Passed: {len(successful_tests)}/{len(results)} ({len(successful_tests)/len(results)*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Total Time: {total_time:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Avg Time per Query: {total_time/len(results):.2f}s\")\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_confidence = sum(r['confidence'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_processing_time = sum(r['processing_time'] for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        print(f\"\\nüìà **QUALITY METRICS:**\")\n",
    "        print(f\"   ‚Ä¢ Average Confidence: {avg_confidence:.3f}\")\n",
    "        print(f\"   ‚Ä¢ Average Processing Time: {avg_processing_time:.3f}s\")\n",
    "    \n",
    "    # System status\n",
    "    status = modular_rag.get_system_status()\n",
    "    print(f\"\\nüèÜ **SYSTEM STATUS:**\")\n",
    "    print(f\"   ‚Ä¢ Total System Queries: {status['total_queries']}\")\n",
    "    print(f\"   ‚Ä¢ System Success Rate: {status['success_rate']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Active Users: {status['memory_stats']['active_users']}\")\n",
    "    \n",
    "    print(f\"\\nüß© **MODULAR CAPABILITIES DEMONSTRATED:**\")\n",
    "    capabilities = [\n",
    "        \"‚úÖ Intelligent query understanding and classification\",\n",
    "        \"‚úÖ Adaptive routing based on query complexity\", \n",
    "        \"‚úÖ Multi-strategy retrieval (semantic, keyword, hybrid)\",\n",
    "        \"‚úÖ Context-aware answer generation\",\n",
    "        \"‚úÖ User session and memory management\",\n",
    "        \"‚úÖ Comprehensive performance monitoring\",\n",
    "        \"‚úÖ Modular architecture with independent components\"\n",
    "    ]\n",
    "    \n",
    "    for capability in capabilities:\n",
    "        print(f\"   {capability}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test suite\n",
    "test_results = run_test_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Demo\n",
    "\n",
    "Try the Modular RAG system interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_demo():\n",
    "    print(\"\\n\" + \"üéÆ\" * 20 + \" MODULAR RAG INTERACTIVE DEMO \" + \"üéÆ\" * 20)\n",
    "    print(\"üß© **MODULAR AI ASSISTANT**\")\n",
    "    print(\"üéÆ\" * 60)\n",
    "    print(\"Experience modular architecture! Each query is processed through\")\n",
    "    print(\"specialized modules that adapt to your question's complexity.\")\n",
    "    print(\"\\nType 'quit' to exit, 'status' for system info, 'help' for commands\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    demo_user = \"demo_user\"\n",
    "    query_count = 0\n",
    "    \n",
    "    example_queries = {\n",
    "        \"Simple\": [\n",
    "            \"What is AI?\",\n",
    "            \"Define cloud computing\",\n",
    "            \"What is telemedicine?\"\n",
    "        ],\n",
    "        \"Comparative\": [\n",
    "            \"Compare cloud computing with traditional computing\",\n",
    "            \"Difference between AI and machine learning\"\n",
    "        ],\n",
    "        \"Complex\": [\n",
    "            \"Analyze the impact of quantum computing on healthcare\",\n",
    "            \"How does digital transformation affect business strategy?\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nüéØ Your question: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"\\nüëã Thank you for exploring Modular RAG!\")\n",
    "                break\n",
    "            elif user_input.lower() == 'status':\n",
    "                status = modular_rag.get_system_status()\n",
    "                print(f\"\\nüìä **SYSTEM STATUS:**\")\n",
    "                print(f\"   ‚Ä¢ Total Queries: {status['total_queries']}\")\n",
    "                print(f\"   ‚Ä¢ Success Rate: {status['success_rate']:.1f}%\")\n",
    "                print(f\"   ‚Ä¢ Avg Processing Time: {status['avg_processing_time']:.2f}s\")\n",
    "                print(f\"   ‚Ä¢ Active Users: {status['memory_stats']['active_users']}\")\n",
    "                continue\n",
    "            elif user_input.lower() == 'help':\n",
    "                print(f\"\\nüí° **EXAMPLE QUERIES:**\")\n",
    "                for category, queries in example_queries.items():\n",
    "                    print(f\"\\nüî∏ **{category}:**\")\n",
    "                    for query in queries:\n",
    "                        print(f\"   ‚Ä¢ {query}\")\n",
    "                continue\n",
    "            elif not user_input:\n",
    "                print(\"Please enter a question or command.\")\n",
    "                continue\n",
    "            \n",
    "            query_count += 1\n",
    "            print(f\"\\nü§î Processing query #{query_count} with Modular RAG...\")\n",
    "            \n",
    "            response = modular_rag.process_query(user_input, demo_user)\n",
    "            \n",
    "            print(f\"\\nü§ñ **ANSWER:**\")\n",
    "            print(f\"   {response.generated_answer}\")\n",
    "            \n",
    "            print(f\"\\nüìä **ANALYSIS:**\")\n",
    "            print(f\"   ‚Ä¢ Query Type: {response.query.query_type.value}\")\n",
    "            print(f\"   ‚Ä¢ Domain: {response.query.domain.value}\")\n",
    "            print(f\"   ‚Ä¢ Confidence: {response.confidence_score:.2f}\")\n",
    "            print(f\"   ‚Ä¢ Processing Time: {response.processing_time:.2f}s\")\n",
    "            print(f\"   ‚Ä¢ Pipeline: {' ‚Üí '.join(response.processing_pipeline)}\")\n",
    "            \n",
    "            if response.retrieved_documents:\n",
    "                print(f\"\\nüìö **TOP SOURCES:**\")\n",
    "                for i, result in enumerate(response.retrieved_documents[:2], 1):\n",
    "                    doc = result.document\n",
    "                    print(f\"   {i}. {doc.title} (Score: {result.score:.2f})\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Demo interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "    \n",
    "    if query_count > 0:\n",
    "        print(f\"\\nüìà **SESSION SUMMARY:**\")\n",
    "        print(f\"   ‚Ä¢ Queries Processed: {query_count}\")\n",
    "        print(f\"   ‚Ä¢ User Profile Created: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ Memory Updated: ‚úÖ\")\n",
    "\n",
    "print(\"\\nüí° **To start interactive demo, uncomment and run the next cell**\")\n",
    "print(\"üéÆ Experience real-time modular processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to start interactive demo\n",
    "# interactive_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "Congratulations! You've built a complete Modular RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ MISSION ACCOMPLISHED üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ\n",
      "\n",
      "üèÜ **MODULAR RAG SYSTEM SUCCESSFULLY IMPLEMENTED!**\n",
      "======================================================================\n",
      "\n",
      "üß© **MODULAR COMPONENTS BUILT:**\n",
      "   üîç **QueryModule** - Intelligent query understanding and classification\n",
      "   üîé **RetrievalModule** - Multi-strategy document retrieval (semantic, keyword, hybrid)\n",
      "   ü§ñ **GenerationModule** - Adaptive answer generation with Gemini integration\n",
      "   üíæ **MemoryModule** - User session and interaction history management\n",
      "   üö¶ **RouterModule** - Intelligent pipeline orchestration and routing\n",
      "   üß© **ModularRAGSystem** - Complete integration with performance monitoring\n",
      "\n",
      "üöÄ **KEY INNOVATIONS:**\n",
      "   üéØ **Adaptive Processing** - Pipeline adapts to query complexity\n",
      "   üîß **Pluggable Architecture** - Easy to swap and extend components\n",
      "   üìä **Comprehensive Monitoring** - Performance tracking for each module\n",
      "   üß† **Context Awareness** - User preferences and conversation memory\n",
      "   ‚ö° **Intelligent Routing** - Optimal strategy selection for each query\n",
      "   üåç **Multi-Domain Support** - Specialized handling for different domains\n",
      "\n",
      "üìà **ADVANTAGES OVER BASIC RAG:**\n",
      "   üéØ **Higher Quality** - Specialized modules for different scenarios\n",
      "   ‚ö° **Better Performance** - Adaptive processing pipelines\n",
      "   üîß **Easier Maintenance** - Independent module updates\n",
      "   üìä **Better Observability** - Detailed monitoring and debugging\n",
      "   üîÑ **Greater Flexibility** - Mix and match components\n",
      "   üèóÔ∏è **Scalability** - Independent scaling of modules\n",
      "\n",
      "üîÆ **NEXT LEVEL ENHANCEMENTS:**\n",
      "   ü§ñ **Agentic Modules** - Add autonomous reasoning capabilities\n",
      "   üîÑ **Self-Improving System** - Modules that learn and adapt\n",
      "   üåê **Multi-Modal Support** - Text, image, audio integration\n",
      "   üìä **GraphRAG Integration** - Knowledge graph reasoning\n",
      "   üõ°Ô∏è **Advanced Safety** - Content filtering and bias detection\n",
      "   üè≠ **Production Deployment** - Kubernetes and cloud scaling\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modular_rag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müéâ\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Generate final summary\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mprint_final_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîß **QUICK START COMMANDS:**\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚Ä¢ Test query: modular_rag.process_query(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is AI?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mprint_final_summary\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menhancement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Final system status\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[43mmodular_rag\u001b[49m\u001b[38;5;241m.\u001b[39mget_system_status()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä **FINAL SYSTEM STATUS:**\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚Ä¢ Modules Active: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(modular_rag\u001b[38;5;241m.\u001b[39mmodules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modular_rag' is not defined"
     ]
    }
   ],
   "source": [
    "def print_final_summary():\n",
    "    print(\"\\n\" + \"üéâ\" * 25 + \" MISSION ACCOMPLISHED \" + \"üéâ\" * 25)\n",
    "    print(\"\\nüèÜ **MODULAR RAG SYSTEM SUCCESSFULLY IMPLEMENTED!**\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nüß© **MODULAR COMPONENTS BUILT:**\")\n",
    "    components = [\n",
    "        \"üîç **QueryModule** - Intelligent query understanding and classification\",\n",
    "        \"üîé **RetrievalModule** - Multi-strategy document retrieval (semantic, keyword, hybrid)\",\n",
    "        \"ü§ñ **GenerationModule** - Adaptive answer generation with Gemini integration\",\n",
    "        \"üíæ **MemoryModule** - User session and interaction history management\",\n",
    "        \"üö¶ **RouterModule** - Intelligent pipeline orchestration and routing\",\n",
    "        \"üß© **ModularRAGSystem** - Complete integration with performance monitoring\"\n",
    "    ]\n",
    "    \n",
    "    for component in components:\n",
    "        print(f\"   {component}\")\n",
    "    \n",
    "    print(\"\\nüöÄ **KEY INNOVATIONS:**\")\n",
    "    innovations = [\n",
    "        \"üéØ **Adaptive Processing** - Pipeline adapts to query complexity\",\n",
    "        \"üîß **Pluggable Architecture** - Easy to swap and extend components\",\n",
    "        \"üìä **Comprehensive Monitoring** - Performance tracking for each module\",\n",
    "        \"üß† **Context Awareness** - User preferences and conversation memory\",\n",
    "        \"‚ö° **Intelligent Routing** - Optimal strategy selection for each query\",\n",
    "        \"üåç **Multi-Domain Support** - Specialized handling for different domains\"\n",
    "    ]\n",
    "    \n",
    "    for innovation in innovations:\n",
    "        print(f\"   {innovation}\")\n",
    "    \n",
    "    print(\"\\nüìà **ADVANTAGES OVER BASIC RAG:**\")\n",
    "    advantages = [\n",
    "        \"üéØ **Higher Quality** - Specialized modules for different scenarios\",\n",
    "        \"‚ö° **Better Performance** - Adaptive processing pipelines\",\n",
    "        \"üîß **Easier Maintenance** - Independent module updates\",\n",
    "        \"üìä **Better Observability** - Detailed monitoring and debugging\",\n",
    "        \"üîÑ **Greater Flexibility** - Mix and match components\",\n",
    "        \"üèóÔ∏è **Scalability** - Independent scaling of modules\"\n",
    "    ]\n",
    "    \n",
    "    for advantage in advantages:\n",
    "        print(f\"   {advantage}\")\n",
    "    \n",
    "    print(\"\\nüîÆ **NEXT LEVEL ENHANCEMENTS:**\")\n",
    "    enhancements = [\n",
    "        \"ü§ñ **Agentic Modules** - Add autonomous reasoning capabilities\",\n",
    "        \"üîÑ **Self-Improving System** - Modules that learn and adapt\",\n",
    "        \"üåê **Multi-Modal Support** - Text, image, audio integration\",\n",
    "        \"üìä **GraphRAG Integration** - Knowledge graph reasoning\",\n",
    "        \"üõ°Ô∏è **Advanced Safety** - Content filtering and bias detection\",\n",
    "        \"üè≠ **Production Deployment** - Kubernetes and cloud scaling\"\n",
    "    ]\n",
    "    \n",
    "    for enhancement in enhancements:\n",
    "        print(f\"   {enhancement}\")\n",
    "    \n",
    "    # Final system status\n",
    "    status = modular_rag.get_system_status()\n",
    "    print(f\"\\nüìä **FINAL SYSTEM STATUS:**\")\n",
    "    print(f\"   ‚Ä¢ Modules Active: {len(modular_rag.modules)}/5\")\n",
    "    print(f\"   ‚Ä¢ Total Queries Processed: {status['total_queries']}\")\n",
    "    print(f\"   ‚Ä¢ System Success Rate: {status['success_rate']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Avg Processing Time: {status['avg_processing_time']:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Users Tracked: {status['memory_stats']['active_users']}\")\n",
    "    print(f\"   ‚Ä¢ Ready for Production: ‚úÖ\")\n",
    "    \n",
    "    print(\"\\nüéØ **READY FOR REAL-WORLD DEPLOYMENT!**\")\n",
    "    print(\"   Your Modular RAG system demonstrates enterprise-grade architecture\")\n",
    "    print(\"   and is ready to handle complex AI applications in production.\")\n",
    "    \n",
    "    print(\"\\n\" + \"üéâ\" * 70)\n",
    "    print(\"   **Thank you for mastering Modular RAG architecture!**\")\n",
    "    print(\"üéâ\" * 70)\n",
    "\n",
    "# Generate final summary\n",
    "print_final_summary()\n",
    "\n",
    "print(f\"\\nüîß **QUICK START COMMANDS:**\")\n",
    "print(f\"   ‚Ä¢ Test query: modular_rag.process_query('What is AI?')\")\n",
    "print(f\"   ‚Ä¢ System status: modular_rag.get_system_status()\")\n",
    "print(f\"   ‚Ä¢ Interactive demo: interactive_demo()\")\n",
    "print(f\"   ‚Ä¢ Add new documents: retrieval_module.index_documents(new_docs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Resources & References\n",
    "\n",
    "**Research Papers:**\n",
    "- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)\n",
    "- [Self-RAG: Learning to Critique and Revise](https://arxiv.org/abs/2310.11511)\n",
    "- [Modular Deep Learning](https://arxiv.org/abs/2302.11529)\n",
    "\n",
    "**Implementation Frameworks:**\n",
    "- [LangChain](https://python.langchain.com/) - LLM application framework\n",
    "- [LlamaIndex](https://docs.llamaindex.ai/) - Data framework for LLMs\n",
    "- [Haystack](https://haystack.deepset.ai/) - End-to-end NLP framework\n",
    "\n",
    "**Vector Databases:**\n",
    "- [Pinecone](https://www.pinecone.io/) - Managed vector database\n",
    "- [Weaviate](https://weaviate.io/) - Open-source vector search\n",
    "- [Qdrant](https://qdrant.tech/) - High-performance vector database\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Your Modular RAG system is now complete and ready for production!**\n",
    "\n",
    "**Next Steps:**\n",
    "1. üöÄ Deploy to cloud infrastructure\n",
    "2. üî¨ Experiment with advanced techniques\n",
    "3. üéØ Customize for your specific domain\n",
    "4. üìä Scale with real-world data\n",
    "\n",
    "**Happy Building! üß©**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
