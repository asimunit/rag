{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379b8089",
   "metadata": {},
   "source": [
    "# 🤖 Agentic RAG Implementation\n",
    "\n",
    "## Autonomous Agents with Iterative Reasoning\n",
    "\n",
    "This notebook demonstrates an **Agentic RAG system** with:\n",
    "- 🧠 Intelligent Planning Agents\n",
    "- 🛠️ Multi-Tool Integration \n",
    "- 🔄 Iterative Execution & Refinement\n",
    "- 🤔 Self-Reflection & Validation\n",
    "- 🎯 Goal-Oriented Problem Solving\n",
    "- 🤝 Multi-Agent Coordination\n",
    "\n",
    "### Key Benefits of Agentic Architecture\n",
    "- **Autonomy**: Agents make independent decisions\n",
    "- **Adaptability**: Dynamic plan adjustment based on results\n",
    "- **Tool Mastery**: Intelligent tool selection and usage\n",
    "- **Self-Improvement**: Learn from successes and failures\n",
    "- **Complex Reasoning**: Break down multi-step problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4c1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: google-generativeai in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.13.4)\n",
      "Requirement already satisfied: python-dotenv in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: sympy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.14.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: scikit-learn in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: scipy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: tqdm in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: Pillow in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: pydantic in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: google-api-core in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-python-client in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.173.0)\n",
      "Requirement already satisfied: protobuf in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sympy) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.11.0->sentence-transformers) (58.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Installing collected packages: tzdata, pytz, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pandas-2.3.0 pytz-2025.2 seaborn-0.13.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers faiss-cpu google-generativeai numpy requests beautifulsoup4 python-dotenv sympy matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e23e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Libraries imported successfully for Agentic RAG!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from datetime import datetime, timedelta\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import google.generativeai as genai\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\"🤖 Libraries imported successfully for Agentic RAG!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f67a3",
   "metadata": {},
   "source": [
    "## 🏗️ Core Agentic Data Structures\n",
    "\n",
    "Define the foundational structures for our agentic system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539d99c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ Agentic data structures defined!\n"
     ]
    }
   ],
   "source": [
    "# Enums for agentic system\n",
    "class AgentType(Enum):\n",
    "    PLANNER = \"planner\"\n",
    "    EXECUTOR = \"executor\"\n",
    "    REFLECTOR = \"reflector\"\n",
    "    COORDINATOR = \"coordinator\"\n",
    "    SPECIALIST = \"specialist\"\n",
    "\n",
    "class TaskType(Enum):\n",
    "    SEARCH = \"search\"\n",
    "    CALCULATE = \"calculate\"\n",
    "    ANALYZE = \"analyze\"\n",
    "    SYNTHESIZE = \"synthesize\"\n",
    "    VERIFY = \"verify\"\n",
    "\n",
    "class PlanStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    IN_PROGRESS = \"in_progress\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    REVISED = \"revised\"\n",
    "\n",
    "class ToolType(Enum):\n",
    "    WEB_SEARCH = \"web_search\"\n",
    "    CALCULATOR = \"calculator\"\n",
    "    DATABASE = \"database\"\n",
    "    RETRIEVER = \"retriever\"\n",
    "    ANALYZER = \"analyzer\"\n",
    "\n",
    "# Core agentic data structures\n",
    "@dataclass\n",
    "class Task:\n",
    "    id: str\n",
    "    description: str\n",
    "    task_type: TaskType\n",
    "    tool_required: ToolType\n",
    "    parameters: Dict[str, Any] = field(default_factory=dict)\n",
    "    status: PlanStatus = PlanStatus.PENDING\n",
    "    result: Optional[Any] = None\n",
    "    confidence: float = 0.0\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "@dataclass\n",
    "class Plan:\n",
    "    id: str\n",
    "    goal: str\n",
    "    tasks: List[Task]\n",
    "    status: PlanStatus = PlanStatus.PENDING\n",
    "    current_step: int = 0\n",
    "    results: List[Any] = field(default_factory=list)\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "    revised_count: int = 0\n",
    "\n",
    "@dataclass\n",
    "class AgentMessage:\n",
    "    sender: str\n",
    "    receiver: str\n",
    "    content: Any\n",
    "    message_type: str\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "@dataclass\n",
    "class AgenticResponse:\n",
    "    query: str\n",
    "    final_answer: str\n",
    "    execution_plan: Plan\n",
    "    tool_usage: Dict[str, int]\n",
    "    confidence_score: float\n",
    "    reasoning_steps: List[str]\n",
    "    processing_time: float\n",
    "    iterations: int\n",
    "\n",
    "print(\"🏗️ Agentic data structures defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b34f1b1",
   "metadata": {},
   "source": [
    "## 🛠️ Tool System Architecture\n",
    "\n",
    "Create a comprehensive tool system for agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fd0a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Tool system created with 5 specialized tools!\n"
     ]
    }
   ],
   "source": [
    "# Base tool class\n",
    "class BaseTool(ABC):\n",
    "    def __init__(self, name: str, description: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.usage_count = 0\n",
    "        self.success_rate = 1.0\n",
    "        self.avg_execution_time = 0.0\n",
    "    \n",
    "    @abstractmethod\n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        \"\"\"Execute tool and return (result, confidence)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update_stats(self, execution_time: float, success: bool):\n",
    "        self.usage_count += 1\n",
    "        \n",
    "        # Update success rate\n",
    "        if self.usage_count == 1:\n",
    "            self.success_rate = 1.0 if success else 0.0\n",
    "        else:\n",
    "            self.success_rate = ((self.success_rate * (self.usage_count - 1)) + \n",
    "                               (1.0 if success else 0.0)) / self.usage_count\n",
    "        \n",
    "        # Update average execution time\n",
    "        self.avg_execution_time = ((self.avg_execution_time * (self.usage_count - 1)) + \n",
    "                                  execution_time) / self.usage_count\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'usage_count': self.usage_count,\n",
    "            'success_rate': self.success_rate,\n",
    "            'avg_execution_time': self.avg_execution_time\n",
    "        }\n",
    "\n",
    "# Web Search Tool\n",
    "class WebSearchTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"WebSearch\",\n",
    "            description=\"Search the web for current information\"\n",
    "        )\n",
    "        self.search_history = []\n",
    "    \n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            query = parameters.get('query', '')\n",
    "            max_results = parameters.get('max_results', 3)\n",
    "            \n",
    "            # Simulate web search (in real implementation, use actual search API)\n",
    "            results = self._simulate_search(query, max_results)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, True)\n",
    "            \n",
    "            return results, 0.8\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, False)\n",
    "            return f\"Search failed: {str(e)}\", 0.0\n",
    "    \n",
    "    def _simulate_search(self, query: str, max_results: int) -> List[Dict[str, str]]:\n",
    "        # Simulated search results\n",
    "        search_results = [\n",
    "            {\n",
    "                \"title\": f\"Result for '{query}' - Article 1\",\n",
    "                \"snippet\": f\"This article discusses {query} and provides comprehensive information about the topic.\",\n",
    "                \"url\": \"https://example.com/article1\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": f\"Understanding {query} - Complete Guide\",\n",
    "                \"snippet\": f\"A detailed guide covering all aspects of {query} with practical examples.\",\n",
    "                \"url\": \"https://example.com/guide\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": f\"Latest Research on {query}\",\n",
    "                \"snippet\": f\"Recent studies and findings related to {query} from leading researchers.\",\n",
    "                \"url\": \"https://example.com/research\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return search_results[:max_results]\n",
    "\n",
    "# Calculator Tool\n",
    "class CalculatorTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Calculator\",\n",
    "            description=\"Perform mathematical calculations and symbolic math\"\n",
    "        )\n",
    "    \n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            expression = parameters.get('expression', '')\n",
    "            calc_type = parameters.get('type', 'numeric')  # numeric, symbolic, equation\n",
    "            \n",
    "            if calc_type == 'symbolic':\n",
    "                result = self._symbolic_calculation(expression)\n",
    "            elif calc_type == 'equation':\n",
    "                result = self._solve_equation(expression)\n",
    "            else:\n",
    "                result = self._numeric_calculation(expression)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, True)\n",
    "            \n",
    "            return result, 0.95\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, False)\n",
    "            return f\"Calculation failed: {str(e)}\", 0.0\n",
    "    \n",
    "    def _numeric_calculation(self, expression: str) -> float:\n",
    "        # Safe evaluation of mathematical expressions\n",
    "        allowed_names = {\n",
    "            k: v for k, v in np.__dict__.items() if not k.startswith(\"__\")\n",
    "        }\n",
    "        allowed_names.update({\n",
    "            \"abs\": abs, \"round\": round, \"min\": min, \"max\": max,\n",
    "            \"sum\": sum, \"pow\": pow\n",
    "        })\n",
    "        \n",
    "        return eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "    \n",
    "    def _symbolic_calculation(self, expression: str) -> str:\n",
    "        # Symbolic math using SymPy\n",
    "        x, y, z = sp.symbols('x y z')\n",
    "        expr = sp.sympify(expression)\n",
    "        simplified = sp.simplify(expr)\n",
    "        return str(simplified)\n",
    "    \n",
    "    def _solve_equation(self, equation: str) -> List[str]:\n",
    "        # Solve equations\n",
    "        x = sp.Symbol('x')\n",
    "        eq = sp.Eq(sp.sympify(equation.split('=')[0]), sp.sympify(equation.split('=')[1]))\n",
    "        solutions = sp.solve(eq, x)\n",
    "        return [str(sol) for sol in solutions]\n",
    "\n",
    "# Database Query Tool\n",
    "class DatabaseTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Database\",\n",
    "            description=\"Query structured data and knowledge bases\"\n",
    "        )\n",
    "        self.knowledge_base = self._create_sample_kb()\n",
    "    \n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            query = parameters.get('query', '')\n",
    "            query_type = parameters.get('type', 'search')  # search, filter, aggregate\n",
    "            \n",
    "            if query_type == 'search':\n",
    "                result = self._search_knowledge(query)\n",
    "            elif query_type == 'filter':\n",
    "                result = self._filter_data(parameters)\n",
    "            else:\n",
    "                result = self._aggregate_data(parameters)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, True)\n",
    "            \n",
    "            return result, 0.85\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, False)\n",
    "            return f\"Database query failed: {str(e)}\", 0.0\n",
    "    \n",
    "    def _create_sample_kb(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'companies': [\n",
    "                {'name': 'Apple', 'sector': 'Technology', 'founded': 1976, 'revenue': 394.3},\n",
    "                {'name': 'Microsoft', 'sector': 'Technology', 'founded': 1975, 'revenue': 211.9},\n",
    "                {'name': 'Amazon', 'sector': 'E-commerce', 'founded': 1994, 'revenue': 513.9}\n",
    "            ],\n",
    "            'technologies': [\n",
    "                {'name': 'Machine Learning', 'category': 'AI', 'maturity': 'Mature'},\n",
    "                {'name': 'Quantum Computing', 'category': 'Computing', 'maturity': 'Emerging'},\n",
    "                {'name': 'Blockchain', 'category': 'Distributed', 'maturity': 'Growing'}\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _search_knowledge(self, query: str) -> List[Dict[str, Any]]:\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for category, items in self.knowledge_base.items():\n",
    "            for item in items:\n",
    "                # Simple text matching\n",
    "                if any(query_lower in str(value).lower() for value in item.values()):\n",
    "                    results.append({'category': category, 'data': item})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _filter_data(self, parameters: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        # Implement filtering logic\n",
    "        return []\n",
    "    \n",
    "    def _aggregate_data(self, parameters: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Implement aggregation logic\n",
    "        return {}\n",
    "\n",
    "# Retrieval Tool\n",
    "class RetrievalTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Retrieval\",\n",
    "            description=\"Retrieve relevant documents from knowledge base\"\n",
    "        )\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.documents = []\n",
    "        self.index = None\n",
    "        self._setup_knowledge_base()\n",
    "    \n",
    "    def _setup_knowledge_base(self):\n",
    "        # Sample documents\n",
    "        docs = [\n",
    "            \"Artificial Intelligence is transforming industries through automation and intelligent decision-making.\",\n",
    "            \"Machine Learning algorithms learn patterns from data to make predictions without explicit programming.\",\n",
    "            \"Quantum Computing leverages quantum mechanics to solve complex problems exponentially faster.\",\n",
    "            \"Cloud Computing provides scalable, on-demand access to computing resources over the internet.\",\n",
    "            \"Digital transformation integrates digital technology into all business areas, changing operations.\"\n",
    "        ]\n",
    "        \n",
    "        self.documents = docs\n",
    "        embeddings = self.embedding_model.encode(docs)\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dimension)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "    \n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            query = parameters.get('query', '')\n",
    "            top_k = parameters.get('top_k', 3)\n",
    "            \n",
    "            query_embedding = self.embedding_model.encode([query])\n",
    "            faiss.normalize_L2(query_embedding)\n",
    "            \n",
    "            scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
    "            \n",
    "            results = []\n",
    "            for score, idx in zip(scores[0], indices[0]):\n",
    "                results.append({\n",
    "                    'document': self.documents[idx],\n",
    "                    'score': float(score)\n",
    "                })\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, True)\n",
    "            \n",
    "            return results, 0.9\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, False)\n",
    "            return f\"Retrieval failed: {str(e)}\", 0.0\n",
    "\n",
    "# Analyzer Tool\n",
    "class AnalyzerTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Analyzer\",\n",
    "            description=\"Analyze data and extract insights\"\n",
    "        )\n",
    "    \n",
    "    def execute(self, parameters: Dict[str, Any]) -> Tuple[Any, float]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            data = parameters.get('data', [])\n",
    "            analysis_type = parameters.get('type', 'summary')  # summary, trend, correlation\n",
    "            \n",
    "            if analysis_type == 'summary':\n",
    "                result = self._summarize_data(data)\n",
    "            elif analysis_type == 'trend':\n",
    "                result = self._analyze_trends(data)\n",
    "            else:\n",
    "                result = self._find_correlations(data)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, True)\n",
    "            \n",
    "            return result, 0.8\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            self.update_stats(execution_time, False)\n",
    "            return f\"Analysis failed: {str(e)}\", 0.0\n",
    "    \n",
    "    def _summarize_data(self, data: List[Any]) -> Dict[str, Any]:\n",
    "        if not data:\n",
    "            return {\"summary\": \"No data to analyze\"}\n",
    "        \n",
    "        return {\n",
    "            \"count\": len(data),\n",
    "            \"first_item\": str(data[0]) if data else None,\n",
    "            \"last_item\": str(data[-1]) if data else None,\n",
    "            \"summary\": f\"Dataset contains {len(data)} items\"\n",
    "        }\n",
    "    \n",
    "    def _analyze_trends(self, data: List[Any]) -> Dict[str, Any]:\n",
    "        return {\"trend\": \"Analysis would identify patterns and trends in the data\"}\n",
    "    \n",
    "    def _find_correlations(self, data: List[Any]) -> Dict[str, Any]:\n",
    "        return {\"correlations\": \"Analysis would find relationships between variables\"}\n",
    "\n",
    "print(\"🛠️ Tool system created with 5 specialized tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66116acb",
   "metadata": {},
   "source": [
    "## 🧠 Agent Base Classes\n",
    "\n",
    "Define base classes for autonomous agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcd60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Base agent class defined!\n"
     ]
    }
   ],
   "source": [
    "# Base Agent class\n",
    "class BaseAgent(ABC):\n",
    "    def __init__(self, name: str, agent_type: AgentType):\n",
    "        self.name = name\n",
    "        self.agent_type = agent_type\n",
    "        self.agent_id = str(uuid.uuid4())[:8]\n",
    "        self.created_at = datetime.now()\n",
    "        self.total_tasks = 0\n",
    "        self.successful_tasks = 0\n",
    "        self.message_queue = []\n",
    "        self.memory = {}\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process(self, input_data: Any) -> Any:\n",
    "        pass\n",
    "    \n",
    "    def send_message(self, receiver: str, content: Any, message_type: str):\n",
    "        message = AgentMessage(\n",
    "            sender=self.name,\n",
    "            receiver=receiver,\n",
    "            content=content,\n",
    "            message_type=message_type\n",
    "        )\n",
    "        return message\n",
    "    \n",
    "    def receive_message(self, message: AgentMessage):\n",
    "        self.message_queue.append(message)\n",
    "    \n",
    "    def update_stats(self, success: bool):\n",
    "        self.total_tasks += 1\n",
    "        if success:\n",
    "            self.successful_tasks += 1\n",
    "    \n",
    "    def get_success_rate(self) -> float:\n",
    "        if self.total_tasks == 0:\n",
    "            return 0.0\n",
    "        return self.successful_tasks / self.total_tasks\n",
    "    \n",
    "    def get_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'type': self.agent_type.value,\n",
    "            'id': self.agent_id,\n",
    "            'total_tasks': self.total_tasks,\n",
    "            'success_rate': self.get_success_rate(),\n",
    "            'created_at': self.created_at\n",
    "        }\n",
    "\n",
    "print(\"🧠 Base agent class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a61bb",
   "metadata": {},
   "source": [
    "## 📋 Action Planner Agent\n",
    "\n",
    "Intelligent agent that creates execution plans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51db1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Test plan created:\n",
      "   Goal: What is the impact of artificial intelligence on healthcare?\n",
      "   Tasks: 3\n",
      "   1. Search for information about: What is the impact of artificial intelligence on healthcare? (Tool: web_search)\n",
      "   2. Analyze gathered information about: What is the impact of artificial intelligence on healthcare? (Tool: analyzer)\n",
      "   3. Synthesize final answer for: What is the impact of artificial intelligence on healthcare? (Tool: retriever)\n",
      "✅ Action Planner Agent ready!\n"
     ]
    }
   ],
   "source": [
    "class ActionPlannerAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"ActionPlanner\", AgentType.PLANNER)\n",
    "        \n",
    "        # Planning patterns and strategies\n",
    "        self.planning_patterns = {\n",
    "            'search_and_analyze': [\n",
    "                (TaskType.SEARCH, ToolType.WEB_SEARCH),\n",
    "                (TaskType.ANALYZE, ToolType.ANALYZER),\n",
    "                (TaskType.SYNTHESIZE, ToolType.RETRIEVER)\n",
    "            ],\n",
    "            'calculate_and_verify': [\n",
    "                (TaskType.CALCULATE, ToolType.CALCULATOR),\n",
    "                (TaskType.VERIFY, ToolType.DATABASE),\n",
    "                (TaskType.SYNTHESIZE, ToolType.ANALYZER)\n",
    "            ],\n",
    "            'research_deep': [\n",
    "                (TaskType.SEARCH, ToolType.WEB_SEARCH),\n",
    "                (TaskType.SEARCH, ToolType.RETRIEVER),\n",
    "                (TaskType.SEARCH, ToolType.DATABASE),\n",
    "                (TaskType.ANALYZE, ToolType.ANALYZER),\n",
    "                (TaskType.SYNTHESIZE, ToolType.RETRIEVER)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def process(self, query: str) -> Plan:\n",
    "        self.update_stats(True)  # Planning rarely fails\n",
    "        \n",
    "        plan_id = str(uuid.uuid4())[:8]\n",
    "        \n",
    "        # Analyze query complexity and type\n",
    "        query_analysis = self._analyze_query(query)\n",
    "        \n",
    "        # Select planning pattern\n",
    "        pattern = self._select_pattern(query_analysis)\n",
    "        \n",
    "        # Create tasks\n",
    "        tasks = self._create_tasks(query, pattern, query_analysis)\n",
    "        \n",
    "        plan = Plan(\n",
    "            id=plan_id,\n",
    "            goal=query,\n",
    "            tasks=tasks\n",
    "        )\n",
    "        \n",
    "        # Store planning context in memory\n",
    "        self.memory[plan_id] = {\n",
    "            'query_analysis': query_analysis,\n",
    "            'selected_pattern': pattern,\n",
    "            'original_query': query\n",
    "        }\n",
    "        \n",
    "        return plan\n",
    "    \n",
    "    def revise_plan(self, original_plan: Plan, failed_task: Task, failure_reason: str) -> Plan:\n",
    "        \"\"\"Revise plan when a task fails\"\"\"\n",
    "        print(f\"🔄 Revising plan due to failed task: {failed_task.description}\")\n",
    "        \n",
    "        # Get original context\n",
    "        context = self.memory.get(original_plan.id, {})\n",
    "        \n",
    "        # Create alternative tasks\n",
    "        alternative_tasks = self._create_alternative_tasks(\n",
    "            failed_task, failure_reason, context\n",
    "        )\n",
    "        \n",
    "        # Create revised plan\n",
    "        revised_tasks = original_plan.tasks[:original_plan.current_step] + alternative_tasks\n",
    "        \n",
    "        revised_plan = Plan(\n",
    "            id=str(uuid.uuid4())[:8],\n",
    "            goal=original_plan.goal,\n",
    "            tasks=revised_tasks,\n",
    "            current_step=original_plan.current_step,\n",
    "            results=original_plan.results.copy(),\n",
    "            revised_count=original_plan.revised_count + 1\n",
    "        )\n",
    "        \n",
    "        return revised_plan\n",
    "    \n",
    "    def _analyze_query(self, query: str) -> Dict[str, Any]:\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        analysis = {\n",
    "            'length': len(query.split()),\n",
    "            'complexity': 'simple',\n",
    "            'requires_calculation': False,\n",
    "            'requires_search': False,\n",
    "            'requires_analysis': False,\n",
    "            'domain': 'general'\n",
    "        }\n",
    "        \n",
    "        # Check for calculation keywords\n",
    "        calc_keywords = ['calculate', 'compute', 'solve', 'equation', 'math', 'formula']\n",
    "        if any(keyword in query_lower for keyword in calc_keywords):\n",
    "            analysis['requires_calculation'] = True\n",
    "        \n",
    "        # Check for search keywords\n",
    "        search_keywords = ['search', 'find', 'lookup', 'what is', 'who is', 'when did']\n",
    "        if any(keyword in query_lower for keyword in search_keywords):\n",
    "            analysis['requires_search'] = True\n",
    "        \n",
    "        # Check for analysis keywords\n",
    "        analysis_keywords = ['analyze', 'compare', 'evaluate', 'assess', 'impact']\n",
    "        if any(keyword in query_lower for keyword in analysis_keywords):\n",
    "            analysis['requires_analysis'] = True\n",
    "        \n",
    "        # Determine complexity\n",
    "        complexity_score = 0\n",
    "        if analysis['length'] > 10:\n",
    "            complexity_score += 1\n",
    "        if analysis['requires_calculation']:\n",
    "            complexity_score += 1\n",
    "        if analysis['requires_analysis']:\n",
    "            complexity_score += 2\n",
    "        \n",
    "        if complexity_score <= 1:\n",
    "            analysis['complexity'] = 'simple'\n",
    "        elif complexity_score <= 3:\n",
    "            analysis['complexity'] = 'medium'\n",
    "        else:\n",
    "            analysis['complexity'] = 'complex'\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _select_pattern(self, analysis: Dict[str, Any]) -> str:\n",
    "        if analysis['requires_calculation']:\n",
    "            return 'calculate_and_verify'\n",
    "        elif analysis['complexity'] == 'complex':\n",
    "            return 'research_deep'\n",
    "        else:\n",
    "            return 'search_and_analyze'\n",
    "    \n",
    "    def _create_tasks(self, query: str, pattern: str, analysis: Dict[str, Any]) -> List[Task]:\n",
    "        tasks = []\n",
    "        pattern_tasks = self.planning_patterns[pattern]\n",
    "        \n",
    "        for i, (task_type, tool_type) in enumerate(pattern_tasks):\n",
    "            task_id = f\"task_{i+1}\"\n",
    "            \n",
    "            # Customize task based on type\n",
    "            if task_type == TaskType.SEARCH:\n",
    "                description = f\"Search for information about: {query}\"\n",
    "                parameters = {'query': query, 'max_results': 3}\n",
    "            elif task_type == TaskType.CALCULATE:\n",
    "                description = f\"Perform calculations related to: {query}\"\n",
    "                parameters = {'expression': query, 'type': 'numeric'}\n",
    "            elif task_type == TaskType.ANALYZE:\n",
    "                description = f\"Analyze gathered information about: {query}\"\n",
    "                parameters = {'type': 'summary'}\n",
    "            elif task_type == TaskType.VERIFY:\n",
    "                description = f\"Verify information accuracy for: {query}\"\n",
    "                parameters = {'query': query, 'type': 'search'}\n",
    "            else:  # SYNTHESIZE\n",
    "                description = f\"Synthesize final answer for: {query}\"\n",
    "                parameters = {'query': query, 'top_k': 3}\n",
    "            \n",
    "            task = Task(\n",
    "                id=task_id,\n",
    "                description=description,\n",
    "                task_type=task_type,\n",
    "                tool_required=tool_type,\n",
    "                parameters=parameters\n",
    "            )\n",
    "            \n",
    "            tasks.append(task)\n",
    "        \n",
    "        return tasks\n",
    "    \n",
    "    def _create_alternative_tasks(self, failed_task: Task, failure_reason: str, context: Dict[str, Any]) -> List[Task]:\n",
    "        \"\"\"Create alternative tasks when original task fails\"\"\"\n",
    "        alternative_tasks = []\n",
    "        \n",
    "        # Try different tool for same task type\n",
    "        if failed_task.task_type == TaskType.SEARCH:\n",
    "            if failed_task.tool_required == ToolType.WEB_SEARCH:\n",
    "                # Try retrieval instead\n",
    "                alt_task = Task(\n",
    "                    id=f\"alt_{failed_task.id}\",\n",
    "                    description=f\"Retrieve information (alternative): {failed_task.description}\",\n",
    "                    task_type=TaskType.SEARCH,\n",
    "                    tool_required=ToolType.RETRIEVER,\n",
    "                    parameters=failed_task.parameters\n",
    "                )\n",
    "                alternative_tasks.append(alt_task)\n",
    "        \n",
    "        # Add verification task\n",
    "        verify_task = Task(\n",
    "            id=f\"verify_{failed_task.id}\",\n",
    "            description=f\"Verify alternative approach for: {failed_task.description}\",\n",
    "            task_type=TaskType.VERIFY,\n",
    "            tool_required=ToolType.DATABASE,\n",
    "            parameters={'query': failed_task.parameters.get('query', ''), 'type': 'search'}\n",
    "        )\n",
    "        alternative_tasks.append(verify_task)\n",
    "        \n",
    "        return alternative_tasks\n",
    "\n",
    "# Test planner\n",
    "planner = ActionPlannerAgent()\n",
    "test_plan = planner.process(\"What is the impact of artificial intelligence on healthcare?\")\n",
    "\n",
    "print(f\"📋 Test plan created:\")\n",
    "print(f\"   Goal: {test_plan.goal}\")\n",
    "print(f\"   Tasks: {len(test_plan.tasks)}\")\n",
    "for i, task in enumerate(test_plan.tasks[:3], 1):\n",
    "    print(f\"   {i}. {task.description} (Tool: {task.tool_required.value})\")\n",
    "print(\"✅ Action Planner Agent ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4de68",
   "metadata": {},
   "source": [
    "## ⚡ Tool Executor Agent\n",
    "\n",
    "Agent that executes tasks using available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce250d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Executing: Search for AI information\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "✅ Tool Executor Agent ready!\n",
      "   Test execution status: completed\n",
      "   Test confidence: 0.80\n"
     ]
    }
   ],
   "source": [
    "class ToolExecutorAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"ToolExecutor\", AgentType.EXECUTOR)\n",
    "        \n",
    "        # Initialize all tools\n",
    "        self.tools = {\n",
    "            ToolType.WEB_SEARCH: WebSearchTool(),\n",
    "            ToolType.CALCULATOR: CalculatorTool(),\n",
    "            ToolType.DATABASE: DatabaseTool(),\n",
    "            ToolType.RETRIEVER: RetrievalTool(),\n",
    "            ToolType.ANALYZER: AnalyzerTool()\n",
    "        }\n",
    "        \n",
    "        self.execution_history = []\n",
    "        self.tool_usage_stats = {tool_type: 0 for tool_type in ToolType}\n",
    "    \n",
    "    def process(self, task: Task) -> Task:\n",
    "        \"\"\"Execute a single task\"\"\"\n",
    "        print(f\"⚡ Executing: {task.description}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        task.status = PlanStatus.IN_PROGRESS\n",
    "        \n",
    "        try:\n",
    "            # Get the appropriate tool\n",
    "            tool = self.tools.get(task.tool_required)\n",
    "            if not tool:\n",
    "                raise ValueError(f\"Tool not available: {task.tool_required}\")\n",
    "            \n",
    "            # Execute tool with task parameters\n",
    "            result, confidence = tool.execute(task.parameters)\n",
    "            \n",
    "            # Update task with results\n",
    "            task.result = result\n",
    "            task.confidence = confidence\n",
    "            task.status = PlanStatus.COMPLETED\n",
    "            \n",
    "            # Update statistics\n",
    "            self.update_stats(True)\n",
    "            self.tool_usage_stats[task.tool_required] += 1\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            # Log execution\n",
    "            self.execution_history.append({\n",
    "                'task_id': task.id,\n",
    "                'tool_used': task.tool_required.value,\n",
    "                'execution_time': execution_time,\n",
    "                'confidence': confidence,\n",
    "                'success': True,\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "            \n",
    "            print(f\"   ✅ Completed in {execution_time:.2f}s (Confidence: {confidence:.2f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle execution failure\n",
    "            task.result = f\"Execution failed: {str(e)}\"\n",
    "            task.confidence = 0.0\n",
    "            task.status = PlanStatus.FAILED\n",
    "            \n",
    "            self.update_stats(False)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            self.execution_history.append({\n",
    "                'task_id': task.id,\n",
    "                'tool_used': task.tool_required.value,\n",
    "                'execution_time': execution_time,\n",
    "                'confidence': 0.0,\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "            \n",
    "            print(f\"   ❌ Failed after {execution_time:.2f}s: {str(e)}\")\n",
    "        \n",
    "        return task\n",
    "    \n",
    "    def execute_plan(self, plan: Plan) -> Plan:\n",
    "        \"\"\"Execute all tasks in a plan sequentially\"\"\"\n",
    "        print(f\"🎯 Executing plan: {plan.goal}\")\n",
    "        \n",
    "        plan.status = PlanStatus.IN_PROGRESS\n",
    "        \n",
    "        for i, task in enumerate(plan.tasks):\n",
    "            plan.current_step = i\n",
    "            \n",
    "            # Execute task\n",
    "            executed_task = self.process(task)\n",
    "            \n",
    "            # Store result\n",
    "            plan.results.append(executed_task.result)\n",
    "            \n",
    "            # Update plan task\n",
    "            plan.tasks[i] = executed_task\n",
    "            \n",
    "            # Check if task failed and needs plan revision\n",
    "            if executed_task.status == PlanStatus.FAILED:\n",
    "                plan.status = PlanStatus.FAILED\n",
    "                break\n",
    "        \n",
    "        if plan.status != PlanStatus.FAILED:\n",
    "            plan.status = PlanStatus.COMPLETED\n",
    "            plan.current_step = len(plan.tasks)\n",
    "        \n",
    "        return plan\n",
    "    \n",
    "    def get_tool_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about tool usage\"\"\"\n",
    "        tool_stats = {}\n",
    "        \n",
    "        for tool_type, tool in self.tools.items():\n",
    "            tool_stats[tool_type.value] = {\n",
    "                'usage_count': self.tool_usage_stats[tool_type],\n",
    "                'tool_stats': tool.get_stats()\n",
    "            }\n",
    "        \n",
    "        return tool_stats\n",
    "    \n",
    "    def get_execution_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary of all executions\"\"\"\n",
    "        if not self.execution_history:\n",
    "            return {'total_executions': 0}\n",
    "        \n",
    "        successful_executions = [e for e in self.execution_history if e['success']]\n",
    "        \n",
    "        return {\n",
    "            'total_executions': len(self.execution_history),\n",
    "            'successful_executions': len(successful_executions),\n",
    "            'success_rate': len(successful_executions) / len(self.execution_history),\n",
    "            'avg_execution_time': np.mean([e['execution_time'] for e in self.execution_history]),\n",
    "            'avg_confidence': np.mean([e['confidence'] for e in successful_executions]) if successful_executions else 0\n",
    "        }\n",
    "\n",
    "# Test executor\n",
    "executor = ToolExecutorAgent()\n",
    "test_task = Task(\n",
    "    id=\"test_1\",\n",
    "    description=\"Search for AI information\",\n",
    "    task_type=TaskType.SEARCH,\n",
    "    tool_required=ToolType.WEB_SEARCH,\n",
    "    parameters={'query': 'artificial intelligence', 'max_results': 2}\n",
    ")\n",
    "\n",
    "executed_task = executor.process(test_task)\n",
    "print(f\"✅ Tool Executor Agent ready!\")\n",
    "print(f\"   Test execution status: {executed_task.status.value}\")\n",
    "print(f\"   Test confidence: {executed_task.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117c1ed",
   "metadata": {},
   "source": [
    "## 🤔 Self-Reflector Agent\n",
    "\n",
    "Agent that validates results and provides feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588e6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤔 Reflecting on plan execution...\n",
      "✅ Self-Reflector Agent ready!\n",
      "   Test reflection success: False\n",
      "   Test recommendations: 0\n"
     ]
    }
   ],
   "source": [
    "class SelfReflectorAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"SelfReflector\", AgentType.REFLECTOR)\n",
    "        \n",
    "        # Validation criteria\n",
    "        self.validation_criteria = {\n",
    "            'confidence_threshold': 0.6,\n",
    "            'completeness_threshold': 0.7,\n",
    "            'consistency_threshold': 0.8,\n",
    "            'relevance_threshold': 0.7\n",
    "        }\n",
    "        \n",
    "        self.reflection_history = []\n",
    "    \n",
    "    def process(self, plan: Plan) -> Dict[str, Any]:\n",
    "        \"\"\"Validate plan execution and provide reflection\"\"\"\n",
    "        print(f\"🤔 Reflecting on plan execution...\")\n",
    "        \n",
    "        reflection = {\n",
    "            'plan_id': plan.id,\n",
    "            'overall_success': False,\n",
    "            'confidence_score': 0.0,\n",
    "            'completeness_score': 0.0,\n",
    "            'consistency_score': 0.0,\n",
    "            'relevance_score': 0.0,\n",
    "            'issues_found': [],\n",
    "            'recommendations': [],\n",
    "            'should_revise': False\n",
    "        }\n",
    "        \n",
    "        # Validate each completed task\n",
    "        completed_tasks = [t for t in plan.tasks if t.status == PlanStatus.COMPLETED]\n",
    "        failed_tasks = [t for t in plan.tasks if t.status == PlanStatus.FAILED]\n",
    "        \n",
    "        if not completed_tasks:\n",
    "            reflection['issues_found'].append(\"No tasks completed successfully\")\n",
    "            reflection['should_revise'] = True\n",
    "            self.reflection_history.append(reflection)\n",
    "            return reflection\n",
    "        \n",
    "        # Calculate confidence score\n",
    "        confidence_scores = [t.confidence for t in completed_tasks]\n",
    "        reflection['confidence_score'] = np.mean(confidence_scores)\n",
    "        \n",
    "        # Calculate completeness score\n",
    "        total_tasks = len(plan.tasks)\n",
    "        completed_count = len(completed_tasks)\n",
    "        reflection['completeness_score'] = completed_count / total_tasks\n",
    "        \n",
    "        # Calculate consistency score\n",
    "        reflection['consistency_score'] = self._assess_consistency(completed_tasks)\n",
    "        \n",
    "        # Calculate relevance score\n",
    "        reflection['relevance_score'] = self._assess_relevance(plan.goal, completed_tasks)\n",
    "        \n",
    "        # Check validation criteria\n",
    "        issues = self._check_validation_criteria(reflection)\n",
    "        reflection['issues_found'] = issues\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self._generate_recommendations(reflection, failed_tasks)\n",
    "        reflection['recommendations'] = recommendations\n",
    "        \n",
    "        # Determine if revision is needed\n",
    "        reflection['should_revise'] = self._should_revise_plan(reflection)\n",
    "        \n",
    "        # Overall success assessment\n",
    "        reflection['overall_success'] = (\n",
    "            reflection['confidence_score'] >= self.validation_criteria['confidence_threshold'] and\n",
    "            reflection['completeness_score'] >= self.validation_criteria['completeness_threshold'] and\n",
    "            not reflection['should_revise']\n",
    "        )\n",
    "        \n",
    "        self.update_stats(reflection['overall_success'])\n",
    "        self.reflection_history.append(reflection)\n",
    "        \n",
    "        print(f\"   📊 Confidence: {reflection['confidence_score']:.2f}\")\n",
    "        print(f\"   📈 Completeness: {reflection['completeness_score']:.2f}\")\n",
    "        print(f\"   🎯 Overall Success: {reflection['overall_success']}\")\n",
    "        \n",
    "        if reflection['issues_found']:\n",
    "            print(f\"   ⚠️  Issues: {len(reflection['issues_found'])}\")\n",
    "        \n",
    "        return reflection\n",
    "    \n",
    "    def _assess_consistency(self, tasks: List[Task]) -> float:\n",
    "        \"\"\"Assess consistency of results across tasks\"\"\"\n",
    "        if len(tasks) < 2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Simple consistency check based on confidence variance\n",
    "        confidence_scores = [t.confidence for t in tasks]\n",
    "        confidence_std = np.std(confidence_scores)\n",
    "        \n",
    "        # Lower standard deviation = higher consistency\n",
    "        consistency = max(0.0, 1.0 - confidence_std)\n",
    "        return consistency\n",
    "    \n",
    "    def _assess_relevance(self, goal: str, tasks: List[Task]) -> float:\n",
    "        \"\"\"Assess relevance of task results to the goal\"\"\"\n",
    "        goal_words = set(goal.lower().split())\n",
    "        relevance_scores = []\n",
    "        \n",
    "        for task in tasks:\n",
    "            if task.result and isinstance(task.result, str):\n",
    "                result_words = set(str(task.result).lower().split())\n",
    "                common_words = goal_words.intersection(result_words)\n",
    "                relevance = len(common_words) / max(len(goal_words), 1)\n",
    "                relevance_scores.append(relevance)\n",
    "            else:\n",
    "                relevance_scores.append(0.5)  # Neutral for non-text results\n",
    "        \n",
    "        return np.mean(relevance_scores) if relevance_scores else 0.5\n",
    "    \n",
    "    def _check_validation_criteria(self, reflection: Dict[str, Any]) -> List[str]:\n",
    "        \"\"\"Check if reflection meets validation criteria\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if reflection['confidence_score'] < self.validation_criteria['confidence_threshold']:\n",
    "            issues.append(f\"Low confidence score: {reflection['confidence_score']:.2f}\")\n",
    "        \n",
    "        if reflection['completeness_score'] < self.validation_criteria['completeness_threshold']:\n",
    "            issues.append(f\"Low completeness: {reflection['completeness_score']:.2f}\")\n",
    "        \n",
    "        if reflection['consistency_score'] < self.validation_criteria['consistency_threshold']:\n",
    "            issues.append(f\"Low consistency: {reflection['consistency_score']:.2f}\")\n",
    "        \n",
    "        if reflection['relevance_score'] < self.validation_criteria['relevance_threshold']:\n",
    "            issues.append(f\"Low relevance: {reflection['relevance_score']:.2f}\")\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    def _generate_recommendations(self, reflection: Dict[str, Any], failed_tasks: List[Task]) -> List[str]:\n",
    "        \"\"\"Generate actionable recommendations\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if reflection['confidence_score'] < 0.7:\n",
    "            recommendations.append(\"Consider using alternative tools or approaches for higher confidence\")\n",
    "        \n",
    "        if reflection['completeness_score'] < 0.8:\n",
    "            recommendations.append(\"Add more comprehensive tasks to improve completeness\")\n",
    "        \n",
    "        if failed_tasks:\n",
    "            recommendations.append(f\"Revise {len(failed_tasks)} failed tasks with alternative approaches\")\n",
    "        \n",
    "        if reflection['relevance_score'] < 0.6:\n",
    "            recommendations.append(\"Focus tasks more specifically on the main goal\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"Plan execution appears satisfactory\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _should_revise_plan(self, reflection: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Determine if plan should be revised\"\"\"\n",
    "        # Revise if multiple criteria are not met\n",
    "        failing_criteria = len(reflection['issues_found'])\n",
    "        \n",
    "        if failing_criteria >= 2:  # Two or more issues\n",
    "            return True\n",
    "        \n",
    "        if reflection['confidence_score'] < 0.4:  # Very low confidence\n",
    "            return True\n",
    "        \n",
    "        if reflection['completeness_score'] < 0.5:  # Very low completeness\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_reflection_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary of all reflections\"\"\"\n",
    "        if not self.reflection_history:\n",
    "            return {'total_reflections': 0}\n",
    "        \n",
    "        successful_reflections = [r for r in self.reflection_history if r['overall_success']]\n",
    "        \n",
    "        return {\n",
    "            'total_reflections': len(self.reflection_history),\n",
    "            'successful_reflections': len(successful_reflections),\n",
    "            'success_rate': len(successful_reflections) / len(self.reflection_history),\n",
    "            'avg_confidence': np.mean([r['confidence_score'] for r in self.reflection_history]),\n",
    "            'avg_completeness': np.mean([r['completeness_score'] for r in self.reflection_history]),\n",
    "            'revisions_recommended': sum(1 for r in self.reflection_history if r['should_revise'])\n",
    "        }\n",
    "\n",
    "# Test reflector\n",
    "reflector = SelfReflectorAgent()\n",
    "test_reflection = reflector.process(test_plan)\n",
    "\n",
    "print(f\"✅ Self-Reflector Agent ready!\")\n",
    "print(f\"   Test reflection success: {test_reflection['overall_success']}\")\n",
    "print(f\"   Test recommendations: {len(test_reflection['recommendations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333eb2c5",
   "metadata": {},
   "source": [
    "## 🎯 Coordinator Agent\n",
    "\n",
    "Master agent that orchestrates the entire agentic system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea19716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Gemini API configured for answer synthesis\n",
      "🎯 Coordinator Agent ready with all sub-agents!\n",
      "   Planner: ActionPlanner\n",
      "   Executor: ToolExecutor\n",
      "   Reflector: SelfReflector\n",
      "   Available Tools: 5\n"
     ]
    }
   ],
   "source": [
    "class CoordinatorAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Coordinator\", AgentType.COORDINATOR)\n",
    "        \n",
    "        # Initialize sub-agents\n",
    "        self.planner = ActionPlannerAgent()\n",
    "        self.executor = ToolExecutorAgent()\n",
    "        self.reflector = SelfReflectorAgent()\n",
    "        \n",
    "        # Configuration\n",
    "        self.max_iterations = 3\n",
    "        self.max_revisions = 2\n",
    "        \n",
    "        # LLM for answer synthesis\n",
    "        self.has_llm = False\n",
    "        api_key = os.getenv('GEMINI_API_KEY')\n",
    "        if api_key:\n",
    "            try:\n",
    "                genai.configure(api_key=api_key)\n",
    "                self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "                self.has_llm = True\n",
    "                print(\"🤖 Gemini API configured for answer synthesis\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Gemini error: {e}\")\n",
    "        else:\n",
    "            print(\"⚠️ No Gemini API key. Using template synthesis.\")\n",
    "    \n",
    "    def process(self, query: str) -> AgenticResponse:\n",
    "        \"\"\"Main coordination process\"\"\"\n",
    "        print(f\"\\n🎯 Coordinator processing: '{query}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        iterations = 0\n",
    "        current_plan = None\n",
    "        final_reflection = None\n",
    "        reasoning_steps = []\n",
    "        tool_usage = {tool_type.value: 0 for tool_type in ToolType}\n",
    "        \n",
    "        # Step 1: Initial Planning\n",
    "        print(\"📋 Step 1: Creating execution plan...\")\n",
    "        current_plan = self.planner.process(query)\n",
    "        reasoning_steps.append(f\"Created plan with {len(current_plan.tasks)} tasks\")\n",
    "        \n",
    "        # Iterative execution and refinement\n",
    "        while iterations < self.max_iterations:\n",
    "            iterations += 1\n",
    "            print(f\"\\n🔄 Iteration {iterations}\")\n",
    "            \n",
    "            # Step 2: Execute Plan\n",
    "            print(f\"⚡ Step 2: Executing plan (Iteration {iterations})...\")\n",
    "            executed_plan = self.executor.execute_plan(current_plan)\n",
    "            \n",
    "            # Update tool usage statistics\n",
    "            for task in executed_plan.tasks:\n",
    "                if task.status == PlanStatus.COMPLETED:\n",
    "                    tool_usage[task.tool_required.value] += 1\n",
    "            \n",
    "            reasoning_steps.append(f\"Iteration {iterations}: Executed {len(executed_plan.tasks)} tasks\")\n",
    "            \n",
    "            # Step 3: Reflection and Validation\n",
    "            print(f\"🤔 Step 3: Reflecting on results (Iteration {iterations})...\")\n",
    "            reflection = self.reflector.process(executed_plan)\n",
    "            final_reflection = reflection\n",
    "            \n",
    "            reasoning_steps.append(\n",
    "                f\"Iteration {iterations}: Reflection - Success: {reflection['overall_success']}, \"\n",
    "                f\"Confidence: {reflection['confidence_score']:.2f}\"\n",
    "            )\n",
    "            \n",
    "            # Check if we should continue iterating\n",
    "            if reflection['overall_success'] and not reflection['should_revise']:\n",
    "                print(f\"✅ Plan successful! Breaking iteration loop.\")\n",
    "                current_plan = executed_plan\n",
    "                break\n",
    "            \n",
    "            # Step 4: Plan Revision (if needed and possible)\n",
    "            if reflection['should_revise'] and current_plan.revised_count < self.max_revisions:\n",
    "                print(f\"🔄 Step 4: Revising plan based on reflection...\")\n",
    "                \n",
    "                failed_tasks = [t for t in executed_plan.tasks if t.status == PlanStatus.FAILED]\n",
    "                if failed_tasks:\n",
    "                    # Revise plan with failed task\n",
    "                    current_plan = self.planner.revise_plan(\n",
    "                        executed_plan, failed_tasks[0], \"Task failed during execution\"\n",
    "                    )\n",
    "                    reasoning_steps.append(f\"Iteration {iterations}: Revised plan due to failed tasks\")\n",
    "                else:\n",
    "                    # No failed tasks but reflection suggests revision\n",
    "                    print(f\"   ⚠️ Reflection suggests revision but no failed tasks found\")\n",
    "                    current_plan = executed_plan\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"   ⚠️ Maximum revisions reached or revision not recommended\")\n",
    "                current_plan = executed_plan\n",
    "                break\n",
    "        \n",
    "        # Step 5: Synthesize Final Answer\n",
    "        print(f\"\\n🧠 Step 5: Synthesizing final answer...\")\n",
    "        final_answer = self._synthesize_answer(query, current_plan, final_reflection)\n",
    "        reasoning_steps.append(\"Synthesized final answer from execution results\")\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        processing_time = time.time() - start_time\n",
    "        confidence_score = final_reflection['confidence_score'] if final_reflection else 0.0\n",
    "        \n",
    "        # Create response\n",
    "        response = AgenticResponse(\n",
    "            query=query,\n",
    "            final_answer=final_answer,\n",
    "            execution_plan=current_plan,\n",
    "            tool_usage=tool_usage,\n",
    "            confidence_score=confidence_score,\n",
    "            reasoning_steps=reasoning_steps,\n",
    "            processing_time=processing_time,\n",
    "            iterations=iterations\n",
    "        )\n",
    "        \n",
    "        self.update_stats(final_reflection['overall_success'] if final_reflection else False)\n",
    "        \n",
    "        print(f\"\\n🎉 Processing complete!\")\n",
    "        print(f\"   Iterations: {iterations}\")\n",
    "        print(f\"   Processing Time: {processing_time:.2f}s\")\n",
    "        print(f\"   Final Confidence: {confidence_score:.2f}\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _synthesize_answer(self, query: str, plan: Plan, reflection: Dict[str, Any]) -> str:\n",
    "        \"\"\"Synthesize final answer from execution results\"\"\"\n",
    "        \n",
    "        if self.has_llm:\n",
    "            return self._synthesize_with_llm(query, plan, reflection)\n",
    "        else:\n",
    "            return self._synthesize_with_template(query, plan, reflection)\n",
    "    \n",
    "    def _synthesize_with_llm(self, query: str, plan: Plan, reflection: Dict[str, Any]) -> str:\n",
    "        \"\"\"Use LLM for sophisticated answer synthesis\"\"\"\n",
    "        \n",
    "        # Prepare context from execution results\n",
    "        context_parts = []\n",
    "        for task in plan.tasks:\n",
    "            if task.status == PlanStatus.COMPLETED and task.result:\n",
    "                context_parts.append(\n",
    "                    f\"Task: {task.description}\\n\"\n",
    "                    f\"Tool Used: {task.tool_required.value}\\n\"\n",
    "                    f\"Result: {str(task.result)[:500]}...\\n\"\n",
    "                    f\"Confidence: {task.confidence:.2f}\\n\"\n",
    "                )\n",
    "        \n",
    "        context = \"\\n\" + \"=\"*50 + \"\\n\".join(context_parts)\n",
    "        \n",
    "        # Create synthesis prompt\n",
    "        prompt = f\"\"\"You are an AI assistant that synthesizes information from multiple sources to provide comprehensive answers.\n",
    "\n",
    "Original Query: {query}\n",
    "\n",
    "Execution Context:\n",
    "- Plan executed with {len(plan.tasks)} tasks\n",
    "- {len([t for t in plan.tasks if t.status == PlanStatus.COMPLETED])} tasks completed successfully\n",
    "- Overall confidence: {reflection['confidence_score']:.2f}\n",
    "- Plan revised {plan.revised_count} times\n",
    "\n",
    "Task Results:\n",
    "{context}\n",
    "\n",
    "Please synthesize a comprehensive, accurate answer to the original query based on the execution results above. \n",
    "Focus on providing value and directly addressing what the user asked.\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error in LLM synthesis: {str(e)}. Falling back to template synthesis.\"\n",
    "    \n",
    "    def _synthesize_with_template(self, query: str, plan: Plan, reflection: Dict[str, Any]) -> str:\n",
    "        \"\"\"Template-based answer synthesis\"\"\"\n",
    "        \n",
    "        completed_tasks = [t for t in plan.tasks if t.status == PlanStatus.COMPLETED]\n",
    "        \n",
    "        if not completed_tasks:\n",
    "            return f\"I apologize, but I was unable to gather sufficient information to answer your question: '{query}'. All execution tasks failed.\"\n",
    "        \n",
    "        answer_parts = []\n",
    "        answer_parts.append(f\"Based on my analysis of '{query}', here's what I found:\\n\")\n",
    "        \n",
    "        # Include results from completed tasks\n",
    "        for i, task in enumerate(completed_tasks[:3], 1):  # Limit to top 3 results\n",
    "            if task.result:\n",
    "                result_text = str(task.result)\n",
    "                if len(result_text) > 300:\n",
    "                    result_text = result_text[:300] + \"...\"\n",
    "                \n",
    "                answer_parts.append(f\"{i}. **{task.task_type.value.title()} Results** (Tool: {task.tool_required.value}):\")\n",
    "                answer_parts.append(f\"   {result_text}\")\n",
    "                answer_parts.append(f\"   (Confidence: {task.confidence:.2f})\\n\")\n",
    "        \n",
    "        # Add summary\n",
    "        answer_parts.append(f\"**Summary**: Completed {len(completed_tasks)} out of {len(plan.tasks)} planned tasks with an overall confidence of {reflection['confidence_score']:.2f}.\")\n",
    "        \n",
    "        if plan.revised_count > 0:\n",
    "            answer_parts.append(f\" The plan was revised {plan.revised_count} times to improve results.\")\n",
    "        \n",
    "        return \"\\n\".join(answer_parts)\n",
    "    \n",
    "    def get_system_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive system status\"\"\"\n",
    "        return {\n",
    "            'coordinator': self.get_info(),\n",
    "            'planner': self.planner.get_info(),\n",
    "            'executor': self.executor.get_info(),\n",
    "            'reflector': self.reflector.get_info(),\n",
    "            'tool_stats': self.executor.get_tool_stats(),\n",
    "            'execution_summary': self.executor.get_execution_summary(),\n",
    "            'reflection_summary': self.reflector.get_reflection_summary()\n",
    "        }\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = CoordinatorAgent()\n",
    "print(\"🎯 Coordinator Agent ready with all sub-agents!\")\n",
    "print(f\"   Planner: {coordinator.planner.name}\")\n",
    "print(f\"   Executor: {coordinator.executor.name}\")\n",
    "print(f\"   Reflector: {coordinator.reflector.name}\")\n",
    "print(f\"   Available Tools: {len(coordinator.executor.tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f25d78",
   "metadata": {},
   "source": [
    "## 🤖 Complete Agentic RAG System\n",
    "\n",
    "Integrate everything into the complete autonomous system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6504ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Initializing Agentic RAG System...\n",
      "🤖 Gemini API configured for answer synthesis\n",
      "✅ Agentic RAG System initialized!\n",
      "🎯 Coordinator: Coordinator\n",
      "🛠️ Available Tools: 5\n",
      "📊 Max Iterations: 3\n",
      "\n",
      "🚀 Complete Agentic RAG System ready!\n"
     ]
    }
   ],
   "source": [
    "class AgenticRAGSystem:\n",
    "    def __init__(self):\n",
    "        print(\"🤖 Initializing Agentic RAG System...\")\n",
    "        \n",
    "        # Initialize the coordinator (which manages all other agents)\n",
    "        self.coordinator = CoordinatorAgent()\n",
    "        \n",
    "        # System configuration\n",
    "        self.config = {\n",
    "            'max_query_length': 500,\n",
    "            'timeout_seconds': 120,\n",
    "            'enable_parallel_execution': False,  # Future enhancement\n",
    "            'enable_learning': False,  # Future enhancement\n",
    "        }\n",
    "        \n",
    "        # System statistics\n",
    "        self.total_queries = 0\n",
    "        self.successful_queries = 0\n",
    "        self.total_processing_time = 0.0\n",
    "        self.query_history = []\n",
    "        \n",
    "        print(\"✅ Agentic RAG System initialized!\")\n",
    "        print(f\"🎯 Coordinator: {self.coordinator.name}\")\n",
    "        print(f\"🛠️ Available Tools: {len(self.coordinator.executor.tools)}\")\n",
    "        print(f\"📊 Max Iterations: {self.coordinator.max_iterations}\")\n",
    "    \n",
    "    def solve(self, query: str, user_id: str = None) -> AgenticResponse:\n",
    "        \"\"\"Main entry point for solving queries\"\"\"\n",
    "        \n",
    "        # Validate input\n",
    "        if not query or len(query.strip()) == 0:\n",
    "            raise ValueError(\"Query cannot be empty\")\n",
    "        \n",
    "        if len(query) > self.config['max_query_length']:\n",
    "            raise ValueError(f\"Query too long. Maximum length: {self.config['max_query_length']}\")\n",
    "        \n",
    "        # Process query\n",
    "        self.total_queries += 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"📝 Query: {query}\")\n",
    "            print(f\"👤 User: {user_id or 'Anonymous'}\")\n",
    "            print(f\"🕐 Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            \n",
    "            # Delegate to coordinator\n",
    "            response = self.coordinator.process(query)\n",
    "            \n",
    "            # Update statistics\n",
    "            processing_time = time.time() - start_time\n",
    "            self.total_processing_time += processing_time\n",
    "            \n",
    "            if response.confidence_score > 0.5:  # Threshold for success\n",
    "                self.successful_queries += 1\n",
    "            \n",
    "            # Store in history\n",
    "            query_record = {\n",
    "                'query': query,\n",
    "                'user_id': user_id,\n",
    "                'timestamp': datetime.now(),\n",
    "                'processing_time': processing_time,\n",
    "                'confidence': response.confidence_score,\n",
    "                'iterations': response.iterations,\n",
    "                'tools_used': sum(response.tool_usage.values()),\n",
    "                'success': response.confidence_score > 0.5\n",
    "            }\n",
    "            self.query_history.append(query_record)\n",
    "            \n",
    "            print(f\"\\n🎉 QUERY SOLVED SUCCESSFULLY!\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            self.total_processing_time += processing_time\n",
    "            \n",
    "            # Create error response\n",
    "            error_response = AgenticResponse(\n",
    "                query=query,\n",
    "                final_answer=f\"I encountered an error while processing your query: {str(e)}\",\n",
    "                execution_plan=Plan(\"error\", query, []),\n",
    "                tool_usage={tool_type.value: 0 for tool_type in ToolType},\n",
    "                confidence_score=0.0,\n",
    "                reasoning_steps=[f\"Error occurred: {str(e)}\"],\n",
    "                processing_time=processing_time,\n",
    "                iterations=0\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n❌ ERROR OCCURRED: {str(e)}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            return error_response\n",
    "    \n",
    "    def get_system_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive system performance metrics\"\"\"\n",
    "        \n",
    "        avg_processing_time = (\n",
    "            self.total_processing_time / max(self.total_queries, 1)\n",
    "        )\n",
    "        success_rate = (\n",
    "            self.successful_queries / max(self.total_queries, 1) * 100\n",
    "        )\n",
    "        \n",
    "        recent_queries = self.query_history[-10:] if self.query_history else []\n",
    "        \n",
    "        return {\n",
    "            'system_overview': {\n",
    "                'total_queries': self.total_queries,\n",
    "                'successful_queries': self.successful_queries,\n",
    "                'success_rate': success_rate,\n",
    "                'avg_processing_time': avg_processing_time,\n",
    "                'total_processing_time': self.total_processing_time\n",
    "            },\n",
    "            'agent_performance': self.coordinator.get_system_status(),\n",
    "            'recent_activity': recent_queries,\n",
    "            'configuration': self.config\n",
    "        }\n",
    "    \n",
    "    def get_performance_summary(self) -> str:\n",
    "        \"\"\"Get human-readable performance summary\"\"\"\n",
    "        metrics = self.get_system_metrics()\n",
    "        overview = metrics['system_overview']\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "🤖 AGENTIC RAG SYSTEM PERFORMANCE SUMMARY\n",
    "{'='*50}\n",
    "\n",
    "📊 Overall Performance:\n",
    "   • Total Queries Processed: {overview['total_queries']}\n",
    "   • Successful Queries: {overview['successful_queries']}\n",
    "   • Success Rate: {overview['success_rate']:.1f}%\n",
    "   • Average Processing Time: {overview['avg_processing_time']:.2f}s\n",
    "\n",
    "🤖 Agent Performance:\n",
    "   • Coordinator Success Rate: {self.coordinator.get_success_rate()*100:.1f}%\n",
    "   • Planner Success Rate: {self.coordinator.planner.get_success_rate()*100:.1f}%\n",
    "   • Executor Success Rate: {self.coordinator.executor.get_success_rate()*100:.1f}%\n",
    "   • Reflector Success Rate: {self.coordinator.reflector.get_success_rate()*100:.1f}%\n",
    "\n",
    "🛠️ Tool Usage:\n",
    "\"\"\"\n",
    "        \n",
    "        tool_stats = metrics['agent_performance']['tool_stats']\n",
    "        for tool_name, stats in tool_stats.items():\n",
    "            usage_count = stats['usage_count']\n",
    "            success_rate = stats['tool_stats']['success_rate'] * 100\n",
    "            summary += f\"   • {tool_name}: {usage_count} uses ({success_rate:.1f}% success)\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize the complete system\n",
    "agentic_rag = AgenticRAGSystem()\n",
    "print(\"\\n🚀 Complete Agentic RAG System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f06b7f",
   "metadata": {},
   "source": [
    "## 🧪 Comprehensive Testing Suite\n",
    "\n",
    "Test the agentic system with various query types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad85a424-1d1a-4625-afad-c321ecd8ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪 AGENTIC RAG TEST SUITE 🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪🧪\n",
      "\n",
      "======================================================================\n",
      "🔬 TEST CASE 1: Simple Information Query\n",
      "❓ Query: 'What is machine learning?'\n",
      "👤 User: test_user_1\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\n",
      "================================================================================\n",
      "📝 Query: What is machine learning?\n",
      "👤 User: test_user_1\n",
      "🕐 Started: 12:01:24\n",
      "\n",
      "🎯 Coordinator processing: 'What is machine learning?'\n",
      "============================================================\n",
      "📋 Step 1: Creating execution plan...\n",
      "\n",
      "🔄 Iteration 1\n",
      "⚡ Step 2: Executing plan (Iteration 1)...\n",
      "🎯 Executing plan: What is machine learning?\n",
      "⚡ Executing: Search for information about: What is machine learning?\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Analyze gathered information about: What is machine learning?\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Synthesize final answer for: What is machine learning?\n",
      "   ✅ Completed in 0.02s (Confidence: 0.90)\n",
      "🤔 Step 3: Reflecting on results (Iteration 1)...\n",
      "🤔 Reflecting on plan execution...\n",
      "   📊 Confidence: 0.83\n",
      "   📈 Completeness: 1.00\n",
      "   🎯 Overall Success: True\n",
      "   ⚠️  Issues: 1\n",
      "✅ Plan successful! Breaking iteration loop.\n",
      "\n",
      "🧠 Step 5: Synthesizing final answer...\n",
      "\n",
      "🎉 Processing complete!\n",
      "   Iterations: 1\n",
      "   Processing Time: 2.67s\n",
      "   Final Confidence: 0.83\n",
      "\n",
      "🎉 QUERY SOLVED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "📊 TEST RESULTS:\n",
      "   ✅ Success: True\n",
      "   🎯 Confidence: 0.83\n",
      "   🔄 Iterations: 1\n",
      "   ⏱️ Processing Time: 2.67s\n",
      "   🛠️ Tools Used: web_search, retriever, analyzer\n",
      "   🧰 Expected Tools: web_search, retrieval\n",
      "   🔧 Tools Match: False\n",
      "\n",
      "======================================================================\n",
      "🔬 TEST CASE 2: Mathematical Calculation\n",
      "❓ Query: 'Calculate the compound interest on $1000 at 5% annually for 3 years'\n",
      "👤 User: test_user_2\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\n",
      "================================================================================\n",
      "📝 Query: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "👤 User: test_user_2\n",
      "🕐 Started: 12:01:26\n",
      "\n",
      "🎯 Coordinator processing: 'Calculate the compound interest on $1000 at 5% annually for 3 years'\n",
      "============================================================\n",
      "📋 Step 1: Creating execution plan...\n",
      "\n",
      "🔄 Iteration 1\n",
      "⚡ Step 2: Executing plan (Iteration 1)...\n",
      "🎯 Executing plan: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "⚡ Executing: Perform calculations related to: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "   ✅ Completed in 0.00s (Confidence: 0.00)\n",
      "⚡ Executing: Verify information accuracy for: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "   ✅ Completed in 0.00s (Confidence: 0.85)\n",
      "⚡ Executing: Synthesize final answer for: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "🤔 Step 3: Reflecting on results (Iteration 1)...\n",
      "🤔 Reflecting on plan execution...\n",
      "   📊 Confidence: 0.55\n",
      "   📈 Completeness: 1.00\n",
      "   🎯 Overall Success: False\n",
      "   ⚠️  Issues: 3\n",
      "🔄 Step 4: Revising plan based on reflection...\n",
      "   ⚠️ Reflection suggests revision but no failed tasks found\n",
      "\n",
      "🧠 Step 5: Synthesizing final answer...\n",
      "\n",
      "🎉 Processing complete!\n",
      "   Iterations: 1\n",
      "   Processing Time: 2.08s\n",
      "   Final Confidence: 0.55\n",
      "\n",
      "🎉 QUERY SOLVED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "📊 TEST RESULTS:\n",
      "   ✅ Success: True\n",
      "   🎯 Confidence: 0.55\n",
      "   🔄 Iterations: 1\n",
      "   ⏱️ Processing Time: 2.08s\n",
      "   🛠️ Tools Used: calculator, database, analyzer\n",
      "   🧰 Expected Tools: calculator\n",
      "   🔧 Tools Match: False\n",
      "\n",
      "======================================================================\n",
      "🔬 TEST CASE 3: Research and Analysis\n",
      "❓ Query: 'Analyze the impact of quantum computing on current encryption methods'\n",
      "👤 User: test_user_3\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\n",
      "================================================================================\n",
      "📝 Query: Analyze the impact of quantum computing on current encryption methods\n",
      "👤 User: test_user_3\n",
      "🕐 Started: 12:01:28\n",
      "\n",
      "🎯 Coordinator processing: 'Analyze the impact of quantum computing on current encryption methods'\n",
      "============================================================\n",
      "📋 Step 1: Creating execution plan...\n",
      "\n",
      "🔄 Iteration 1\n",
      "⚡ Step 2: Executing plan (Iteration 1)...\n",
      "🎯 Executing plan: Analyze the impact of quantum computing on current encryption methods\n",
      "⚡ Executing: Search for information about: Analyze the impact of quantum computing on current encryption methods\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Analyze gathered information about: Analyze the impact of quantum computing on current encryption methods\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Synthesize final answer for: Analyze the impact of quantum computing on current encryption methods\n",
      "   ✅ Completed in 0.01s (Confidence: 0.90)\n",
      "🤔 Step 3: Reflecting on results (Iteration 1)...\n",
      "🤔 Reflecting on plan execution...\n",
      "   📊 Confidence: 0.83\n",
      "   📈 Completeness: 1.00\n",
      "   🎯 Overall Success: True\n",
      "   ⚠️  Issues: 1\n",
      "✅ Plan successful! Breaking iteration loop.\n",
      "\n",
      "🧠 Step 5: Synthesizing final answer...\n",
      "\n",
      "🎉 Processing complete!\n",
      "   Iterations: 1\n",
      "   Processing Time: 2.41s\n",
      "   Final Confidence: 0.83\n",
      "\n",
      "🎉 QUERY SOLVED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "📊 TEST RESULTS:\n",
      "   ✅ Success: True\n",
      "   🎯 Confidence: 0.83\n",
      "   🔄 Iterations: 1\n",
      "   ⏱️ Processing Time: 2.41s\n",
      "   🛠️ Tools Used: web_search, retriever, analyzer\n",
      "   🧰 Expected Tools: web_search, retrieval, analyzer\n",
      "   🔧 Tools Match: False\n",
      "\n",
      "======================================================================\n",
      "🔬 TEST CASE 4: Database Query\n",
      "❓ Query: 'Find information about technology companies founded after 1990'\n",
      "👤 User: test_user_4\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\n",
      "================================================================================\n",
      "📝 Query: Find information about technology companies founded after 1990\n",
      "👤 User: test_user_4\n",
      "🕐 Started: 12:01:31\n",
      "\n",
      "🎯 Coordinator processing: 'Find information about technology companies founded after 1990'\n",
      "============================================================\n",
      "📋 Step 1: Creating execution plan...\n",
      "\n",
      "🔄 Iteration 1\n",
      "⚡ Step 2: Executing plan (Iteration 1)...\n",
      "🎯 Executing plan: Find information about technology companies founded after 1990\n",
      "⚡ Executing: Search for information about: Find information about technology companies founded after 1990\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Analyze gathered information about: Find information about technology companies founded after 1990\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "⚡ Executing: Synthesize final answer for: Find information about technology companies founded after 1990\n",
      "   ✅ Completed in 0.01s (Confidence: 0.90)\n",
      "🤔 Step 3: Reflecting on results (Iteration 1)...\n",
      "🤔 Reflecting on plan execution...\n",
      "   📊 Confidence: 0.83\n",
      "   📈 Completeness: 1.00\n",
      "   🎯 Overall Success: True\n",
      "   ⚠️  Issues: 1\n",
      "✅ Plan successful! Breaking iteration loop.\n",
      "\n",
      "🧠 Step 5: Synthesizing final answer...\n",
      "\n",
      "🎉 Processing complete!\n",
      "   Iterations: 1\n",
      "   Processing Time: 1.29s\n",
      "   Final Confidence: 0.83\n",
      "\n",
      "🎉 QUERY SOLVED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "📊 TEST RESULTS:\n",
      "   ✅ Success: True\n",
      "   🎯 Confidence: 0.83\n",
      "   🔄 Iterations: 1\n",
      "   ⏱️ Processing Time: 1.29s\n",
      "   🛠️ Tools Used: web_search, retriever, analyzer\n",
      "   🧰 Expected Tools: database\n",
      "   🔧 Tools Match: False\n",
      "\n",
      "======================================================================\n",
      "🔬 TEST CASE 5: Complex Multi-Step Query\n",
      "❓ Query: 'Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference'\n",
      "👤 User: test_user_5\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "🤖 AGENTIC RAG SYSTEM - SOLVING QUERY\n",
      "================================================================================\n",
      "📝 Query: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "👤 User: test_user_5\n",
      "🕐 Started: 12:01:32\n",
      "\n",
      "🎯 Coordinator processing: 'Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference'\n",
      "============================================================\n",
      "📋 Step 1: Creating execution plan...\n",
      "\n",
      "🔄 Iteration 1\n",
      "⚡ Step 2: Executing plan (Iteration 1)...\n",
      "🎯 Executing plan: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "⚡ Executing: Perform calculations related to: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "   ✅ Completed in 0.00s (Confidence: 0.00)\n",
      "⚡ Executing: Verify information accuracy for: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "   ✅ Completed in 0.00s (Confidence: 0.85)\n",
      "⚡ Executing: Synthesize final answer for: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "   ✅ Completed in 0.00s (Confidence: 0.80)\n",
      "🤔 Step 3: Reflecting on results (Iteration 1)...\n",
      "🤔 Reflecting on plan execution...\n",
      "   📊 Confidence: 0.55\n",
      "   📈 Completeness: 1.00\n",
      "   🎯 Overall Success: False\n",
      "   ⚠️  Issues: 3\n",
      "🔄 Step 4: Revising plan based on reflection...\n",
      "   ⚠️ Reflection suggests revision but no failed tasks found\n",
      "\n",
      "🧠 Step 5: Synthesizing final answer...\n",
      "\n",
      "🎉 Processing complete!\n",
      "   Iterations: 1\n",
      "   Processing Time: 0.92s\n",
      "   Final Confidence: 0.55\n",
      "\n",
      "🎉 QUERY SOLVED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "📊 TEST RESULTS:\n",
      "   ✅ Success: True\n",
      "   🎯 Confidence: 0.55\n",
      "   🔄 Iterations: 1\n",
      "   ⏱️ Processing Time: 0.92s\n",
      "   🛠️ Tools Used: calculator, database, analyzer\n",
      "   🧰 Expected Tools: database, calculator, analyzer\n",
      "   🔧 Tools Match: True\n",
      "\n",
      "======================================================================\n",
      "📈 TEST SUITE SUMMARY\n",
      "======================================================================\n",
      "   ✅ Passed: 5\n",
      "   ❌ Failed: 0\n",
      "   ⏱️ Total Time: 9.36s\n",
      "   🎯 Average Confidence: 0.72\n",
      "\n",
      "🔍 DETAILED RESULTS:\n",
      "\n",
      "Test 1: Simple Information Query\n",
      "   Query: What is machine learning?\n",
      "   Status: ✅ PASSED\n",
      "   Confidence: 0.83\n",
      "   Tools Used: web_search, retriever, analyzer\n",
      "   Expected Tools: web_search, retrieval\n",
      "   Tools Match: False\n",
      "\n",
      "Test 2: Mathematical Calculation\n",
      "   Query: Calculate the compound interest on $1000 at 5% annually for 3 years\n",
      "   Status: ✅ PASSED\n",
      "   Confidence: 0.55\n",
      "   Tools Used: calculator, database, analyzer\n",
      "   Expected Tools: calculator\n",
      "   Tools Match: False\n",
      "\n",
      "Test 3: Research and Analysis\n",
      "   Query: Analyze the impact of quantum computing on current encryption methods\n",
      "   Status: ✅ PASSED\n",
      "   Confidence: 0.83\n",
      "   Tools Used: web_search, retriever, analyzer\n",
      "   Expected Tools: web_search, retrieval, analyzer\n",
      "   Tools Match: False\n",
      "\n",
      "Test 4: Database Query\n",
      "   Query: Find information about technology companies founded after 1990\n",
      "   Status: ✅ PASSED\n",
      "   Confidence: 0.83\n",
      "   Tools Used: web_search, retriever, analyzer\n",
      "   Expected Tools: database\n",
      "   Tools Match: False\n",
      "\n",
      "Test 5: Complex Multi-Step Query\n",
      "   Query: Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\n",
      "   Status: ✅ PASSED\n",
      "   Confidence: 0.55\n",
      "   Tools Used: calculator, database, analyzer\n",
      "   Expected Tools: database, calculator, analyzer\n",
      "   Tools Match: True\n",
      "\n",
      "📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊 SYSTEM PERFORMANCE 📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊📊\n",
      "\n",
      "🤖 AGENTIC RAG SYSTEM PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "\n",
      "📊 Overall Performance:\n",
      "   • Total Queries Processed: 5\n",
      "   • Successful Queries: 5\n",
      "   • Success Rate: 100.0%\n",
      "   • Average Processing Time: 1.87s\n",
      "\n",
      "🤖 Agent Performance:\n",
      "   • Coordinator Success Rate: 60.0%\n",
      "   • Planner Success Rate: 100.0%\n",
      "   • Executor Success Rate: 100.0%\n",
      "   • Reflector Success Rate: 60.0%\n",
      "\n",
      "🛠️ Tool Usage:\n",
      "   • web_search: 3 uses (100.0% success)\n",
      "   • calculator: 2 uses (0.0% success)\n",
      "   • database: 2 uses (100.0% success)\n",
      "   • retriever: 3 uses (100.0% success)\n",
      "   • analyzer: 5 uses (100.0% success)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_agentic_test_suite():\n",
    "    print(\"\\n\" + \"🧪\"*20 + \" AGENTIC RAG TEST SUITE \" + \"🧪\"*20)\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Simple Information Query\",\n",
    "            \"query\": \"What is machine learning?\",\n",
    "            \"expected_tools\": [\"web_search\", \"retrieval\"],\n",
    "            \"user_id\": \"test_user_1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mathematical Calculation\",\n",
    "            \"query\": \"Calculate the compound interest on $1000 at 5% annually for 3 years\",\n",
    "            \"expected_tools\": [\"calculator\"],\n",
    "            \"user_id\": \"test_user_2\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Research and Analysis\",\n",
    "            \"query\": \"Analyze the impact of quantum computing on current encryption methods\",\n",
    "            \"expected_tools\": [\"web_search\", \"retrieval\", \"analyzer\"],\n",
    "            \"user_id\": \"test_user_3\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Database Query\",\n",
    "            \"query\": \"Find information about technology companies founded after 1990\",\n",
    "            \"expected_tools\": [\"database\"],\n",
    "            \"user_id\": \"test_user_4\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Complex Multi-Step Query\",\n",
    "            \"query\": \"Compare the revenue growth of Apple and Microsoft, then calculate the percentage difference\",\n",
    "            \"expected_tools\": [\"database\", \"calculator\", \"analyzer\"],\n",
    "            \"user_id\": \"test_user_5\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"🔬 TEST CASE {i}: {test_case['name']}\")\n",
    "        print(f\"❓ Query: '{test_case['query']}'\")\n",
    "        print(f\"👤 User: {test_case['user_id']}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        try:\n",
    "            # Execute test\n",
    "            response = agentic_rag.solve(\n",
    "                test_case['query'], \n",
    "                test_case['user_id']\n",
    "            )\n",
    "            \n",
    "            # Analyze results\n",
    "            tools_used = [tool for tool, count in response.tool_usage.items() if count > 0]\n",
    "            expected_tools = test_case['expected_tools']\n",
    "            tools_match = set(tools_used) == set(expected_tools)\n",
    "            \n",
    "            test_result = {\n",
    "                \"test_case\": test_case['name'],\n",
    "                \"query\": test_case['query'],\n",
    "                \"success\": response.confidence_score > 0.5,\n",
    "                \"confidence\": response.confidence_score,\n",
    "                \"iterations\": response.iterations,\n",
    "                \"processing_time\": response.processing_time,\n",
    "                \"tools_used\": tools_used,\n",
    "                \"expected_tools\": expected_tools,\n",
    "                \"tools_match\": tools_match,\n",
    "                \"response\": response\n",
    "            }\n",
    "            \n",
    "            results.append(test_result)\n",
    "            \n",
    "            print(f\"\\n📊 TEST RESULTS:\")\n",
    "            print(f\"   ✅ Success: {test_result['success']}\")\n",
    "            print(f\"   🎯 Confidence: {test_result['confidence']:.2f}\")\n",
    "            print(f\"   🔄 Iterations: {test_result['iterations']}\")\n",
    "            print(f\"   ⏱️ Processing Time: {test_result['processing_time']:.2f}s\")\n",
    "            print(f\"   🛠️ Tools Used: {', '.join(test_result['tools_used'])}\")\n",
    "            print(f\"   🧰 Expected Tools: {', '.join(test_result['expected_tools'])}\")\n",
    "            print(f\"   🔧 Tools Match: {test_result['tools_match']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Test failed with error: {str(e)}\")\n",
    "            results.append({\n",
    "                \"test_case\": test_case['name'],\n",
    "                \"error\": str(e),\n",
    "                \"success\": False\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"📈 TEST SUITE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    passed = sum(1 for r in results if r.get('success', False))\n",
    "    failed = len(results) - passed\n",
    "    \n",
    "    print(f\"   ✅ Passed: {passed}\")\n",
    "    print(f\"   ❌ Failed: {failed}\")\n",
    "    print(f\"   ⏱️ Total Time: {total_time:.2f}s\")\n",
    "    print(f\"   🎯 Average Confidence: {np.mean([r.get('confidence', 0) for r in results if 'confidence' in r]):.2f}\")\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n🔍 DETAILED RESULTS:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nTest {i}: {result['test_case']}\")\n",
    "        print(f\"   Query: {result['query']}\")\n",
    "        if 'success' in result:\n",
    "            print(f\"   Status: {'✅ PASSED' if result['success'] else '❌ FAILED'}\")\n",
    "            print(f\"   Confidence: {result.get('confidence', 0):.2f}\")\n",
    "            print(f\"   Tools Used: {', '.join(result.get('tools_used', []))}\")\n",
    "            print(f\"   Expected Tools: {', '.join(result.get('expected_tools', []))}\")\n",
    "            print(f\"   Tools Match: {result.get('tools_match', False)}\")\n",
    "        else:\n",
    "            print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test suite\n",
    "test_results = run_agentic_test_suite()\n",
    "\n",
    "# Print system performance after testing\n",
    "print(\"\\n\" + \"📊\"*20 + \" SYSTEM PERFORMANCE \" + \"📊\"*20)\n",
    "print(agentic_rag.get_performance_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a46b8-4f66-43a4-ab7b-d39c7276f3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
