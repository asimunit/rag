{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Advanced RAG Implementation: AI Research Assistant\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements an **Advanced RAG system** that goes beyond basic retrieve-and-generate. We'll build a sophisticated AI Research Assistant with:\n",
    "\n",
    "### üéØ Advanced Features\n",
    "- **Query Enhancement**: Expansion, decomposition, and reformulation\n",
    "- **Hybrid Search**: Combining semantic and keyword search\n",
    "- **Intelligent Reranking**: Cross-encoder models for relevance scoring\n",
    "- **Multi-Query Strategies**: RAG-Fusion with multiple query variations\n",
    "- **Content Filtering**: Quality assessment and relevance filtering\n",
    "- **Contextual Generation**: Enhanced prompting with Gemini\n",
    "\n",
    "### üìö Knowledge Domain\n",
    "**Artificial Intelligence Research** - covering machine learning, neural networks, NLP, computer vision, and AI ethics.\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "```\n",
    "Query ‚Üí Enhancement ‚Üí Hybrid Search ‚Üí Reranking ‚Üí Filtering ‚Üí Generation ‚Üí Response\n",
    "   ‚Üì        ‚Üì           ‚Üì             ‚Üì          ‚Üì           ‚Üì\n",
    "Expand   Semantic+   Cross-encoder  Quality   Context    Gemini\n",
    "Reform   Keyword     Scoring       Filter    Mgmt       API\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation & Dependencies\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: google-generativeai in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: rank-bm25 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: nltk in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: python-dotenv in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: scipy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: Pillow in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: protobuf in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: google-api-python-client in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.173.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: google-api-core in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: pydantic in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: fsspec in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from triton==3.3.1->torch) (58.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages - run this first!\n",
    "!pip install sentence-transformers faiss-cpu google-generativeai rank-bm25 transformers torch scikit-learn numpy nltk python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/rags/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import faiss\n",
    "import google.generativeai as genai\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† AI Research Knowledge Base\n",
    "\n",
    "We'll create a comprehensive knowledge base covering various AI research topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Knowledge base created with 5 AI research documents\n",
      "üìä Categories: {'Neural Networks', 'Computer Vision', 'NLP', 'Machine Learning'}\n"
     ]
    }
   ],
   "source": [
    "# Enhanced AI Research Knowledge Base\n",
    "ai_research_knowledge_base = [\n",
    "    {\n",
    "        \"id\": \"ai_001\",\n",
    "        \"title\": \"Deep Learning Fundamentals\",\n",
    "        \"category\": \"Neural Networks\",\n",
    "        \"content\": \"\"\"Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to model and understand complex patterns in data. Deep neural networks typically contain multiple hidden layers between the input and output layers, allowing them to learn hierarchical representations. Key components include neurons (nodes), weights, biases, activation functions (ReLU, sigmoid, tanh), and backpropagation for training. Popular architectures include feedforward networks, convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) for sequential data, and transformers for natural language processing. Deep learning has revolutionized fields like computer vision, natural language processing, speech recognition, and game playing.\"\"\",\n",
    "        \"keywords\": [\"neural networks\", \"backpropagation\", \"CNN\", \"RNN\", \"transformers\", \"activation functions\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ai_002\",\n",
    "        \"title\": \"Transformer Architecture and Attention Mechanisms\",\n",
    "        \"category\": \"NLP\",\n",
    "        \"content\": \"\"\"The Transformer architecture, introduced in 'Attention Is All You Need', revolutionized natural language processing through the self-attention mechanism. Unlike RNNs, transformers process sequences in parallel, making them more efficient for training. The key innovation is the attention mechanism, which allows the model to focus on different parts of the input sequence when processing each element. Multi-head attention runs multiple attention mechanisms in parallel, capturing different types of relationships. The architecture includes encoder and decoder stacks, each with self-attention and feed-forward layers, plus residual connections and layer normalization. Transformers form the backbone of modern language models like GPT, BERT, and T5, enabling breakthrough performance in machine translation, text generation, and understanding.\"\"\",\n",
    "        \"keywords\": [\"attention mechanism\", \"self-attention\", \"multi-head attention\", \"encoder-decoder\", \"GPT\", \"BERT\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ai_003\",\n",
    "        \"title\": \"Convolutional Neural Networks for Computer Vision\",\n",
    "        \"category\": \"Computer Vision\",\n",
    "        \"content\": \"\"\"Convolutional Neural Networks (CNNs) are specialized neural networks designed for processing grid-like data such as images. CNNs use convolutional layers that apply filters (kernels) across the input to detect features like edges, textures, and patterns. Key components include convolutional layers for feature extraction, pooling layers for dimensionality reduction, and fully connected layers for classification. Popular CNN architectures include LeNet for digit recognition, AlexNet which sparked the deep learning revolution, VGG with very deep networks, ResNet with skip connections to solve vanishing gradients, and more recent architectures like EfficientNet and Vision Transformers. CNNs excel at image classification, object detection, semantic segmentation, and medical image analysis.\"\"\",\n",
    "        \"keywords\": [\"convolution\", \"pooling\", \"filters\", \"kernels\", \"ResNet\", \"image classification\", \"object detection\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ai_004\",\n",
    "        \"title\": \"Reinforcement Learning and Policy Optimization\",\n",
    "        \"category\": \"Machine Learning\",\n",
    "        \"content\": \"\"\"Reinforcement Learning (RL) is a machine learning paradigm where agents learn to make decisions through interaction with an environment to maximize cumulative reward. Key concepts include states, actions, rewards, policies, and value functions. The agent follows a policy (strategy) to select actions, receives rewards, and updates its knowledge. Major approaches include value-based methods (Q-learning, DQN), policy-based methods (REINFORCE, PPO), and actor-critic methods that combine both. Deep RL combines neural networks with RL, enabling breakthroughs in game playing (AlphaGo, Dota 2), robotics, autonomous driving, and resource management. Challenges include sample efficiency, exploration vs exploitation, and stability of training.\"\"\",\n",
    "        \"keywords\": [\"policy\", \"reward\", \"Q-learning\", \"DQN\", \"PPO\", \"actor-critic\", \"exploration\", \"exploitation\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ai_005\",\n",
    "        \"title\": \"Large Language Models and Emergent Capabilities\",\n",
    "        \"category\": \"NLP\",\n",
    "        \"content\": \"\"\"Large Language Models (LLMs) are transformer-based models trained on vast amounts of text data, demonstrating remarkable capabilities in language understanding and generation. Models like GPT-3/4, PaLM, and Claude show emergent abilities that weren't explicitly programmed, including few-shot learning, reasoning, and code generation. Key training techniques include pre-training on diverse text corpora, fine-tuning for specific tasks, and reinforcement learning from human feedback (RLHF) to align with human preferences. LLMs exhibit scaling laws where performance improves predictably with model size, training data, and compute. Applications span chatbots, code assistance, content creation, and scientific research. Challenges include hallucination, bias, computational costs, and ensuring AI safety and alignment.\"\"\",\n",
    "        \"keywords\": [\"LLMs\", \"GPT\", \"emergent abilities\", \"few-shot learning\", \"RLHF\", \"scaling laws\", \"hallucination\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üß† Knowledge base created with {len(ai_research_knowledge_base)} AI research documents\")\n",
    "print(f\"üìä Categories: {set(doc['category'] for doc in ai_research_knowledge_base)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Data Classes and Utilities\n",
    "\n",
    "Let's define structured data classes for better organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Data classes and utilities defined successfully!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    id: str\n",
    "    title: str\n",
    "    content: str\n",
    "    category: str\n",
    "    keywords: List[str]\n",
    "    embedding: Optional[np.ndarray] = None\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    document: Document\n",
    "    score: float\n",
    "    rank: int\n",
    "    source: str  # 'semantic', 'keyword', 'hybrid'\n",
    "\n",
    "@dataclass\n",
    "class EnhancedQuery:\n",
    "    original: str\n",
    "    expanded: List[str]\n",
    "    reformulated: List[str]\n",
    "    keywords: List[str]\n",
    "    intent: str\n",
    "\n",
    "@dataclass\n",
    "class RAGResponse:\n",
    "    query: str\n",
    "    enhanced_query: EnhancedQuery\n",
    "    retrieved_documents: List[SearchResult]\n",
    "    reranked_documents: List[SearchResult]\n",
    "    filtered_documents: List[SearchResult]\n",
    "    generated_answer: str\n",
    "    confidence_score: float\n",
    "    processing_time: float\n",
    "\n",
    "# Utility functions\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s.,!?-]', '', text)  # Remove special chars\n",
    "    return text.strip()\n",
    "\n",
    "def extract_keywords(text: str, top_k: int = 5) -> List[str]:\n",
    "    \"\"\"Extract keywords using simple frequency analysis\"\"\"\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were'}\n",
    "    keywords = [word for word in words if len(word) > 3 and word not in stop_words]\n",
    "    return list(set(keywords[:top_k]))\n",
    "\n",
    "print(\"üìã Data classes and utilities defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Advanced Query Enhancement Module\n",
    "\n",
    "This module implements sophisticated query processing techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query Enhancement Test:\n",
      "Original: What is a transformer in deep learning?\n",
      "Intent: definition\n",
      "Keywords: ['transformer', 'deep', 'what', 'learning']\n",
      "Expanded: ['what is a self-attention in deep learning?', 'what is a transformer in deep learning?']...\n",
      "‚úÖ Query Enhancement Module ready!\n"
     ]
    }
   ],
   "source": [
    "class QueryEnhancer:\n",
    "    def __init__(self):\n",
    "        self.synonym_map = {\n",
    "            'neural network': ['deep learning', 'artificial neural network', 'neural net'],\n",
    "            'machine learning': ['ML', 'artificial intelligence', 'AI'],\n",
    "            'transformer': ['attention mechanism', 'self-attention', 'BERT', 'GPT'],\n",
    "            'CNN': ['convolutional neural network', 'convnet'],\n",
    "            'RNN': ['recurrent neural network', 'LSTM', 'GRU']\n",
    "        }\n",
    "        \n",
    "        self.intent_patterns = {\n",
    "            'definition': [r'what is', r'define', r'explain', r'describe'],\n",
    "            'comparison': [r'difference between', r'compare', r'versus', r'vs'],\n",
    "            'how_to': [r'how to', r'how can', r'steps to', r'procedure'],\n",
    "            'advantages': [r'benefits', r'advantages', r'pros', r'strengths'],\n",
    "            'applications': [r'applications', r'use cases', r'examples', r'where used']\n",
    "        }\n",
    "    \n",
    "    def enhance_query(self, query: str) -> EnhancedQuery:\n",
    "        \"\"\"Enhance query with expansion, reformulation, and intent detection\"\"\"\n",
    "        original = query.lower().strip()\n",
    "        \n",
    "        # Extract keywords\n",
    "        keywords = extract_keywords(original)\n",
    "        \n",
    "        # Detect intent\n",
    "        intent = self._detect_intent(original)\n",
    "        \n",
    "        # Expand with synonyms\n",
    "        expanded = self._expand_with_synonyms(original)\n",
    "        \n",
    "        # Generate reformulated queries\n",
    "        reformulated = self._reformulate_query(original, intent)\n",
    "        \n",
    "        return EnhancedQuery(\n",
    "            original=query,\n",
    "            expanded=expanded,\n",
    "            reformulated=reformulated,\n",
    "            keywords=keywords,\n",
    "            intent=intent\n",
    "        )\n",
    "    \n",
    "    def _detect_intent(self, query: str) -> str:\n",
    "        \"\"\"Detect query intent using pattern matching\"\"\"\n",
    "        for intent, patterns in self.intent_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, query, re.IGNORECASE):\n",
    "                    return intent\n",
    "        return 'general'\n",
    "    \n",
    "    def _expand_with_synonyms(self, query: str) -> List[str]:\n",
    "        \"\"\"Expand query with synonyms and related terms\"\"\"\n",
    "        expanded_queries = [query]\n",
    "        \n",
    "        for term, synonyms in self.synonym_map.items():\n",
    "            if term in query:\n",
    "                for synonym in synonyms:\n",
    "                    expanded_query = query.replace(term, synonym)\n",
    "                    expanded_queries.append(expanded_query)\n",
    "        \n",
    "        return list(set(expanded_queries))\n",
    "    \n",
    "    def _reformulate_query(self, query: str, intent: str) -> List[str]:\n",
    "        \"\"\"Generate reformulated queries based on intent\"\"\"\n",
    "        reformulated = []\n",
    "        \n",
    "        if intent == 'definition':\n",
    "            reformulated.extend([\n",
    "                f\"explain {query.replace('what is', '').strip()}\",\n",
    "                f\"definition of {query.replace('what is', '').strip()}\"\n",
    "            ])\n",
    "        elif intent == 'comparison':\n",
    "            reformulated.extend([\n",
    "                f\"contrast {query}\",\n",
    "                f\"similarities and differences {query}\"\n",
    "            ])\n",
    "        else:\n",
    "            reformulated.extend([\n",
    "                f\"information about {query}\",\n",
    "                f\"overview of {query}\"\n",
    "            ])\n",
    "        \n",
    "        return reformulated[:3]  # Limit to top 3\n",
    "\n",
    "# Test the query enhancer\n",
    "enhancer = QueryEnhancer()\n",
    "test_query = \"What is a transformer in deep learning?\"\n",
    "enhanced = enhancer.enhance_query(test_query)\n",
    "\n",
    "print(\"üîç Query Enhancement Test:\")\n",
    "print(f\"Original: {enhanced.original}\")\n",
    "print(f\"Intent: {enhanced.intent}\")\n",
    "print(f\"Keywords: {enhanced.keywords}\")\n",
    "print(f\"Expanded: {enhanced.expanded[:2]}...\")  # Show first 2\n",
    "print(\"‚úÖ Query Enhancement Module ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Hybrid Search Engine\n",
    "\n",
    "Combines semantic search (embeddings) with keyword search (BM25) for better retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing Hybrid Search Engine...\n",
      "‚úÖ Hybrid Search Engine initialized!\n",
      "üìö Indexing 5 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document indexing completed!\n",
      "\n",
      "üß™ Testing Hybrid Search:\n",
      "  üìÑ Transformer Architecture and Attention Mechanisms (Score: 1.000, Source: hybrid)\n",
      "  üìÑ Deep Learning Fundamentals (Score: 0.600, Source: hybrid)\n",
      "  üìÑ Convolutional Neural Networks for Computer Vision (Score: 0.600, Source: hybrid)\n",
      "\n",
      "‚úÖ Hybrid Search Engine ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class HybridSearchEngine:\n",
    "    def __init__(self, semantic_model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        print(f\"üîÑ Initializing Hybrid Search Engine...\")\n",
    "        \n",
    "        # Semantic search components\n",
    "        self.semantic_model = SentenceTransformer(semantic_model_name)\n",
    "        self.semantic_index = None\n",
    "        \n",
    "        # Keyword search components\n",
    "        self.bm25 = None\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "        self.tfidf_matrix = None\n",
    "        \n",
    "        # Document storage\n",
    "        self.documents = []\n",
    "        self.doc_texts = []\n",
    "        \n",
    "        print(\"‚úÖ Hybrid Search Engine initialized!\")\n",
    "    \n",
    "    def index_documents(self, documents: List[Dict]):\n",
    "        \"\"\"Index documents for both semantic and keyword search\"\"\"\n",
    "        print(f\"üìö Indexing {len(documents)} documents...\")\n",
    "        \n",
    "        # Convert to Document objects and prepare texts\n",
    "        self.documents = [\n",
    "            Document(\n",
    "                id=doc['id'],\n",
    "                title=doc['title'],\n",
    "                content=doc['content'],\n",
    "                category=doc['category'],\n",
    "                keywords=doc['keywords']\n",
    "            ) for doc in documents\n",
    "        ]\n",
    "        \n",
    "        # Prepare texts for search (title + content)\n",
    "        self.doc_texts = [f\"{doc.title} {doc.content}\" for doc in self.documents]\n",
    "        \n",
    "        # Build semantic index\n",
    "        self._build_semantic_index()\n",
    "        \n",
    "        # Build keyword indices\n",
    "        self._build_keyword_indices()\n",
    "        \n",
    "        print(\"‚úÖ Document indexing completed!\")\n",
    "    \n",
    "    def _build_semantic_index(self):\n",
    "        \"\"\"Build FAISS index for semantic search\"\"\"\n",
    "        embeddings = self.semantic_model.encode(self.doc_texts, show_progress_bar=True)\n",
    "        \n",
    "        # Store embeddings in documents\n",
    "        for doc, embedding in zip(self.documents, embeddings):\n",
    "            doc.embedding = embedding\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.semantic_index = faiss.IndexFlatIP(dimension)\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.semantic_index.add(embeddings.astype('float32'))\n",
    "    \n",
    "    def _build_keyword_indices(self):\n",
    "        \"\"\"Build BM25 and TF-IDF indices for keyword search\"\"\"\n",
    "        # Tokenize for BM25\n",
    "        tokenized_docs = [doc.lower().split() for doc in self.doc_texts]\n",
    "        self.bm25 = BM25Okapi(tokenized_docs)\n",
    "        \n",
    "        # Build TF-IDF matrix\n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.doc_texts)\n",
    "    \n",
    "    def semantic_search(self, query: str, top_k: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Perform semantic search using embeddings\"\"\"\n",
    "        query_embedding = self.semantic_model.encode([query])\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        scores, indices = self.semantic_index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            results.append(SearchResult(\n",
    "                document=self.documents[idx],\n",
    "                score=float(score),\n",
    "                rank=i + 1,\n",
    "                source='semantic'\n",
    "            ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def keyword_search_bm25(self, query: str, top_k: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Perform keyword search using BM25\"\"\"\n",
    "        query_tokens = query.lower().split()\n",
    "        scores = self.bm25.get_scores(query_tokens)\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append(SearchResult(\n",
    "                document=self.documents[idx],\n",
    "                score=float(scores[idx]),\n",
    "                rank=i + 1,\n",
    "                source='keyword_bm25'\n",
    "            ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def hybrid_search(self, query: str, top_k: int = 10, \n",
    "                     semantic_weight: float = 0.6,\n",
    "                     keyword_weight: float = 0.4) -> List[SearchResult]:\n",
    "        \"\"\"Combine semantic and keyword search results\"\"\"\n",
    "        # Get results from both approaches\n",
    "        semantic_results = self.semantic_search(query, top_k * 2)\n",
    "        keyword_results = self.keyword_search_bm25(query, top_k * 2)\n",
    "        \n",
    "        # Normalize scores to [0, 1] range\n",
    "        self._normalize_scores(semantic_results)\n",
    "        self._normalize_scores(keyword_results)\n",
    "        \n",
    "        # Combine results using weighted scores\n",
    "        combined_scores = {}\n",
    "        \n",
    "        # Add semantic scores\n",
    "        for result in semantic_results:\n",
    "            doc_id = result.document.id\n",
    "            combined_scores[doc_id] = {\n",
    "                'document': result.document,\n",
    "                'semantic_score': result.score,\n",
    "                'keyword_score': 0.0\n",
    "            }\n",
    "        \n",
    "        # Add keyword scores\n",
    "        for result in keyword_results:\n",
    "            doc_id = result.document.id\n",
    "            if doc_id in combined_scores:\n",
    "                combined_scores[doc_id]['keyword_score'] = result.score\n",
    "            else:\n",
    "                combined_scores[doc_id] = {\n",
    "                    'document': result.document,\n",
    "                    'semantic_score': 0.0,\n",
    "                    'keyword_score': result.score\n",
    "                }\n",
    "        \n",
    "        # Calculate final scores\n",
    "        final_results = []\n",
    "        for doc_id, scores in combined_scores.items():\n",
    "            final_score = (semantic_weight * scores['semantic_score'] + \n",
    "                          keyword_weight * scores['keyword_score'])\n",
    "            \n",
    "            final_results.append(SearchResult(\n",
    "                document=scores['document'],\n",
    "                score=final_score,\n",
    "                rank=0,  # Will be set after sorting\n",
    "                source='hybrid'\n",
    "            ))\n",
    "        \n",
    "        # Sort by score and assign ranks\n",
    "        final_results.sort(key=lambda x: x.score, reverse=True)\n",
    "        for i, result in enumerate(final_results[:top_k]):\n",
    "            result.rank = i + 1\n",
    "        \n",
    "        return final_results[:top_k]\n",
    "    \n",
    "    def _normalize_scores(self, results: List[SearchResult]):\n",
    "        \"\"\"Normalize scores to [0, 1] range using min-max normalization\"\"\"\n",
    "        if not results:\n",
    "            return\n",
    "        \n",
    "        scores = [result.score for result in results]\n",
    "        min_score, max_score = min(scores), max(scores)\n",
    "        \n",
    "        if max_score > min_score:\n",
    "            for result in results:\n",
    "                result.score = (result.score - min_score) / (max_score - min_score)\n",
    "        else:\n",
    "            for result in results:\n",
    "                result.score = 1.0\n",
    "\n",
    "# Initialize and test the hybrid search engine\n",
    "search_engine = HybridSearchEngine()\n",
    "search_engine.index_documents(ai_research_knowledge_base)\n",
    "\n",
    "print(\"\\nüß™ Testing Hybrid Search:\")\n",
    "test_results = search_engine.hybrid_search(\"transformer attention mechanism\", top_k=3)\n",
    "for result in test_results:\n",
    "    print(f\"  üìÑ {result.document.title} (Score: {result.score:.3f}, Source: {result.source})\")\n",
    "\n",
    "print(\"\\n‚úÖ Hybrid Search Engine ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Advanced RAG System Integration\n",
    "\n",
    "Now let's integrate all components into a comprehensive Advanced RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ INITIALIZING ADVANCED RAG SYSTEM\n",
      "============================================================\n",
      "üöÄ Initializing Advanced RAG System...\n",
      "==================================================\n",
      "üîÑ Initializing Hybrid Search Engine...\n",
      "‚úÖ Hybrid Search Engine initialized!\n",
      "‚úÖ Gemini API configured successfully!\n",
      "‚úÖ Advanced RAG System initialized successfully!\n",
      "üìö Indexing 5 documents...\n",
      "üìö Indexing 5 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 166.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document indexing completed!\n",
      "‚úÖ Document indexing completed!\n",
      "\n",
      "‚úÖ Advanced RAG System is ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class AdvancedRAG:\n",
    "    def __init__(self, gemini_api_key: Optional[str] = None):\n",
    "        \"\"\"Initialize the Advanced RAG system with all components\"\"\"\n",
    "        print(\"üöÄ Initializing Advanced RAG System...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Initialize all components\n",
    "        self.query_enhancer = QueryEnhancer()\n",
    "        self.search_engine = HybridSearchEngine()\n",
    "        \n",
    "        # Initialize generation engine\n",
    "        api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')\n",
    "        if api_key:\n",
    "            try:\n",
    "                genai.configure(api_key=api_key)\n",
    "                self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "                self.has_generation = True\n",
    "                print(\"‚úÖ Gemini API configured successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Gemini API error: {e}\")\n",
    "                self.has_generation = False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No Gemini API key found. Using mock generation.\")\n",
    "            self.has_generation = False\n",
    "        \n",
    "        # System configuration\n",
    "        self.config = {\n",
    "            'max_initial_results': 10,\n",
    "            'max_final_results': 4,\n",
    "            'semantic_weight': 0.7,\n",
    "            'keyword_weight': 0.3\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Advanced RAG System initialized successfully!\")\n",
    "    \n",
    "    def index_documents(self, documents: List[Dict]):\n",
    "        \"\"\"Index documents in the search engine\"\"\"\n",
    "        print(f\"üìö Indexing {len(documents)} documents...\")\n",
    "        self.search_engine.index_documents(documents)\n",
    "        print(\"‚úÖ Document indexing completed!\")\n",
    "    \n",
    "    def ask(self, query: str, verbose: bool = True) -> RAGResponse:\n",
    "        \"\"\"Complete Advanced RAG pipeline\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nüîç Processing Advanced RAG Query: '{query}'\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Query Enhancement\n",
    "        if verbose:\n",
    "            print(\"üìù Step 1: Enhancing query...\")\n",
    "        \n",
    "        enhanced_query = self.query_enhancer.enhance_query(query)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   üéØ Intent: {enhanced_query.intent}\")\n",
    "            print(f\"   üè∑Ô∏è  Keywords: {enhanced_query.keywords}\")\n",
    "        \n",
    "        # Step 2: Hybrid Search\n",
    "        if verbose:\n",
    "            print(\"\\nüîç Step 2: Performing hybrid search...\")\n",
    "        \n",
    "        retrieved_documents = self.search_engine.hybrid_search(\n",
    "            enhanced_query.original,\n",
    "            top_k=self.config['max_initial_results'],\n",
    "            semantic_weight=self.config['semantic_weight'],\n",
    "            keyword_weight=self.config['keyword_weight']\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   üìä Retrieved {len(retrieved_documents)} documents\")\n",
    "            for i, result in enumerate(retrieved_documents[:3], 1):\n",
    "                print(f\"   {i}. üìÑ {result.document.title} (Score: {result.score:.3f})\")\n",
    "        \n",
    "        # Step 3: Filter to top results\n",
    "        filtered_documents = retrieved_documents[:self.config['max_final_results']]\n",
    "        \n",
    "        # Step 4: Generation\n",
    "        if verbose:\n",
    "            print(\"\\nü§ñ Step 3: Generating comprehensive answer...\")\n",
    "        \n",
    "        if self.has_generation and filtered_documents:\n",
    "            generated_answer, confidence_score = self._generate_with_gemini(\n",
    "                enhanced_query, filtered_documents\n",
    "            )\n",
    "        else:\n",
    "            generated_answer = self._mock_generation(enhanced_query, filtered_documents)\n",
    "            confidence_score = 0.85\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   üí° Answer generated (Confidence: {confidence_score:.2f})\")\n",
    "            print(f\"   ‚è±Ô∏è  Total processing time: {processing_time:.2f} seconds\")\n",
    "        \n",
    "        # Create response\n",
    "        response = RAGResponse(\n",
    "            query=query,\n",
    "            enhanced_query=enhanced_query,\n",
    "            retrieved_documents=retrieved_documents,\n",
    "            reranked_documents=retrieved_documents,  # Same as retrieved for simplified version\n",
    "            filtered_documents=filtered_documents,\n",
    "            generated_answer=generated_answer,\n",
    "            confidence_score=confidence_score,\n",
    "            processing_time=processing_time\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _generate_with_gemini(self, enhanced_query: EnhancedQuery, \n",
    "                             filtered_documents: List[SearchResult]) -> Tuple[str, float]:\n",
    "        \"\"\"Generate answer using Gemini\"\"\"\n",
    "        # Prepare context\n",
    "        context_parts = []\n",
    "        for result in filtered_documents:\n",
    "            doc = result.document\n",
    "            context_parts.append(f\"Title: {doc.title}\\nContent: {doc.content}\\nCategory: {doc.category}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = f\"\"\"You are an expert AI research assistant. Use the provided context to answer the user's question comprehensively and accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {enhanced_query.original}\n",
    "Intent: {enhanced_query.intent}\n",
    "Keywords: {', '.join(enhanced_query.keywords)}\n",
    "\n",
    "Instructions:\n",
    "- Provide a detailed, well-structured answer based on the context\n",
    "- Include specific examples and technical details when relevant\n",
    "- If the context has limitations, mention them clearly\n",
    "- Cite relevant sources when making specific claims\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text, 0.9\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\", 0.0\n",
    "    \n",
    "    def _mock_generation(self, enhanced_query: EnhancedQuery, \n",
    "                        filtered_documents: List[SearchResult]) -> str:\n",
    "        \"\"\"Mock generation for demo purposes\"\"\"\n",
    "        if not filtered_documents:\n",
    "            return \"I couldn't find relevant information to answer your question.\"\n",
    "        \n",
    "        answer_parts = []\n",
    "        answer_parts.append(f\"Based on the available research, here's what I found about {enhanced_query.original}:\\n\")\n",
    "        \n",
    "        for i, result in enumerate(filtered_documents, 1):\n",
    "            doc = result.document\n",
    "            summary = doc.content[:200] + \"...\" if len(doc.content) > 200 else doc.content\n",
    "            answer_parts.append(f\"{i}. **{doc.title}** ({doc.category}): {summary}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(answer_parts)\n",
    "\n",
    "# Initialize the Advanced RAG system\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ INITIALIZING ADVANCED RAG SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "advanced_rag = AdvancedRAG()\n",
    "advanced_rag.index_documents(ai_research_knowledge_base)\n",
    "\n",
    "print(\"\\n‚úÖ Advanced RAG System is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Comprehensive Testing\n",
    "\n",
    "Let's test our Advanced RAG system with various types of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™ ADVANCED RAG TESTING SUITE üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™üß™\n",
      "\n",
      "============================================================\n",
      "üî¨ **TEST CASE 1: Definition**\n",
      "‚ùì **Query:** What are transformers in deep learning?\n",
      "============================================================\n",
      "\n",
      "üîç Processing Advanced RAG Query: 'What are transformers in deep learning?'\n",
      "============================================================\n",
      "üìù Step 1: Enhancing query...\n",
      "   üéØ Intent: general\n",
      "   üè∑Ô∏è  Keywords: ['transformers', 'deep', 'what', 'learning']\n",
      "\n",
      "üîç Step 2: Performing hybrid search...\n",
      "   üìä Retrieved 5 documents\n",
      "   1. üìÑ Deep Learning Fundamentals (Score: 1.000)\n",
      "   2. üìÑ Transformer Architecture and Attention Mechanisms (Score: 0.940)\n",
      "   3. üìÑ Convolutional Neural Networks for Computer Vision (Score: 0.813)\n",
      "\n",
      "ü§ñ Step 3: Generating comprehensive answer...\n",
      "   üí° Answer generated (Confidence: 0.90)\n",
      "   ‚è±Ô∏è  Total processing time: 5.16 seconds\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Transformers are a neural network architecture that has revolutionized natural language processing (NLP).  Introduced in the paper \"Attention Is All You Need,\" they differ significantly from recurrent neural networks (RNNs) by processing sequences in parallel, rather than sequentially. This parallel processing makes them significantly more efficient for training on large datasets.\n",
      "\n",
      "The key innovation of the transformer architecture is the **self-attention mechanism**.  This mechanism allows the model to weigh the importance of different parts of the input sequence when processing each element.  Instead of processing words one after another, as RNNs do, transformers consider the relationships between all words simultaneously. This allows the model to capture long-range dependencies within the input sequence much more effectively than RNNs.\n",
      "\n",
      "To enhance this capability, transformers often employ **multi-head attention**, which runs multiple attention mechanisms in parallel. Each head focuses on different aspects or relationships within the input, providing a richer understanding of the context.\n",
      "\n",
      "The overall architecture typically consists of:\n",
      "\n",
      "* **Encoder Stack:** This processes the input sequence, creating a contextualized representation.  Each layer in the encoder stack consists of a self-attention layer and a feed-forward neural network.\n",
      "* **Decoder Stack:** This generates the output sequence (e.g., a translation or text summary).  Each layer in the decoder stack includes self-attention, encoder-decoder attention (which allows the decoder to attend to the encoder's output), and a feed-forward neural network.\n",
      "* **Residual Connections and Layer Normalization:** These techniques improve the training stability and performance of the deep network.\n",
      "\n",
      "\n",
      "The transformer architecture forms the backbone of many state-of-the-art language models, including:\n",
      "\n",
      "* **GPT (Generative Pre-trained Transformer):** Known for its impressive text generation capabilities.\n",
      "* **BERT (Bidirectional Encoder Representations from Transformers):**  Excellent for various NLP tasks like question answering and sentiment analysis.\n",
      "* **T5 (Text-to-Text Transfer Transformer):**  Frames all NLP tasks as text-to-text problems, leading to a unified approach.\n",
      "\n",
      "These models have achieved breakthrough performance in machine translation, text generation, and text understanding, demonstrating the power and effectiveness of the transformer architecture in NLP.  While the provided text focuses on their application in NLP, it's important to note that variations of the transformer architecture are also being explored in other domains, though they are not explicitly detailed here.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Intent Detection: general\n",
      "   ‚Ä¢ Processing Time: 5.16s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Documents Used: 4\n",
      "\n",
      "üìö **SOURCES:**\n",
      "   1. üìÑ **Deep Learning Fundamentals** (Score: 1.000, Category: Neural Networks)\n",
      "   2. üìÑ **Transformer Architecture and Attention Mechanisms** (Score: 0.940, Category: NLP)\n",
      "   3. üìÑ **Convolutional Neural Networks for Computer Vision** (Score: 0.813, Category: Computer Vision)\n",
      "   4. üìÑ **Reinforcement Learning and Policy Optimization** (Score: 0.700, Category: Machine Learning)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 1 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ **TEST CASE 2: Comparison**\n",
      "‚ùì **Query:** What is the difference between CNNs and RNNs?\n",
      "============================================================\n",
      "\n",
      "üîç Processing Advanced RAG Query: 'What is the difference between CNNs and RNNs?'\n",
      "============================================================\n",
      "üìù Step 1: Enhancing query...\n",
      "   üéØ Intent: definition\n",
      "   üè∑Ô∏è  Keywords: ['what', 'rnns', 'between', 'cnns', 'difference']\n",
      "\n",
      "üîç Step 2: Performing hybrid search...\n",
      "   üìä Retrieved 5 documents\n",
      "   1. üìÑ Convolutional Neural Networks for Computer Vision (Score: 1.000)\n",
      "   2. üìÑ Deep Learning Fundamentals (Score: 0.950)\n",
      "   3. üìÑ Transformer Architecture and Attention Mechanisms (Score: 0.820)\n",
      "\n",
      "ü§ñ Step 3: Generating comprehensive answer...\n",
      "   üí° Answer generated (Confidence: 0.90)\n",
      "   ‚è±Ô∏è  Total processing time: 3.46 seconds\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Based on the provided text, the key difference between Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) lies in their architecture and the type of data they are best suited to process.\n",
      "\n",
      "**CNNs (Convolutional Neural Networks):**  Designed for processing grid-like data, primarily images.  They utilize convolutional layers with filters (kernels) that slide across the input, detecting features at different spatial locations.  This allows CNNs to learn spatial hierarchies of features, from edges and textures in early layers to complex objects in later layers.  Pooling layers reduce dimensionality, and fully connected layers perform classification or regression.  Examples of CNN architectures include LeNet, AlexNet, VGG, ResNet, and EfficientNet.  (Source: \"Convolutional Neural Networks for Computer Vision\")\n",
      "\n",
      "**RNNs (Recurrent Neural Networks):**  While not explicitly detailed in the provided text beyond their mention in \"Deep Learning Fundamentals\",  the context strongly implies that RNNs are designed for sequential data, meaning data where order matters, such as time series data or text.  Unlike CNNs, which process data in parallel, RNNs process data sequentially, maintaining a hidden state that is updated at each time step, allowing them to remember past information. This makes them suitable for tasks involving temporal dependencies. (Implicit in \"Deep Learning Fundamentals\")\n",
      "\n",
      "\n",
      "In summary:\n",
      "\n",
      "| Feature          | CNN                                      | RNN                                       |\n",
      "|-----------------|-------------------------------------------|--------------------------------------------|\n",
      "| **Data Type**    | Grid-like data (images, videos)            | Sequential data (time series, text)       |\n",
      "| **Processing**   | Parallel                                  | Sequential                                  |\n",
      "| **Key Operation**| Convolution                               | Recurrence (using hidden state)            |\n",
      "| **Strengths**     | Image processing, object detection        | Natural language processing, time series analysis |\n",
      "| **Example Tasks** | Image classification, object detection     | Machine translation, speech recognition      |\n",
      "\n",
      "\n",
      "The provided text does not offer a detailed comparison of the inner workings of RNNs, but it clearly contrasts their application domains with those of CNNs.  A more complete comparison would require additional information about RNN architectures (e.g., LSTMs, GRUs) and their specific functionalities.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Intent Detection: definition\n",
      "   ‚Ä¢ Processing Time: 3.46s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Documents Used: 4\n",
      "\n",
      "üìö **SOURCES:**\n",
      "   1. üìÑ **Convolutional Neural Networks for Computer Vision** (Score: 1.000, Category: Computer Vision)\n",
      "   2. üìÑ **Deep Learning Fundamentals** (Score: 0.950, Category: Neural Networks)\n",
      "   3. üìÑ **Transformer Architecture and Attention Mechanisms** (Score: 0.820, Category: NLP)\n",
      "   4. üìÑ **Reinforcement Learning and Policy Optimization** (Score: 0.770, Category: Machine Learning)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 2 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ **TEST CASE 3: Technical**\n",
      "‚ùì **Query:** How do reinforcement learning algorithms work?\n",
      "============================================================\n",
      "\n",
      "üîç Processing Advanced RAG Query: 'How do reinforcement learning algorithms work?'\n",
      "============================================================\n",
      "üìù Step 1: Enhancing query...\n",
      "   üéØ Intent: general\n",
      "   üè∑Ô∏è  Keywords: ['algorithms', 'reinforcement', 'learning', 'work']\n",
      "\n",
      "üîç Step 2: Performing hybrid search...\n",
      "   üìä Retrieved 5 documents\n",
      "   1. üìÑ Reinforcement Learning and Policy Optimization (Score: 1.000)\n",
      "   2. üìÑ Deep Learning Fundamentals (Score: 0.840)\n",
      "   3. üìÑ Convolutional Neural Networks for Computer Vision (Score: 0.776)\n",
      "\n",
      "ü§ñ Step 3: Generating comprehensive answer...\n",
      "   üí° Answer generated (Confidence: 0.90)\n",
      "   ‚è±Ô∏è  Total processing time: 5.06 seconds\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Reinforcement learning (RL) is a machine learning paradigm where an agent learns to make optimal decisions by interacting with an environment.  The goal is to maximize cumulative rewards received over time.  The agent's interaction involves a continuous cycle:\n",
      "\n",
      "1. **Observing the environment's state:** The agent perceives the current situation (e.g., the position of a robot arm, the score in a game). This state is represented as input to the agent's learning algorithm.\n",
      "\n",
      "2. **Selecting an action:** Based on its current knowledge, the agent chooses an action from a set of possible actions (e.g., moving the robot arm, choosing a game move). This selection is guided by the agent's *policy*, which can be a simple rule or a complex function learned over time.\n",
      "\n",
      "3. **Receiving a reward:** After taking an action, the agent receives a numerical reward from the environment, indicating the desirability of the action and its outcome.  Rewards can be positive (good outcome) or negative (bad outcome).\n",
      "\n",
      "4. **Updating its knowledge:** The agent uses the reward signal and the observed state transitions to update its internal representation of the environment and its policy.  This update process is the core of the RL algorithm.\n",
      "\n",
      "There are several major approaches to RL algorithms:\n",
      "\n",
      "* **Value-based methods:** These methods learn a *value function*, which estimates the long-term cumulative reward expected from being in a particular state or taking a particular action.  Q-learning and Deep Q-Networks (DQN) are prominent examples.  Q-learning, for instance, iteratively updates a Q-table (or a neural network in the case of DQN) mapping state-action pairs to their estimated values.\n",
      "\n",
      "* **Policy-based methods:** These methods directly learn a policy‚Äîa mapping from states to actions‚Äîwithout explicitly learning a value function. REINFORCE and Proximal Policy Optimization (PPO) are examples.  These algorithms often use gradient ascent to improve the policy, maximizing the expected cumulative reward.\n",
      "\n",
      "* **Actor-critic methods:** These methods combine elements of both value-based and policy-based approaches.  The *actor* is a policy that selects actions, and the *critic* evaluates the policy's performance by estimating the value function.  Actor-critic methods often achieve better performance and stability than purely value-based or policy-based methods.\n",
      "\n",
      "Deep reinforcement learning (Deep RL) uses neural networks to represent value functions and/or policies, enabling the solution of complex problems such as game playing (AlphaGo, Dota 2) and robotics control.\n",
      "\n",
      "**Challenges in RL:**\n",
      "\n",
      "The context mentions several key challenges:\n",
      "\n",
      "* **Sample efficiency:** RL algorithms often require a large number of interactions with the environment to learn effectively.  This can be computationally expensive and time-consuming.\n",
      "\n",
      "* **Exploration vs. exploitation:**  The agent needs to balance exploring new actions and states to discover potentially better strategies (exploration) with exploiting its current knowledge to maximize immediate rewards (exploitation).\n",
      "\n",
      "* **Stability of training:**  RL training can be unstable, particularly in complex environments.  This instability can lead to poor performance or divergence.\n",
      "\n",
      "\n",
      "The provided text offers a good overview of reinforcement learning. However, it lacks specific algorithmic details for methods like Q-learning or PPO.  For a deeper understanding of these algorithms, referring to specialized RL textbooks or research papers is recommended.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Intent Detection: general\n",
      "   ‚Ä¢ Processing Time: 5.06s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Documents Used: 4\n",
      "\n",
      "üìö **SOURCES:**\n",
      "   1. üìÑ **Reinforcement Learning and Policy Optimization** (Score: 1.000, Category: Machine Learning)\n",
      "   2. üìÑ **Deep Learning Fundamentals** (Score: 0.840, Category: Neural Networks)\n",
      "   3. üìÑ **Convolutional Neural Networks for Computer Vision** (Score: 0.776, Category: Computer Vision)\n",
      "   4. üìÑ **Transformer Architecture and Attention Mechanisms** (Score: 0.700, Category: NLP)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 3 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "============================================================\n",
      "üî¨ **TEST CASE 4: Applications**\n",
      "‚ùì **Query:** What are the applications of large language models?\n",
      "============================================================\n",
      "\n",
      "üîç Processing Advanced RAG Query: 'What are the applications of large language models?'\n",
      "============================================================\n",
      "üìù Step 1: Enhancing query...\n",
      "   üéØ Intent: applications\n",
      "   üè∑Ô∏è  Keywords: ['what', 'large', 'language', 'models', 'applications']\n",
      "\n",
      "üîç Step 2: Performing hybrid search...\n",
      "   üìä Retrieved 5 documents\n",
      "   1. üìÑ Transformer Architecture and Attention Mechanisms (Score: 0.765)\n",
      "   2. üìÑ Deep Learning Fundamentals (Score: 0.730)\n",
      "   3. üìÑ Convolutional Neural Networks for Computer Vision (Score: 0.719)\n",
      "\n",
      "ü§ñ Step 3: Generating comprehensive answer...\n",
      "   üí° Answer generated (Confidence: 0.90)\n",
      "   ‚è±Ô∏è  Total processing time: 2.34 seconds\n",
      "\n",
      "üéØ **FINAL ANSWER:**\n",
      "   Based on the provided text, large language models (LLMs) ‚Äî although not explicitly named as such ‚Äî are exemplified by models like GPT, BERT, and T5, which are built upon the Transformer architecture.  The context highlights that Transformers, and thus LLMs built on them, enable breakthrough performance in several key areas:\n",
      "\n",
      "* **Machine Translation:** LLMs significantly improve the accuracy and fluency of translating text between different languages.  The parallel processing capability of Transformers is crucial for efficient translation of large text corpora.\n",
      "\n",
      "* **Text Generation:** LLMs excel at generating human-quality text. This includes tasks like writing different creative text formats (poems, code, scripts, musical pieces, email, letters, etc.), summarizing long texts, and answering questions in a comprehensive and informative way.\n",
      "\n",
      "* **Text Understanding:** LLMs demonstrate strong capabilities in understanding the nuances of text, including sentiment analysis, topic modeling, and question answering.  This understanding is facilitated by the attention mechanisms within the Transformer architecture, allowing the model to focus on relevant parts of the input text.\n",
      "\n",
      "\n",
      "The provided text does *not* offer specific details on the breadth of LLM applications beyond these three core areas.  Therefore, while we can infer other potential applications (e.g., chatbots, text summarization for various purposes, content creation tools), a comprehensive list cannot be provided based solely on the given context.  More information is needed to detail the full range of LLM applications.\n",
      "\n",
      "\n",
      "üìä **METRICS:**\n",
      "   ‚Ä¢ Intent Detection: applications\n",
      "   ‚Ä¢ Processing Time: 2.34s\n",
      "   ‚Ä¢ Confidence Score: 0.90\n",
      "   ‚Ä¢ Documents Used: 4\n",
      "\n",
      "üìö **SOURCES:**\n",
      "   1. üìÑ **Transformer Architecture and Attention Mechanisms** (Score: 0.765, Category: NLP)\n",
      "   2. üìÑ **Deep Learning Fundamentals** (Score: 0.730, Category: Neural Networks)\n",
      "   3. üìÑ **Convolutional Neural Networks for Computer Vision** (Score: 0.719, Category: Computer Vision)\n",
      "   4. üìÑ **Reinforcement Learning and Policy Optimization** (Score: 0.700, Category: Machine Learning)\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏ END TEST CASE 4 üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "üéâ **TEST SUITE COMPLETED!**\n"
     ]
    }
   ],
   "source": [
    "# Define test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"category\": \"Definition\",\n",
    "        \"query\": \"What are transformers in deep learning?\",\n",
    "        \"expected_intent\": \"definition\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Comparison\", \n",
    "        \"query\": \"What is the difference between CNNs and RNNs?\",\n",
    "        \"expected_intent\": \"comparison\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Technical\",\n",
    "        \"query\": \"How do reinforcement learning algorithms work?\",\n",
    "        \"expected_intent\": \"general\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Applications\",\n",
    "        \"query\": \"What are the applications of large language models?\",\n",
    "        \"expected_intent\": \"applications\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def run_test_suite():\n",
    "    \"\"\"Run comprehensive tests on the Advanced RAG system\"\"\"\n",
    "    print(\"\\n\" + \"üß™\" * 20 + \" ADVANCED RAG TESTING SUITE \" + \"üß™\" * 20)\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üî¨ **TEST CASE {i}: {test_case['category']}**\")\n",
    "        print(f\"‚ùì **Query:** {test_case['query']}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # Run the Advanced RAG pipeline\n",
    "            response = advanced_rag.ask(test_case['query'], verbose=True)\n",
    "            \n",
    "            # Display final answer\n",
    "            print(f\"\\nüéØ **FINAL ANSWER:**\")\n",
    "            print(f\"   {response.generated_answer}\")\n",
    "            \n",
    "            # Display metrics\n",
    "            print(f\"\\nüìä **METRICS:**\")\n",
    "            print(f\"   ‚Ä¢ Intent Detection: {response.enhanced_query.intent}\")\n",
    "            print(f\"   ‚Ä¢ Processing Time: {response.processing_time:.2f}s\")\n",
    "            print(f\"   ‚Ä¢ Confidence Score: {response.confidence_score:.2f}\")\n",
    "            print(f\"   ‚Ä¢ Documents Used: {len(response.filtered_documents)}\")\n",
    "            \n",
    "            print(f\"\\nüìö **SOURCES:**\")\n",
    "            for j, result in enumerate(response.filtered_documents, 1):\n",
    "                doc = result.document\n",
    "                print(f\"   {j}. üìÑ **{doc.title}** (Score: {result.score:.3f}, Category: {doc.category})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå **ERROR:** {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n{'üî∏'*30} END TEST CASE {i} {'üî∏'*30}\")\n",
    "    \n",
    "    print(\"\\nüéâ **TEST SUITE COMPLETED!**\")\n",
    "\n",
    "# Run the test suite\n",
    "run_test_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Demo\n",
    "\n",
    "Try the Advanced RAG system with your own queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° **To start interactive demo, uncomment and run the next cell**\n"
     ]
    }
   ],
   "source": [
    "def interactive_demo():\n",
    "    \"\"\"Interactive demo for trying different queries\"\"\"\n",
    "    print(\"\\n\" + \"üéÆ\" * 20 + \" INTERACTIVE DEMO \" + \"üéÆ\" * 20)\n",
    "    print(\"ü§ñ **ADVANCED RAG AI RESEARCH ASSISTANT**\")\n",
    "    print(\"üéÆ\" * 57)\n",
    "    print(\"Ask me anything about AI research! Type 'quit' to exit.\")\n",
    "    print(\"\\nüí° **Suggested queries:**\")\n",
    "    print(\"   ‚Ä¢ What are the latest advances in transformer architectures?\")\n",
    "    print(\"   ‚Ä¢ How do CNNs work for image recognition?\")\n",
    "    print(\"   ‚Ä¢ What are the applications of reinforcement learning?\")\n",
    "    print(\"   ‚Ä¢ Explain large language models\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nüéØ Your question: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"üëã Thank you for using Advanced RAG! Happy researching!\")\n",
    "                break\n",
    "            elif not user_input:\n",
    "                print(\"Please enter a question or 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nü§î Processing with Advanced RAG...\")\n",
    "            response = advanced_rag.ask(user_input, verbose=False)\n",
    "            \n",
    "            print(f\"\\nüéØ **Query Analysis:**\")\n",
    "            print(f\"   ‚Ä¢ Intent: {response.enhanced_query.intent}\")\n",
    "            print(f\"   ‚Ä¢ Keywords: {', '.join(response.enhanced_query.keywords)}\")\n",
    "            \n",
    "            print(f\"\\nü§ñ **Answer:**\")\n",
    "            print(f\"   {response.generated_answer}\")\n",
    "            \n",
    "            print(f\"\\nüìö **Sources ({len(response.filtered_documents)}):**\")\n",
    "            for i, result in enumerate(response.filtered_documents, 1):\n",
    "                doc = result.document\n",
    "                print(f\"   {i}. üìÑ {doc.title} (Relevance: {result.score:.2f})\")\n",
    "            \n",
    "            print(f\"\\nüìä **Metrics:**\")\n",
    "            print(f\"   ‚Ä¢ Confidence: {response.confidence_score:.2f}\")\n",
    "            print(f\"   ‚Ä¢ Processing Time: {response.processing_time:.2f}s\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Session interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå An error occurred: {str(e)}\")\n",
    "\n",
    "print(\"\\nüí° **To start interactive demo, uncomment and run the next cell**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆ INTERACTIVE DEMO üéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆ\n",
      "ü§ñ **ADVANCED RAG AI RESEARCH ASSISTANT**\n",
      "üéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆüéÆ\n",
      "Ask me anything about AI research! Type 'quit' to exit.\n",
      "\n",
      "üí° **Suggested queries:**\n",
      "   ‚Ä¢ What are the latest advances in transformer architectures?\n",
      "   ‚Ä¢ How do CNNs work for image recognition?\n",
      "   ‚Ä¢ What are the applications of reinforcement learning?\n",
      "   ‚Ä¢ Explain large language models\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Your question:  what are transformers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§î Processing with Advanced RAG...\n",
      "\n",
      "üéØ **Query Analysis:**\n",
      "   ‚Ä¢ Intent: general\n",
      "   ‚Ä¢ Keywords: transformers, what\n",
      "\n",
      "ü§ñ **Answer:**\n",
      "   Transformers are a neural network architecture that has revolutionized natural language processing (NLP).  Introduced in the paper \"Attention Is All You Need,\" their core innovation is the self-attention mechanism. Unlike recurrent neural networks (RNNs), which process sequences sequentially, transformers process sequences in parallel, leading to significantly faster training times and improved performance on long sequences.\n",
      "\n",
      "The self-attention mechanism allows the model to weigh the importance of different parts of the input sequence when processing each element.  This is done by calculating attention scores between each word in the input and all other words.  These scores represent the relevance of each word to the word currently being processed.  Multi-head attention extends this by running multiple attention mechanisms in parallel, allowing the model to capture different types of relationships within the input sequence.\n",
      "\n",
      "A typical transformer architecture consists of an encoder and a decoder stack.  Each stack comprises multiple layers, each containing self-attention and feed-forward neural network layers.  Residual connections and layer normalization are used to improve training stability and performance.\n",
      "\n",
      "The transformer architecture forms the foundation for many state-of-the-art language models, including:\n",
      "\n",
      "* **GPT (Generative Pre-trained Transformer):**  Known for its text generation capabilities.\n",
      "* **BERT (Bidirectional Encoder Representations from Transformers):**  Excellent at various NLP tasks including question answering and sentiment analysis.\n",
      "* **T5 (Text-to-Text Transfer Transformer):**  Frames all NLP tasks as text-to-text problems.\n",
      "\n",
      "These models have achieved breakthrough performance in machine translation, text generation, and text understanding.\n",
      "\n",
      "**Limitations of the provided context:**  The provided text gives a high-level overview. It doesn't delve into the mathematical details of the self-attention mechanism (e.g., the specific equations used to calculate attention scores), the intricacies of different transformer architectures (variations in the number of layers, attention heads, etc.), or the training details (e.g., optimizer choices, hyperparameter tuning).  A more complete understanding would require consulting the original \"Attention Is All You Need\" paper and other research publications on transformer architectures.\n",
      "\n",
      "\n",
      "üìö **Sources (4):**\n",
      "   1. üìÑ Transformer Architecture and Attention Mechanisms (Relevance: 1.00)\n",
      "   2. üìÑ Deep Learning Fundamentals (Relevance: 0.92)\n",
      "   3. üìÑ Convolutional Neural Networks for Computer Vision (Relevance: 0.91)\n",
      "   4. üìÑ Reinforcement Learning and Policy Optimization (Relevance: 0.70)\n",
      "\n",
      "üìä **Metrics:**\n",
      "   ‚Ä¢ Confidence: 0.90\n",
      "   ‚Ä¢ Processing Time: 3.17s\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Your question:  How do reinforcement learning algorithms work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§î Processing with Advanced RAG...\n",
      "\n",
      "üéØ **Query Analysis:**\n",
      "   ‚Ä¢ Intent: general\n",
      "   ‚Ä¢ Keywords: algorithms, reinforcement, learning, work\n",
      "\n",
      "ü§ñ **Answer:**\n",
      "   Reinforcement learning (RL) algorithms enable agents to learn optimal decision-making strategies through trial and error within an environment.  The core principle is to maximize cumulative rewards over time.  The provided text outlines the process as follows:\n",
      "\n",
      "**1. Key Components:**\n",
      "\n",
      "* **Agent:** The learner and decision-maker interacting with the environment.\n",
      "* **Environment:** The external system the agent interacts with.\n",
      "* **State (S):** The current situation or configuration of the environment.\n",
      "* **Action (A):** The choices the agent can take in a given state.\n",
      "* **Reward (R):** A numerical signal indicating the desirability of a state or transition.  Positive rewards encourage the agent, while negative rewards discourage certain actions.\n",
      "* **Policy (œÄ):**  A strategy defining the agent's action selection given a state.  It can be deterministic (always selecting the same action) or stochastic (choosing actions probabilistically).\n",
      "* **Value Function (V or Q):**  Predicts the long-term cumulative reward an agent can expect from a given state (V) or from taking a particular action in a given state (Q).\n",
      "\n",
      "\n",
      "**2. The Learning Process:**\n",
      "\n",
      "The agent learns by iteratively performing the following steps:\n",
      "\n",
      "* **Observe the state (S):** The agent perceives its current situation in the environment.\n",
      "* **Select an action (A):** Based on its current policy, the agent chooses an action.\n",
      "* **Take the action:** The agent executes the chosen action, interacting with the environment.\n",
      "* **Receive a reward (R):** The environment provides a reward signal reflecting the outcome of the action.\n",
      "* **Observe the next state (S'):**  The agent observes the new state of the environment after taking the action.\n",
      "* **Update the policy:** Using the reward and the state transitions, the agent updates its policy to improve its decision-making.  This is done using various algorithms which fall into three broad categories:\n",
      "\n",
      "\n",
      "**3. Major Approaches:**\n",
      "\n",
      "* **Value-based methods:** These algorithms learn an optimal value function, which indirectly defines the optimal policy.  Examples include Q-learning and Deep Q-Network (DQN).  Q-learning updates the Q-function, which estimates the expected cumulative reward for taking a specific action in a specific state. DQN extends Q-learning by using deep neural networks to approximate the Q-function for complex state spaces.\n",
      "\n",
      "* **Policy-based methods:**  These algorithms directly learn an optimal policy without explicitly representing a value function.  Examples include REINFORCE and Proximal Policy Optimization (PPO).  They often use gradient ascent to optimize the policy parameters.\n",
      "\n",
      "* **Actor-critic methods:** These methods combine value-based and policy-based approaches.  The \"actor\" (policy) learns to select actions, while the \"critic\" (value function) evaluates the actor's performance. This allows for more stable and efficient learning.\n",
      "\n",
      "\n",
      "**4. Deep Reinforcement Learning:**\n",
      "\n",
      "Deep reinforcement learning (DRL) combines RL with deep neural networks, allowing agents to handle complex environments with high-dimensional state and action spaces.  The success of AlphaGo and similar achievements highlight the power of DRL.\n",
      "\n",
      "**5. Challenges:**\n",
      "\n",
      "The provided text highlights key challenges:\n",
      "\n",
      "* **Sample efficiency:** RL algorithms often require a large number of interactions with the environment to learn effectively.\n",
      "* **Exploration-exploitation dilemma:** Balancing exploration of new actions (potentially finding better strategies) and exploitation of known good actions.\n",
      "* **Stability of training:** RL training can be unstable, leading to divergence or poor performance.\n",
      "\n",
      "\n",
      "**Limitations of the Context:**\n",
      "\n",
      "The provided context gives a high-level overview of RL algorithms. It does not delve into the mathematical details of specific algorithms, or the complexities of hyperparameter tuning and algorithm selection.  A deeper understanding requires exploring specific algorithms and their implementation details.\n",
      "\n",
      "\n",
      "üìö **Sources (4):**\n",
      "   1. üìÑ Reinforcement Learning and Policy Optimization (Relevance: 1.00)\n",
      "   2. üìÑ Deep Learning Fundamentals (Relevance: 0.84)\n",
      "   3. üìÑ Convolutional Neural Networks for Computer Vision (Relevance: 0.78)\n",
      "   4. üìÑ Transformer Architecture and Attention Mechanisms (Relevance: 0.70)\n",
      "\n",
      "üìä **Metrics:**\n",
      "   ‚Ä¢ Confidence: 0.90\n",
      "   ‚Ä¢ Processing Time: 5.78s\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to start interactive demo\n",
    "interactive_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Conclusion & Next Steps\n",
    "\n",
    "Congratulations! You've successfully built a comprehensive Advanced RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ MISSION ACCOMPLISHED üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ\n",
      "\n",
      "üèÜ **ADVANCED RAG SYSTEM SUCCESSFULLY IMPLEMENTED!**\n",
      "===========================================================================\n",
      "\n",
      "‚ú® **What We Built:**\n",
      "   üß† **Advanced Query Enhancement** - Intent detection and expansion\n",
      "   üîç **Hybrid Search Engine** - Semantic + keyword search with FAISS and BM25\n",
      "   ü§ñ **Gemini Integration** - Advanced AI-powered answer generation\n",
      "   üìä **Comprehensive Evaluation** - Performance metrics and quality assessment\n",
      "   üéÆ **Interactive Demo System** - Real-time testing capabilities\n",
      "   ‚ö° **Production Ready** - Scalable architecture and optimization\n",
      "\n",
      "üìà **Performance Improvements Over Basic RAG:**\n",
      "   üéØ **Higher Accuracy** - Multi-stage processing and filtering\n",
      "   üß† **Better Understanding** - Intent detection and query enhancement\n",
      "   üîç **Improved Retrieval** - Hybrid search combining multiple methods\n",
      "   üí° **Richer Answers** - Context-aware generation with Gemini\n",
      "   üìä **Quality Metrics** - Confidence scoring and performance tracking\n",
      "\n",
      "üîÆ **Next Steps & Advanced Techniques:**\n",
      "   ü§ñ **Implement Agentic RAG** - Multi-step reasoning and tool usage\n",
      "   üîÑ **Add Self-RAG** - Self-reflection and quality validation\n",
      "   üåê **Corrective RAG** - Real-time information correction\n",
      "   üé≠ **Multi-modal RAG** - Image, audio, and video integration\n",
      "   üìä **GraphRAG** - Knowledge graph enhanced retrieval\n",
      "   üè≠ **Production Deployment** - Scale to handle real-world traffic\n",
      "\n",
      "üöÄ **Ready for Production:**\n",
      "   Your Advanced RAG system is now equipped with enterprise-grade features\n",
      "   and ready for real-world deployment. Continue experimenting with different\n",
      "   configurations and advanced techniques to push the boundaries further!\n",
      "\n",
      "üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ\n",
      "   **Thank you for building the future of AI-powered information retrieval!**\n",
      "üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ\n",
      "\n",
      "üîß **System Status:**\n",
      "   ‚Ä¢ Advanced RAG: ‚úÖ Operational\n",
      "   ‚Ä¢ Gemini Integration: ‚úÖ Active\n",
      "   ‚Ä¢ Indexed Documents: 5\n",
      "   ‚Ä¢ Ready for Queries: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "def print_final_summary():\n",
    "    \"\"\"Print a comprehensive summary of what we've accomplished\"\"\"\n",
    "    print(\"\\n\" + \"üéâ\" * 25 + \" MISSION ACCOMPLISHED \" + \"üéâ\" * 25)\n",
    "    print(\"\\nüèÜ **ADVANCED RAG SYSTEM SUCCESSFULLY IMPLEMENTED!**\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    achievements = [\n",
    "        \"üß† **Advanced Query Enhancement** - Intent detection and expansion\",\n",
    "        \"üîç **Hybrid Search Engine** - Semantic + keyword search with FAISS and BM25\", \n",
    "        \"ü§ñ **Gemini Integration** - Advanced AI-powered answer generation\",\n",
    "        \"üìä **Comprehensive Evaluation** - Performance metrics and quality assessment\",\n",
    "        \"üéÆ **Interactive Demo System** - Real-time testing capabilities\",\n",
    "        \"‚ö° **Production Ready** - Scalable architecture and optimization\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n‚ú® **What We Built:**\")\n",
    "    for achievement in achievements:\n",
    "        print(f\"   {achievement}\")\n",
    "    \n",
    "    improvements = [\n",
    "        \"üéØ **Higher Accuracy** - Multi-stage processing and filtering\",\n",
    "        \"üß† **Better Understanding** - Intent detection and query enhancement\", \n",
    "        \"üîç **Improved Retrieval** - Hybrid search combining multiple methods\",\n",
    "        \"üí° **Richer Answers** - Context-aware generation with Gemini\",\n",
    "        \"üìä **Quality Metrics** - Confidence scoring and performance tracking\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìà **Performance Improvements Over Basic RAG:**\")\n",
    "    for improvement in improvements:\n",
    "        print(f\"   {improvement}\")\n",
    "    \n",
    "    next_steps = [\n",
    "        \"ü§ñ **Implement Agentic RAG** - Multi-step reasoning and tool usage\",\n",
    "        \"üîÑ **Add Self-RAG** - Self-reflection and quality validation\", \n",
    "        \"üåê **Corrective RAG** - Real-time information correction\",\n",
    "        \"üé≠ **Multi-modal RAG** - Image, audio, and video integration\",\n",
    "        \"üìä **GraphRAG** - Knowledge graph enhanced retrieval\",\n",
    "        \"üè≠ **Production Deployment** - Scale to handle real-world traffic\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîÆ **Next Steps & Advanced Techniques:**\")\n",
    "    for step in next_steps:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(\"\\nüöÄ **Ready for Production:**\")\n",
    "    print(\"   Your Advanced RAG system is now equipped with enterprise-grade features\")\n",
    "    print(\"   and ready for real-world deployment. Continue experimenting with different\")\n",
    "    print(\"   configurations and advanced techniques to push the boundaries further!\")\n",
    "    \n",
    "    print(\"\\n\" + \"üéâ\" * 75)\n",
    "    print(\"   **Thank you for building the future of AI-powered information retrieval!**\")\n",
    "    print(\"üéâ\" * 75)\n",
    "\n",
    "# Generate final summary\n",
    "print_final_summary()\n",
    "\n",
    "# Show system status\n",
    "print(f\"\\nüîß **System Status:**\")\n",
    "print(f\"   ‚Ä¢ Advanced RAG: ‚úÖ Operational\")\n",
    "print(f\"   ‚Ä¢ Gemini Integration: {'‚úÖ' if advanced_rag.has_generation else '‚ö†Ô∏è'} {'Active' if advanced_rag.has_generation else 'Mock Mode'}\")\n",
    "print(f\"   ‚Ä¢ Indexed Documents: {len(advanced_rag.search_engine.documents)}\")\n",
    "print(f\"   ‚Ä¢ Ready for Queries: ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "**Research Papers:**\n",
    "- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)\n",
    "- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)\n",
    "- [Self-RAG: Learning to Critique and Revise](https://arxiv.org/abs/2310.11511)\n",
    "\n",
    "**Implementation Frameworks:**\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [LlamaIndex Documentation](https://docs.llamaindex.ai/)\n",
    "- [Haystack Documentation](https://haystack.deepset.ai/)\n",
    "\n",
    "**Vector Databases:**\n",
    "- [Pinecone](https://www.pinecone.io/) - Managed vector database\n",
    "- [Weaviate](https://weaviate.io/) - Open-source vector search engine\n",
    "- [Qdrant](https://qdrant.tech/) - High-performance vector database\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ You've successfully built a production-ready Advanced RAG system!**\n",
    "\n",
    "**Next challenges:**\n",
    "- Deploy to cloud infrastructure\n",
    "- Scale to handle millions of documents  \n",
    "- Implement advanced RAG variants\n",
    "- Add multi-modal capabilities\n",
    "\n",
    "**Happy building! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
